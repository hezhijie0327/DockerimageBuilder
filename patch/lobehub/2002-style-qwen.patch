diff --git a/packages/model-bank/src/aiModels/qwen.ts b/packages/model-bank/src/aiModels/qwen.ts
index 0ac4a90f7ba80..17543b340dcc1 100644
--- a/packages/model-bank/src/aiModels/qwen.ts
+++ b/packages/model-bank/src/aiModels/qwen.ts
@@ -1019,7 +1019,8 @@ const qwenChatModels: AIChatModelCard[] = [
       deploymentName: 'qwen-plus-2025-12-01',
     },
     contextWindowTokens: 1_000_000,
-    description: 'Enhanced ultra-large Qwen model supporting Chinese, English, and other languages.',
+    description:
+      'Enhanced ultra-large Qwen model supporting Chinese, English, and other languages.',
     displayName: 'Qwen Plus',
     enabled: true,
     id: 'qwen-plus',
@@ -1477,7 +1478,8 @@ const qwenChatModels: AIChatModelCard[] = [
       vision: true,
     },
     contextWindowTokens: 131_072,
-    description: 'Qwen3 VL 8B non-thinking mode (Instruct) for standard multimodal generation and recognition.',
+    description:
+      'Qwen3 VL 8B non-thinking mode (Instruct) for standard multimodal generation and recognition.',
     displayName: 'Qwen3 VL 8B Instruct',
     id: 'qwen3-vl-8b-instruct',
     maxOutput: 32_768,
@@ -2180,6 +2182,74 @@ const qwenChatModels: AIChatModelCard[] = [
 ];
 
 const qwenImageModels: AIImageModelCard[] = [
+  {
+    description:
+      'Z-Image is a lightweight text-to-image generation model that can rapidly produce images, supports both Chinese and English text rendering, and flexibly adapts to multiple resolutions and aspect ratios.',
+    displayName: 'Z-Image Turbo',
+    enabled: true,
+    id: 'z-image-turbo',
+    organization: 'Qwen',
+    parameters: {
+      height: { default: 1536, max: 2048, min: 512, step: 1 },
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      width: { default: 1024, max: 2048, min: 512, step: 1 },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.1, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2025-12-19',
+    type: 'image',
+  },
+  {
+    description:
+      'Qwen Image Editing Model supports multi-image input and multi-image output, enabling precise in-image text editing, object addition, removal, or relocation, subject action modification, image style transfer, and enhanced visual detail.',
+    displayName: 'Qwen Image Edit Max',
+    enabled: true,
+    id: 'qwen-image-edit-max',
+    organization: 'Qwen',
+    parameters: {
+      imageUrl: {
+        default: '',
+      },
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.5, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2026-01-17',
+    type: 'image',
+  },
+  {
+    description:
+      'Qwen Image Editing Model supports multi-image input and multi-image output, enabling precise in-image text editing, object addition, removal, or relocation, subject action modification, image style transfer, and enhanced visual detail.',
+    displayName: 'Qwen Image Edit Plus',
+    enabled: true,
+    id: 'qwen-image-edit-plus',
+    organization: 'Qwen',
+    parameters: {
+      imageUrl: {
+        default: '',
+      },
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.2, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2025-12-23',
+    type: 'image',
+  },
   {
     description:
       'Qwen Image Edit is an image-to-image model that edits images based on input images and text prompts, enabling precise adjustments and creative transformations.',
@@ -2203,6 +2273,54 @@ const qwenImageModels: AIImageModelCard[] = [
     releasedAt: '2025-09-18',
     type: 'image',
   },
+  {
+    description:
+      'Qwen Image Generation Model (Max series) delivers enhanced realism and visual naturalness compared with the Plus series, effectively reducing AI-generated artifacts, and demonstrating outstanding performance in human appearance, texture details, and text rendering.',
+    displayName: 'Qwen Image Max',
+    enabled: true,
+    id: 'qwen-image-max',
+    organization: 'Qwen',
+    parameters: {
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      size: {
+        default: '1664x928',
+        enum: ['1664x928', '1472x1140', '1328x1328', '1140x1472', '928x1664'],
+      },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.5, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2025-12-31',
+    type: 'image',
+  },
+  {
+    description:
+      'It supports a wide range of artistic styles and is particularly proficient at rendering complex text within images, enabling integrated image–text layout design.',
+    displayName: 'Qwen Image Plus',
+    enabled: true,
+    id: 'qwen-image-plus',
+    organization: 'Qwen',
+    parameters: {
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      size: {
+        default: '1664x928',
+        enum: ['1664x928', '1472x1140', '1328x1328', '1140x1472', '928x1664'],
+      },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.2, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2026-01-12',
+    type: 'image',
+  },
   {
     description:
       'Qwen-Image is a general image generation model supporting multiple art styles and strong complex text rendering, especially Chinese and English. It supports multi-line layouts, paragraph-level text, and fine detail for complex text-image layouts.',
@@ -2227,9 +2345,77 @@ const qwenImageModels: AIImageModelCard[] = [
     releasedAt: '2025-08-13',
     type: 'image',
   },
+  {
+    description: 'Wanxiang 2.6 Image supports image editing and mixed image–text layout output.',
+    displayName: 'Wanxiang2.6 Image',
+    enabled: true,
+    id: 'wan2.6-image',
+    organization: 'Qwen',
+    parameters: {
+      height: { default: 1280, max: 1280, min: 768, step: 1 },
+      imageUrl: {
+        default: '',
+      },
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      width: { default: 1280, max: 1280, min: 768, step: 1 },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.2, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2025-07-28',
+    type: 'image',
+  },
+  {
+    description:
+      'Wanxiang 2.6 T2I supports flexible selection of image dimensions within total pixel area and aspect ratio constraints (same as Wanxiang 2.5).',
+    displayName: 'Wanxiang2.6 T2I',
+    enabled: true,
+    id: 'wan2.6-t2i',
+    organization: 'Qwen',
+    parameters: {
+      height: { default: 1280, max: 1440, min: 1280, step: 1 },
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      width: { default: 1280, max: 1440, min: 1280, step: 1 },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.2, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2025-12-16',
+    type: 'image',
+  },
+  {
+    description:
+      'Wanxiang 2.5 T2I supports flexible selection of image dimensions within total pixel area and aspect ratio constraints.',
+    displayName: 'Wanxiang2.5 T2I Preview',
+    enabled: true,
+    id: 'wan2.5-t2i-preview',
+    organization: 'Qwen',
+    parameters: {
+      height: { default: 1280, max: 1440, min: 1280, step: 1 },
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      width: { default: 1280, max: 1440, min: 1280, step: 1 },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.2, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2025-09-23',
+    type: 'image',
+  },
   {
     description:
-      'Wanxiang 2.2 Speed is the latest model with upgrades in creativity, stability, and realism, delivering fast generation and high value.',
+      'Wanxiang 2.2 Flash is the latest model with upgrades in creativity, stability, and realism, delivering fast generation and high value.',
     displayName: 'Wanxiang2.2 T2I Flash',
     enabled: true,
     id: 'wan2.2-t2i-flash',
@@ -2251,7 +2437,7 @@ const qwenImageModels: AIImageModelCard[] = [
   },
   {
     description:
-      'Wanxiang 2.2 Pro is the latest model with upgrades in creativity, stability, and realism, producing richer details.',
+      'Wanxiang 2.2 Plus is the latest model with upgrades in creativity, stability, and realism, producing richer details.',
     displayName: 'Wanxiang2.2 T2I Plus',
     enabled: true,
     id: 'wan2.2-t2i-plus',
diff --git a/packages/model-runtime/src/providers/qwen/createImage.ts b/packages/model-runtime/src/providers/qwen/createImage.ts
index 3c279008d7276..a4baf39616a0a 100644
--- a/packages/model-runtime/src/providers/qwen/createImage.ts
+++ b/packages/model-runtime/src/providers/qwen/createImage.ts
@@ -7,6 +7,25 @@ import { AgentRuntimeError } from '../../utils/createError';
 
 const log = createDebug('lobe-image:qwen');
 
+const text2ImageModels = new Set([
+  'wan2.5-t2i-preview',
+  'wan2.2-t2i-flash',
+  'wan2.2-t2i-plus',
+  'wanx2.1-t2i-turbo',
+  'wanx2.1-t2i-plus',
+  'wanx2.0-t2i-turbo',
+  'wanx-v1',
+  'stable-diffusion-xl',
+  'stable-diffusion-v1.5',
+  'stable-diffusion-3.5-large',
+  'stable-diffusion-3.5-large-turbo',
+  'flux-schnell',
+  'flux-dev',
+  'flux-merged',
+]);
+
+const image2ImageModels = new Set(['wan2.5-i2i-preview', 'wanx2.1-imageedit']);
+
 interface QwenImageTaskResponse {
   output: {
     error_message?: string;
@@ -20,7 +39,7 @@ interface QwenImageTaskResponse {
 }
 
 // Interface for qwen-image-edit multimodal-generation response
-interface QwenImageEditResponse {
+interface QwenMultimodalGenerationResponse {
   output: {
     choices: Array<{
       message: {
@@ -34,31 +53,51 @@ interface QwenImageEditResponse {
 }
 
 /**
- * Create an image generation task with Qwen API for text-to-image models
+ * Create an image generation task with Qwen API
+ * Supports both text-to-image and image-to-image workflows
  */
-async function createImageTask(payload: CreateImagePayload, apiKey: string): Promise<string> {
+async function createQwenImageTask(
+  payload: CreateImagePayload,
+  apiKey: string,
+  endpoint: 'text2image' | 'image2image',
+): Promise<string> {
   const { model, params } = payload;
-  // I can only say that the design of Alibaba Cloud's API is really bad; each model has a different endpoint path.
-  const endpoint = `https://dashscope.aliyuncs.com/api/v1/services/aigc/text2image/image-synthesis`;
-  log('Creating image task with model: %s, endpoint: %s', model, endpoint);
+  const url = `https://dashscope.aliyuncs.com/api/v1/services/aigc/${endpoint}/image-synthesis`;
+  log('Creating %s task with model: %s, endpoint: %s', endpoint, model, url);
 
-  const response = await fetch(endpoint, {
+  const input: Record<string, any> = {
+    prompt: params.prompt,
+  };
+
+  const parameters: Record<string, any> = {
+    n: 1,
+    ...(typeof params.seed === 'number' ? { seed: params.seed } : {}),
+    ...(params.width && params.height
+      ? { size: `${params.width}*${params.height}` }
+      : params.size
+        ? { size: params.size.replaceAll('x', '*') }
+        : { size: '1024*1024' }),
+  };
+
+  if (endpoint === 'image2image') {
+    let images = params.imageUrls;
+    if (!images && params.imageUrl) {
+      images = [params.imageUrl];
+      log('Converting imageUrl to images array: using image %s', params.imageUrl);
+    }
+
+    if (!images || images.length === 0) {
+      throw new Error('imageUrls or imageUrl is required for image-to-image models');
+    }
+
+    input.images = images;
+  }
+
+  const response = await fetch(url, {
     body: JSON.stringify({
-      input: {
-        prompt: params.prompt,
-        // negativePrompt is not part of standard parameters
-        // but can be supported by extending the params type if needed
-      },
+      input,
       model,
-      parameters: {
-        n: 1,
-        ...(typeof params.seed === 'number' ? { seed: params.seed } : {}),
-        ...(params.width && params.height
-          ? { size: `${params.width}*${params.height}` }
-          : params.size
-            ? { size: params.size.replaceAll('x', '*') }
-            : { size: '1024*1024' }),
-      },
+      parameters,
     }),
     headers: {
       'Authorization': `Bearer ${apiKey}`,
@@ -76,7 +115,7 @@ async function createImageTask(payload: CreateImagePayload, apiKey: string): Pro
       // Failed to parse JSON error response
     }
     throw new Error(
-      `Failed to create image task (${response.status}): ${errorData?.message || response.statusText}`,
+      `Failed to create ${endpoint} task (${response.status}): ${errorData?.message || response.statusText}`,
     );
   }
 
@@ -87,10 +126,10 @@ async function createImageTask(payload: CreateImagePayload, apiKey: string): Pro
 }
 
 /**
- * Create image with Qwen image-edit API for image-to-image models
+ * Create image with Qwen multimodal-generation API for image-to-image models
  * This is a synchronous API that returns the result directly
  */
-async function createImageEdit(
+async function createMultimodalGeneration(
   payload: CreateImagePayload,
   apiKey: string,
 ): Promise<CreateImageResponse> {
@@ -143,7 +182,7 @@ async function createImageEdit(
     );
   }
 
-  const data: QwenImageEditResponse = await response.json();
+  const data: QwenMultimodalGenerationResponse = await response.json();
 
   if (!data.output.choices || data.output.choices.length === 0) {
     throw new Error('No image choices returned from qwen-image-edit API');
@@ -196,7 +235,10 @@ async function queryTaskStatus(taskId: string, apiKey: string): Promise<QwenImag
 
 /**
  * Create image using Qwen API
- * Supports both text-to-image (async with polling) and image-to-image (sync) workflows
+ * Supports three types:
+ * - text2image (async with polling for legacy models)
+ * - image2image (async with polling for legacy models)
+ * - multimodal-generation (sync for new models, default fallback)
  */
 export async function createQwenImage(
   payload: CreateImagePayload,
@@ -206,59 +248,103 @@ export async function createQwenImage(
   const { model } = payload;
 
   try {
-    // Check if this is qwen-image-edit model for image-to-image
-    if (model === 'qwen-image-edit') {
-      log('Using multimodal-generation API for qwen-image-edit model');
-      return await createImageEdit(payload, apiKey);
+    const isImage2ImageModel = image2ImageModels.has(model);
+    const isText2ImageModel = text2ImageModels.has(model);
+
+    if (isImage2ImageModel) {
+      log('Using image2image API for model: %s', model);
+
+      const taskId = await createQwenImageTask(payload, apiKey, 'image2image');
+
+      const result = await asyncifyPolling<QwenImageTaskResponse, CreateImageResponse>({
+        checkStatus: (taskStatus: QwenImageTaskResponse): TaskResult<CreateImageResponse> => {
+          log('Task %s status: %s', taskId, taskStatus.output.task_status);
+
+          if (taskStatus.output.task_status === 'SUCCEEDED') {
+            if (!taskStatus.output.results || taskStatus.output.results.length === 0) {
+              return {
+                error: new Error('Task succeeded but no images generated'),
+                status: 'failed',
+              };
+            }
+
+            const generatedImageUrl = taskStatus.output.results[0].url;
+            log('Image generated successfully: %s', generatedImageUrl);
+
+            return {
+              data: { imageUrl: generatedImageUrl },
+              status: 'success',
+            };
+          }
+
+          if (taskStatus.output.task_status === 'FAILED') {
+            const errorMessage = taskStatus.output.error_message || 'Image generation task failed';
+            return {
+              error: new Error(`Qwen image generation failed: ${errorMessage}`),
+              status: 'failed',
+            };
+          }
+
+          return { status: 'pending' };
+        },
+        logger: {
+          debug: (message: any, ...args: any[]) => log(message, ...args),
+          error: (message: any, ...args: any[]) => log(message, ...args),
+        },
+        pollingQuery: () => queryTaskStatus(taskId, apiKey),
+      });
+
+      return result;
     }
 
-    // Default to text-to-image workflow for other qwen models
-    log('Using text2image API for model: %s', model);
+    if (isText2ImageModel) {
+      log('Using text2image API for model: %s', model);
 
-    // 1. Create image generation task
-    const taskId = await createImageTask(payload, apiKey);
+      const taskId = await createQwenImageTask(payload, apiKey, 'text2image');
 
-    // 2. Poll task status until completion using asyncifyPolling
-    const result = await asyncifyPolling<QwenImageTaskResponse, CreateImageResponse>({
-      checkStatus: (taskStatus: QwenImageTaskResponse): TaskResult<CreateImageResponse> => {
-        log('Task %s status: %s', taskId, taskStatus.output.task_status);
+      const result = await asyncifyPolling<QwenImageTaskResponse, CreateImageResponse>({
+        checkStatus: (taskStatus: QwenImageTaskResponse): TaskResult<CreateImageResponse> => {
+          log('Task %s status: %s', taskId, taskStatus.output.task_status);
 
-        if (taskStatus.output.task_status === 'SUCCEEDED') {
-          if (!taskStatus.output.results || taskStatus.output.results.length === 0) {
+          if (taskStatus.output.task_status === 'SUCCEEDED') {
+            if (!taskStatus.output.results || taskStatus.output.results.length === 0) {
+              return {
+                error: new Error('Task succeeded but no images generated'),
+                status: 'failed',
+              };
+            }
+
+            const generatedImageUrl = taskStatus.output.results[0].url;
+            log('Image generated successfully: %s', generatedImageUrl);
+
+            return {
+              data: { imageUrl: generatedImageUrl },
+              status: 'success',
+            };
+          }
+
+          if (taskStatus.output.task_status === 'FAILED') {
+            const errorMessage = taskStatus.output.error_message || 'Image generation task failed';
             return {
-              error: new Error('Task succeeded but no images generated'),
+              error: new Error(`Qwen image generation failed: ${errorMessage}`),
               status: 'failed',
             };
           }
 
-          const generatedImageUrl = taskStatus.output.results[0].url;
-          log('Image generated successfully: %s', generatedImageUrl);
-
-          return {
-            data: { imageUrl: generatedImageUrl },
-            status: 'success',
-          };
-        }
-
-        if (taskStatus.output.task_status === 'FAILED') {
-          const errorMessage = taskStatus.output.error_message || 'Image generation task failed';
-          return {
-            error: new Error(`Qwen image generation failed: ${errorMessage}`),
-            status: 'failed',
-          };
-        }
-
-        // Continue polling for pending/running status or other unknown statuses
-        return { status: 'pending' };
-      },
-      logger: {
-        debug: (message: any, ...args: any[]) => log(message, ...args),
-        error: (message: any, ...args: any[]) => log(message, ...args),
-      },
-      pollingQuery: () => queryTaskStatus(taskId, apiKey),
-    });
+          return { status: 'pending' };
+        },
+        logger: {
+          debug: (message: any, ...args: any[]) => log(message, ...args),
+          error: (message: any, ...args: any[]) => log(message, ...args),
+        },
+        pollingQuery: () => queryTaskStatus(taskId, apiKey),
+      });
+
+      return result;
+    }
 
-    return result;
+    log('Using multimodal-generation API for model: %s', model);
+    return await createMultimodalGeneration(payload, apiKey);
   } catch (error) {
     log('Error in createQwenImage: %O', error);
 
