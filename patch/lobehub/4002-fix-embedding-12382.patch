diff --git a/.env.example b/.env.example
index f182b9ee9d9..2459216f844 100644
--- a/.env.example
+++ b/.env.example
@@ -374,6 +374,17 @@ OPENAI_API_KEY=sk-xxxxxxxxx
 # Specify the Embedding model and Reranker model(unImplemented)
 # DEFAULT_FILES_CONFIG="embedding_model=openai/embedding-text-3-small,reranker_model=cohere/rerank-english-v3.0,query_mode=full_text"
 
+# Embedding batch size for processing (default: 50)
+# Note: Adjust based on provider limits:
+# - Qwen text-embedding-v3/v4: recommended 10
+# - Qwen text-embedding-v1/v2: recommended 25
+# - Most other providers: 50-100
+# EMBEDDING_BATCH_SIZE=50
+
+# Embedding concurrency for parallel processing (default: 10)
+# Higher values may increase speed but consume more API quota
+# EMBEDDING_CONCURRENCY=10
+
 # #######################################
 # ######### MCP Service Config ##########
 # #######################################
diff --git a/src/envs/file.ts b/src/envs/file.ts
index a8090bfb097..f2c47fc422a 100644
--- a/src/envs/file.ts
+++ b/src/envs/file.ts
@@ -23,6 +23,8 @@ export const getFileConfig = () => {
     runtimeEnv: {
       CHUNKS_AUTO_EMBEDDING: process.env.CHUNKS_AUTO_EMBEDDING !== '0',
       CHUNKS_AUTO_GEN_METADATA: process.env.CHUNKS_AUTO_GEN_METADATA !== '0',
+      EMBEDDING_BATCH_SIZE: process.env.EMBEDDING_BATCH_SIZE,
+      EMBEDDING_CONCURRENCY: process.env.EMBEDDING_CONCURRENCY,
 
       NEXT_PUBLIC_S3_DOMAIN: process.env.NEXT_PUBLIC_S3_DOMAIN,
       NEXT_PUBLIC_S3_FILE_PATH: process.env.NEXT_PUBLIC_S3_FILE_PATH || DEFAULT_S3_FILE_PATH,
@@ -40,6 +42,8 @@ export const getFileConfig = () => {
     server: {
       CHUNKS_AUTO_EMBEDDING: z.boolean(),
       CHUNKS_AUTO_GEN_METADATA: z.boolean(),
+      EMBEDDING_BATCH_SIZE: z.coerce.number().int().positive().default(50),
+      EMBEDDING_CONCURRENCY: z.coerce.number().int().positive().default(10),
 
       // S3
       S3_ACCESS_KEY_ID: z.string().optional(),
diff --git a/src/server/routers/async/file.ts b/src/server/routers/async/file.ts
index 5cb70cf8181..01e34ecf382 100644
--- a/src/server/routers/async/file.ts
+++ b/src/server/routers/async/file.ts
@@ -82,8 +82,8 @@ export const fileRouter = router({
 
           const startAt = Date.now();
 
-          const CHUNK_SIZE = 50;
-          const CONCURRENCY = 10;
+          const CHUNK_SIZE = fileEnv.EMBEDDING_BATCH_SIZE;
+          const CONCURRENCY = fileEnv.EMBEDDING_CONCURRENCY;
 
           const chunks = await ctx.chunkModel.getChunksTextByFileId(input.fileId);
           const requestArray = chunk(chunks, CHUNK_SIZE);
