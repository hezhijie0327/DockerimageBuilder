diff --git a/packages/model-bank/src/aiModels/qwen.ts b/packages/model-bank/src/aiModels/qwen.ts
index 759919b094a..cf0838f502d 100644
--- a/packages/model-bank/src/aiModels/qwen.ts
+++ b/packages/model-bank/src/aiModels/qwen.ts
@@ -1130,8 +1130,8 @@ const qwenChatModels: AIChatModelCard[] = [
   {
     abilities: {
       functionCall: true,
-      search: true,
       reasoning: true,
+      search: true,
     },
     contextWindowTokens: 262_144,
     description:
@@ -2281,6 +2281,78 @@ const qwenChatModels: AIChatModelCard[] = [
 ];
 
 const qwenImageModels: AIImageModelCard[] = [
+  {
+    description:
+      'Z-Image is a lightweight text-to-image generation model that can rapidly produce images, supports both Chinese and English text rendering, and flexibly adapts to multiple resolutions and aspect ratios.',
+    displayName: 'Z-Image Turbo',
+    enabled: true,
+    id: 'z-image-turbo',
+    organization: 'Qwen',
+    parameters: {
+      height: { default: 1536, max: 4096, min: 256, step: 1 },
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      width: { default: 1024, max: 4096, min: 256, step: 1 },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.1, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2025-12-19',
+    type: 'image',
+  },
+  {
+    description:
+      'Qwen Image Editing Model supports multi-image input and multi-image output, enabling precise in-image text editing, object addition, removal, or relocation, subject action modification, image style transfer, and enhanced visual detail.',
+    displayName: 'Qwen Image Edit Max',
+    enabled: true,
+    id: 'qwen-image-edit-max',
+    organization: 'Qwen',
+    parameters: {
+      height: { default: 1536, max: 2048, min: 512, step: 1 },
+      imageUrls: {
+        default: [],
+      },
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      width: { default: 1024, max: 2048, min: 512, step: 1 },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.5, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2026-01-17',
+    type: 'image',
+  },
+  {
+    description:
+      'Qwen Image Editing Model supports multi-image input and multi-image output, enabling precise in-image text editing, object addition, removal, or relocation, subject action modification, image style transfer, and enhanced visual detail.',
+    displayName: 'Qwen Image Edit Plus',
+    enabled: true,
+    id: 'qwen-image-edit-plus',
+    organization: 'Qwen',
+    parameters: {
+      height: { default: 1536, max: 2048, min: 512, step: 1 },
+      imageUrls: {
+        default: [],
+      },
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      width: { default: 1024, max: 2048, min: 512, step: 1 },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.2, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2025-12-23',
+    type: 'image',
+  },
   {
     description:
       'Qwen Image Edit is an image-to-image model that edits images based on input images and text prompts, enabling precise adjustments and creative transformations.',
@@ -2304,6 +2376,54 @@ const qwenImageModels: AIImageModelCard[] = [
     releasedAt: '2025-09-18',
     type: 'image',
   },
+  {
+    description:
+      'Qwen Image Generation Model (Max series) delivers enhanced realism and visual naturalness compared with the Plus series, effectively reducing AI-generated artifacts, and demonstrating outstanding performance in human appearance, texture details, and text rendering.',
+    displayName: 'Qwen Image Max',
+    enabled: true,
+    id: 'qwen-image-max',
+    organization: 'Qwen',
+    parameters: {
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      size: {
+        default: '1664x928',
+        enum: ['1664x928', '1472x1140', '1328x1328', '1140x1472', '928x1664'],
+      },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.5, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2025-12-31',
+    type: 'image',
+  },
+  {
+    description:
+      'It supports a wide range of artistic styles and is particularly proficient at rendering complex text within images, enabling integrated image–text layout design.',
+    displayName: 'Qwen Image Plus',
+    enabled: true,
+    id: 'qwen-image-plus',
+    organization: 'Qwen',
+    parameters: {
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      size: {
+        default: '1664x928',
+        enum: ['1664x928', '1472x1140', '1328x1328', '1140x1472', '928x1664'],
+      },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.2, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2026-01-12',
+    type: 'image',
+  },
   {
     description:
       'Qwen-Image is a general image generation model supporting multiple art styles and strong complex text rendering, especially Chinese and English. It supports multi-line layouts, paragraph-level text, and fine detail for complex text-image layouts.',
@@ -2328,11 +2448,100 @@ const qwenImageModels: AIImageModelCard[] = [
     releasedAt: '2025-08-13',
     type: 'image',
   },
+  {
+    description: 'Wanxiang 2.6 Image supports image editing and mixed image–text layout output.',
+    displayName: 'Wanxiang2.6 Image',
+    enabled: true,
+    id: 'wan2.6-image',
+    organization: 'Qwen',
+    parameters: {
+      height: { default: 1280, max: 2880, min: 640, step: 1 },
+      imageUrls: {
+        default: [],
+      },
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      width: { default: 1280, max: 2880, min: 640, step: 1 },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.2, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2025-07-28',
+    type: 'image',
+  },
   {
     description:
-      'Wanxiang 2.2 Speed is the latest model with upgrades in creativity, stability, and realism, delivering fast generation and high value.',
-    displayName: 'Wanxiang2.2 T2I Flash',
+      'Wanxiang 2.6 T2I supports flexible selection of image dimensions within total pixel area and aspect ratio constraints (same as Wanxiang 2.5).',
+    displayName: 'Wanxiang2.6 T2I',
     enabled: true,
+    id: 'wan2.6-t2i',
+    organization: 'Qwen',
+    parameters: {
+      height: { default: 1280, max: 2880, min: 640, step: 1 },
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      width: { default: 1280, max: 2880, min: 640, step: 1 },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.2, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2025-12-16',
+    type: 'image',
+  },
+  {
+    description: 'Wanxiang 2.5 I2I Preview supports single-image editing and multi-image fusion.',
+    displayName: 'Wanxiang2.5 I2I Preview',
+    id: 'wan2.5-i2i-preview',
+    organization: 'Qwen',
+    parameters: {
+      height: { default: 1280, max: 2560, min: 384, step: 1 },
+      imageUrls: {
+        default: [],
+      },
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      width: { default: 1280, max: 2560, min: 384, step: 1 },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.2, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2025-09-23',
+    type: 'image',
+  },
+  {
+    description:
+      'Wanxiang 2.5 T2I supports flexible selection of image dimensions within total pixel area and aspect ratio constraints.',
+    displayName: 'Wanxiang2.5 T2I Preview',
+    id: 'wan2.5-t2i-preview',
+    organization: 'Qwen',
+    parameters: {
+      height: { default: 1280, max: 2880, min: 640, step: 1 },
+      prompt: {
+        default: '',
+      },
+      seed: { default: null },
+      width: { default: 1280, max: 2880, min: 640, step: 1 },
+    },
+    pricing: {
+      currency: 'CNY',
+      units: [{ name: 'imageGeneration', rate: 0.2, strategy: 'fixed', unit: 'image' }],
+    },
+    releasedAt: '2025-09-23',
+    type: 'image',
+  },
+  {
+    description:
+      'Wanxiang 2.2 Flash is the latest model with upgrades in creativity, stability, and realism, delivering fast generation and high value.',
+    displayName: 'Wanxiang2.2 T2I Flash',
     id: 'wan2.2-t2i-flash',
     organization: 'Qwen',
     parameters: {
@@ -2352,7 +2561,7 @@ const qwenImageModels: AIImageModelCard[] = [
   },
   {
     description:
-      'Wanxiang 2.2 Pro is the latest model with upgrades in creativity, stability, and realism, producing richer details.',
+      'Wanxiang 2.2 Plus is the latest model with upgrades in creativity, stability, and realism, producing richer details.',
     displayName: 'Wanxiang2.2 T2I Plus',
     enabled: true,
     id: 'wan2.2-t2i-plus',
diff --git a/packages/model-runtime/src/providers/qwen/createImage.test.ts b/packages/model-runtime/src/providers/qwen/createImage.test.ts
index f636d874952..9b8f011f2b0 100644
--- a/packages/model-runtime/src/providers/qwen/createImage.test.ts
+++ b/packages/model-runtime/src/providers/qwen/createImage.test.ts
@@ -1,8 +1,8 @@
 // @vitest-environment node
 import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
 
-import type { CreateImageOptions } from '../../core/openaiCompatibleFactory';
-import type { CreateImagePayload } from '../../types/image';
+import { type CreateImageOptions } from '../../core/openaiCompatibleFactory';
+import { type CreateImagePayload } from '../../types/image';
 import { createQwenImage } from './createImage';
 
 // Mock the console.error to avoid polluting test output
@@ -23,6 +23,109 @@ afterEach(() => {
 });
 
 describe('createQwenImage', () => {
+  describe('Base URL handling', () => {
+    it('should use intl baseURL when provided', async () => {
+      const mockTaskId = 'task-123456';
+      const mockImageUrl = 'https://example.com/test-image.jpg';
+      const intlBaseUrl = 'https://dashscope-intl.aliyuncs.com/compatible-mode/v1';
+
+      // Mock fetch for task creation and immediate success
+      global.fetch = vi
+        .fn()
+        .mockResolvedValueOnce({
+          ok: true,
+          json: async () => ({
+            output: { task_id: mockTaskId },
+            request_id: 'req-123',
+          }),
+        })
+        .mockResolvedValueOnce({
+          ok: true,
+          json: async () => ({
+            output: {
+              task_id: mockTaskId,
+              task_status: 'SUCCEEDED',
+              results: [{ url: mockImageUrl }],
+            },
+            request_id: 'req-124',
+          }),
+        });
+
+      const payload: CreateImagePayload = {
+        model: 'wanx-v1',
+        params: {
+          prompt: 'Test image',
+        },
+      };
+
+      const optionsWithCustomUrl: CreateImageOptions = {
+        apiKey: 'test-api-key',
+        provider: 'qwen',
+        baseURL: intlBaseUrl,
+      };
+
+      const result = await createQwenImage(payload, optionsWithCustomUrl);
+
+      // Verify the custom base URL is used (without /compatible-mode/v1)
+      expect(fetch).toHaveBeenCalledWith(
+        'https://dashscope-intl.aliyuncs.com/api/v1/services/aigc/text2image/image-synthesis',
+        expect.any(Object),
+      );
+
+      // Verify the task status query also uses the custom base URL
+      expect(fetch).toHaveBeenCalledWith(
+        'https://dashscope-intl.aliyuncs.com/api/v1/tasks/task-123456',
+        expect.any(Object),
+      );
+
+      expect(result).toEqual({ imageUrl: mockImageUrl });
+    });
+
+    it('should use default baseURL when not provided', async () => {
+      const mockTaskId = 'task-123456';
+      const mockImageUrl = 'https://dashscope.oss-cn-beijing.aliyuncs.com/aigc/test-image.jpg';
+
+      // Mock fetch for task creation and immediate success
+      global.fetch = vi
+        .fn()
+        .mockResolvedValueOnce({
+          ok: true,
+          json: async () => ({
+            output: { task_id: mockTaskId },
+            request_id: 'req-123',
+          }),
+        })
+        .mockResolvedValueOnce({
+          ok: true,
+          json: async () => ({
+            output: {
+              task_id: mockTaskId,
+              task_status: 'SUCCEEDED',
+              results: [{ url: mockImageUrl }],
+            },
+            request_id: 'req-124',
+          }),
+        });
+
+      const payload: CreateImagePayload = {
+        model: 'wanx-v1',
+        params: {
+          prompt: 'Test image',
+        },
+      };
+
+      const result = await createQwenImage(payload, mockOptions);
+
+      // Verify the default base URL is used
+      expect(fetch).toHaveBeenCalledWith(
+        'https://dashscope.aliyuncs.com/api/v1/services/aigc/text2image/image-synthesis',
+        expect.any(Object),
+      );
+
+      expect(result).toEqual({ imageUrl: mockImageUrl });
+    });
+  });
+
   describe('Success scenarios', () => {
     it('should successfully generate image with immediate success', async () => {
       const mockTaskId = 'task-123456';
@@ -701,157 +804,12 @@ describe('createQwenImage', () => {
       );
     });
 
-    it('should convert imageUrls array to imageUrl for qwen-image-edit', async () => {
-      const mockImageUrl =
-        'https://dashscope.oss-cn-beijing.aliyuncs.com/aigc/imageUrls-converted.jpg';
-
-      global.fetch = vi.fn().mockResolvedValueOnce({
-        ok: true,
-        json: async () => ({
-          output: {
-            choices: [
-              {
-                message: {
-                  content: [{ image: mockImageUrl }],
-                },
-              },
-            ],
-          },
-          request_id: 'req-imageUrls-123',
-        }),
-      });
-
-      const payload: CreateImagePayload = {
-        model: 'qwen-image-edit',
-        params: {
-          prompt: 'Edit this image to add a dog',
-          imageUrls: [
-            'https://example.com/source-image-1.jpg',
-            'https://example.com/source-image-2.jpg',
-          ],
-        },
-      };
-
-      const result = await createQwenImage(payload, mockOptions);
-
-      expect(result).toEqual({
-        imageUrl: mockImageUrl,
-      });
-
-      const [url, options] = (fetch as any).mock.calls[0];
-      const body = JSON.parse(options.body);
-
-      // Verify that the first imageUrl from imageUrls array was used
-      expect(body.input.messages[0].content[0].image).toBe(
-        'https://example.com/source-image-1.jpg',
-      );
-    });
-
-    it('should use first imageUrl when imageUrls has multiple elements', async () => {
-      const mockImageUrl = 'https://dashscope.oss-cn-beijing.aliyuncs.com/aigc/first-element.jpg';
-
-      global.fetch = vi.fn().mockResolvedValueOnce({
-        ok: true,
-        json: async () => ({
-          output: {
-            choices: [
-              {
-                message: {
-                  content: [{ image: mockImageUrl }],
-                },
-              },
-            ],
-          },
-          request_id: 'req-first-element',
-        }),
-      });
-
-      const payload: CreateImagePayload = {
-        model: 'qwen-image-edit',
-        params: {
-          prompt: 'Use the first image only',
-          imageUrls: [
-            'https://example.com/first-image.jpg',
-            'https://example.com/second-image.jpg',
-            'https://example.com/third-image.jpg',
-          ],
-        },
-      };
-
-      await createQwenImage(payload, mockOptions);
-
-      const [url, options] = (fetch as any).mock.calls[0];
-      const body = JSON.parse(options.body);
-
-      // Should use only the first image from the array
-      expect(body.input.messages[0].content[0].image).toBe('https://example.com/first-image.jpg');
-    });
-
-    it('should throw error when imageUrls is empty array', async () => {
-      const payload: CreateImagePayload = {
-        model: 'qwen-image-edit',
-        params: {
-          prompt: 'Edit this image',
-          imageUrls: [], // Empty array
-        },
-      };
-
-      await expect(createQwenImage(payload, mockOptions)).rejects.toEqual(
-        expect.objectContaining({
-          errorType: 'ProviderBizError',
-          provider: 'qwen',
-        }),
-      );
-    });
-
-    it('should prioritize imageUrl over imageUrls when both are provided', async () => {
-      const mockImageUrl = 'https://dashscope.oss-cn-beijing.aliyuncs.com/aigc/priority-test.jpg';
-
-      global.fetch = vi.fn().mockResolvedValueOnce({
-        ok: true,
-        json: async () => ({
-          output: {
-            choices: [
-              {
-                message: {
-                  content: [{ image: mockImageUrl }],
-                },
-              },
-            ],
-          },
-          request_id: 'req-priority-test',
-        }),
-      });
-
-      const payload: CreateImagePayload = {
-        model: 'qwen-image-edit',
-        params: {
-          prompt: 'Test priority between imageUrl and imageUrls',
-          imageUrl: 'https://example.com/priority-image.jpg',
-          imageUrls: [
-            'https://example.com/should-not-use-1.jpg',
-            'https://example.com/should-not-use-2.jpg',
-          ],
-        },
-      };
-
-      await createQwenImage(payload, mockOptions);
-
-      const [url, options] = (fetch as any).mock.calls[0];
-      const body = JSON.parse(options.body);
-
-      // Should use imageUrl, not imageUrls
-      expect(body.input.messages[0].content[0].image).toBe(
-        'https://example.com/priority-image.jpg',
-      );
-    });
-
-    it('should throw error when neither imageUrl nor imageUrls are provided', async () => {
+    it('should throw error when imageUrl is not provided', async () => {
       const payload: CreateImagePayload = {
         model: 'qwen-image-edit',
         params: {
           prompt: 'Edit this image',
-          // Neither imageUrl nor imageUrls provided
+          // imageUrl not provided
         },
       };
 
diff --git a/packages/model-runtime/src/providers/qwen/createImage.ts b/packages/model-runtime/src/providers/qwen/createImage.ts
index 4213ac7126f..13135d4484e 100644
--- a/packages/model-runtime/src/providers/qwen/createImage.ts
+++ b/packages/model-runtime/src/providers/qwen/createImage.ts
@@ -1,13 +1,32 @@
 import createDebug from 'debug';
 
-import type { CreateImageOptions } from '../../core/openaiCompatibleFactory';
-import type { CreateImagePayload, CreateImageResponse } from '../../types/image';
-import type { TaskResult } from '../../utils/asyncifyPolling';
+import { type CreateImageOptions } from '../../core/openaiCompatibleFactory';
+import { type CreateImagePayload, type CreateImageResponse } from '../../types/image';
+import { type TaskResult } from '../../utils/asyncifyPolling';
 import { asyncifyPolling } from '../../utils/asyncifyPolling';
 import { AgentRuntimeError } from '../../utils/createError';
 
 const log = createDebug('lobe-image:qwen');
 
+const text2ImageModels = [
+  /^wan2\.(2|5)-t2i-/,
+  /^wanx2\.(0|1)-t2i-/,
+  /^wanx-v1/,
+  /^stable-diffusion-/,
+  /^flux-/,
+];
+
+const image2ImageModels = [/^wan2\.(2|5)-i2i-$/];
+
+const imageRequiredModels = [/^qwen-image-edit/, /^wan2\.(2|5)-i2i-$/, /^wan2\.6-image/];
+
+// Helper function to check if model matches any pattern in the array
+function matchesModel(model: string, patterns: Array<string | RegExp>): boolean {
+  return patterns.some((pattern) =>
+    pattern instanceof RegExp ? pattern.test(model) : pattern === model,
+  );
+}
+
 interface QwenImageTaskResponse {
   output: {
     error_message?: string;
@@ -20,8 +39,8 @@ interface QwenImageTaskResponse {
   request_id: string;
 }
 
-// Interface for qwen-image-edit multimodal-generation response
-interface QwenImageEditResponse {
+// Interface for multimodal-generation response
+interface QwenMultimodalGenerationResponse {
   output: {
     choices: Array<{
       message: {
@@ -35,31 +54,57 @@ interface QwenImageEditResponse {
 }
 
 /**
- * Create an image generation task with Qwen API for text-to-image models
+ * Create an image generation task with Qwen API
+ * Supports both text-to-image and image-to-image workflows
  */
-async function createImageTask(payload: CreateImagePayload, apiKey: string): Promise<string> {
+async function createQwenImageTask(
+  payload: CreateImagePayload,
+  apiKey: string,
+  endpoint: 'text2image' | 'image2image',
+  provider: string,
+  baseUrl: string,
+): Promise<string> {
   const { model, params } = payload;
-  // I can only say that the design of Alibaba Cloud's API is really bad; each model has a different endpoint path.
-  const endpoint = `https://dashscope.aliyuncs.com/api/v1/services/aigc/text2image/image-synthesis`;
-  log('Creating image task with model: %s, endpoint: %s', model, endpoint);
+  const url = `${baseUrl}/api/v1/services/aigc/${endpoint}/image-synthesis`;
+  log('Creating %s task with model: %s, endpoint: %s', endpoint, model, url);
 
-  const response = await fetch(endpoint, {
+  const input: Record<string, any> = {
+    prompt: params.prompt,
+  };
+
+  const parameters: Record<string, any> = {
+    n: 1,
+    ...(typeof params.seed === 'number' ? { seed: params.seed } : {}),
+    ...(params.width && params.height
+      ? { size: `${params.width}*${params.height}` }
+      : params.size
+        ? { size: params.size.replaceAll('x', '*') }
+        : { size: '1024*1024' }),
+  };
+
+  if (endpoint === 'image2image') {
+    let images = params.imageUrls;
+    if (!images && params.imageUrl) {
+      images = [params.imageUrl];
+      log('Converting imageUrl to images array: using image %s', params.imageUrl);
+    }
+
+    if (!images || images.length === 0) {
+      throw AgentRuntimeError.createImage({
+        error: new Error('imageUrls or imageUrl is required for image-to-image models'),
+        errorType: 'ProviderBizError',
+        provider,
+      });
+    }
+
+    input.images = images;
+  }
+
+  const response = await fetch(url, {
     body: JSON.stringify({
-      input: {
-        prompt: params.prompt,
-        // negativePrompt is not part of standard parameters
-        // but can be supported by extending the params type if needed
-      },
+      input,
       model,
-      parameters: {
-        n: 1,
-        ...(typeof params.seed === 'number' ? { seed: params.seed } : {}),
-        ...(params.width && params.height
-          ? { size: `${params.width}*${params.height}` }
-          : params.size
-            ? { size: params.size.replaceAll('x', '*') }
-            : { size: '1024*1024' }),
-      },
+      parameters,
     }),
     headers: {
       'Authorization': `Bearer ${apiKey}`,
@@ -77,7 +122,7 @@ async function createImageTask(payload: CreateImagePayload, apiKey: string): Pro
       // Failed to parse JSON error response
     }
     throw new Error(
-      `Failed to create image task (${response.status}): ${errorData?.message || response.statusText}`,
+      `Failed to create ${endpoint} task for model ${model} (${response.status}): ${errorData?.message || response.statusText}`,
     );
   }
 
@@ -88,26 +133,39 @@ async function createImageTask(payload: CreateImagePayload, apiKey: string): Pro
 }
 
 /**
- * Create image with Qwen image-edit API for image-to-image models
+ * Create image with Qwen multimodal-generation API
  * This is a synchronous API that returns the result directly
+ * Supports both text-to-image (t2i) and image-to-image (i2i) workflows
  */
-async function createImageEdit(
+async function createMultimodalGeneration(
   payload: CreateImagePayload,
   apiKey: string,
+  baseUrl: string,
 ): Promise<CreateImageResponse> {
   const { model, params } = payload;
-  const endpoint = `https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation`;
-  log('Creating image edit with model: %s, endpoint: %s', model, endpoint);
-
-  // Handle imageUrls to imageUrl conversion
-  let imageUrl = params.imageUrl;
-  if (!imageUrl && params.imageUrls && params.imageUrls.length > 0) {
-    imageUrl = params.imageUrls[0];
-    log('Converting imageUrls to imageUrl: using first image %s', imageUrl);
+  const endpoint = `${baseUrl}/api/v1/services/aigc/multimodal-generation/generation`;
+  log('Creating image with model: %s, endpoint: %s', model, endpoint);
+
+  // Check if this model requires an image
+  const requiresImage = matchesModel(model, imageRequiredModels);
+
+  if (requiresImage && !params.imageUrl && (!params.imageUrls || params.imageUrls.length === 0)) {
+    throw AgentRuntimeError.createImage({
+      error: new Error(`imageUrl or imageUrls is required for model ${model}`),
+      errorType: 'ProviderBizError',
+      provider: 'qwen',
+    });
   }
 
-  if (!imageUrl) {
-    throw new Error('imageUrl or imageUrls is required for qwen-image-edit model');
+  const content: Array<{ image: string } | { text: string }> = [{ text: params.prompt }];
+
+  if (params.imageUrl) {
+    content.unshift({ image: params.imageUrl });
+  } else if (params.imageUrls && params.imageUrls.length > 0) {
+    // Add each image as a separate object in the content array
+    for (const imageUrl of params.imageUrls.reverse()) {
+      content.unshift({ image: imageUrl });
+    }
   }
 
   const response = await fetch(endpoint, {
@@ -115,7 +173,7 @@ async function createImageEdit(
       input: {
         messages: [
           {
-            content: [{ image: imageUrl }, { text: params.prompt }],
+            content,
             role: 'user',
           },
         ],
@@ -140,24 +198,24 @@ async function createImageEdit(
       // Failed to parse JSON error response
     }
     throw new Error(
-      `Failed to create image edit (${response.status}): ${errorData?.message || response.statusText}`,
+      `Failed to create image for model ${model} (${response.status}): ${errorData?.message || response.statusText}`,
     );
   }
 
-  const data: QwenImageEditResponse = await response.json();
+  const data: QwenMultimodalGenerationResponse = await response.json();
 
   if (!data.output.choices || data.output.choices.length === 0) {
-    throw new Error('No image choices returned from qwen-image-edit API');
+    throw new Error(`No image choices returned from API for model ${model}`);
   }
 
   const choice = data.output.choices[0];
   if (!choice.message.content || choice.message.content.length === 0) {
-    throw new Error('No image content returned from qwen-image-edit API');
+    throw new Error(`No image content returned from API for model ${model}`);
   }
 
   const imageContent = choice.message.content.find((content) => 'image' in content);
   if (!imageContent) {
-    throw new Error('No image found in response content');
+    throw new Error(`No image found in response content for model ${model}`);
   }
 
   const resultImageUrl = imageContent.image;
@@ -169,8 +227,12 @@ async function createImageEdit(
 /**
  * Query the status of an image generation task
  */
-async function queryTaskStatus(taskId: string, apiKey: string): Promise<QwenImageTaskResponse> {
-  const endpoint = `https://dashscope.aliyuncs.com/api/v1/tasks/${taskId}`;
+async function queryTaskStatus(
+  taskId: string,
+  apiKey: string,
+  baseUrl: string,
+): Promise<QwenImageTaskResponse> {
+  const endpoint = `${baseUrl}/api/v1/tasks/${taskId}`;
 
   log('Querying task status for: %s', taskId);
 
@@ -188,7 +250,7 @@ async function queryTaskStatus(taskId: string, apiKey: string): Promise<QwenImag
       // Failed to parse JSON error response
     }
     throw new Error(
-      `Failed to query task status (${response.status}): ${errorData?.message || response.statusText}`,
+      `Failed to query task status for ${taskId} (${response.status}): ${errorData?.message || response.statusText}`,
     );
   }
 
@@ -197,69 +259,78 @@ async function queryTaskStatus(taskId: string, apiKey: string): Promise<QwenImag
 
 /**
  * Create image using Qwen API
- * Supports both text-to-image (async with polling) and image-to-image (sync) workflows
+ * Supports three types:
+ * - text2image (async with polling for legacy models)
+ * - image2image (async with polling for legacy models)
+ * - multimodal-generation (sync for new models, default fallback)
  */
 export async function createQwenImage(
   payload: CreateImagePayload,
   options: CreateImageOptions,
 ): Promise<CreateImageResponse> {
-  const { apiKey, provider } = options;
+  const { apiKey, baseURL, provider } = options;
   const { model } = payload;
 
+  // Check if URL has /compatible-mode/v1 suffix and remove it
+  const suffixIndex = baseURL ? baseURL.indexOf('/compatible-mode/v1') : -1;
+  const dashscopeURL: string =
+    suffixIndex > -1 ? baseURL!.slice(0, suffixIndex) : 'https://dashscope.aliyuncs.com';
+  log('Using dashscopeURL: %s', dashscopeURL);
+
   try {
-    // Check if this is qwen-image-edit model for image-to-image
-    if (model === 'qwen-image-edit') {
-      log('Using multimodal-generation API for qwen-image-edit model');
-      return await createImageEdit(payload, apiKey);
-    }
+    const isText2Image = matchesModel(model, text2ImageModels);
+    const isImage2Image = matchesModel(model, image2ImageModels);
 
-    // Default to text-to-image workflow for other qwen models
-    log('Using text2image API for model: %s', model);
+    if (isText2Image || isImage2Image) {
+      const endpoint = isImage2Image ? 'image2image' : 'text2image';
+      log('Using %s API for model: %s', endpoint, model);
 
-    // 1. Create image generation task
-    const taskId = await createImageTask(payload, apiKey);
+      const taskId = await createQwenImageTask(payload, apiKey, endpoint, provider, dashscopeURL);
 
-    // 2. Poll task status until completion using asyncifyPolling
-    const result = await asyncifyPolling<QwenImageTaskResponse, CreateImageResponse>({
-      checkStatus: (taskStatus: QwenImageTaskResponse): TaskResult<CreateImageResponse> => {
-        log('Task %s status: %s', taskId, taskStatus.output.task_status);
+      const result = await asyncifyPolling<QwenImageTaskResponse, CreateImageResponse>({
+        checkStatus: (taskStatus: QwenImageTaskResponse): TaskResult<CreateImageResponse> => {
+          log('Task %s status: %s', taskId, taskStatus.output.task_status);
 
-        if (taskStatus.output.task_status === 'SUCCEEDED') {
-          if (!taskStatus.output.results || taskStatus.output.results.length === 0) {
+          if (taskStatus.output.task_status === 'SUCCEEDED') {
+            if (!taskStatus.output.results || taskStatus.output.results.length === 0) {
+              return {
+                error: new Error('Task succeeded but no images generated'),
+                status: 'failed',
+              };
+            }
+
+            const generatedImageUrl = taskStatus.output.results[0].url;
+            log('Image generated successfully: %s', generatedImageUrl);
+
+            return {
+              data: { imageUrl: generatedImageUrl },
+              status: 'success',
+            };
+          }
+
+          if (taskStatus.output.task_status === 'FAILED') {
+            const errorMessage =
+              taskStatus.output.error_message || 'Task failed without error message';
             return {
-              error: new Error('Task succeeded but no images generated'),
+              error: new Error(`Image generation failed for model ${model}: ${errorMessage}`),
               status: 'failed',
             };
           }
 
-          const generatedImageUrl = taskStatus.output.results[0].url;
-          log('Image generated successfully: %s', generatedImageUrl);
-
-          return {
-            data: { imageUrl: generatedImageUrl },
-            status: 'success',
-          };
-        }
-
-        if (taskStatus.output.task_status === 'FAILED') {
-          const errorMessage = taskStatus.output.error_message || 'Image generation task failed';
-          return {
-            error: new Error(`Qwen image generation failed: ${errorMessage}`),
-            status: 'failed',
-          };
-        }
-
-        // Continue polling for pending/running status or other unknown statuses
-        return { status: 'pending' };
-      },
-      logger: {
-        debug: (message: any, ...args: any[]) => log(message, ...args),
-        error: (message: any, ...args: any[]) => log(message, ...args),
-      },
-      pollingQuery: () => queryTaskStatus(taskId, apiKey),
-    });
+          return { status: 'pending' };
+        },
+        logger: {
+          debug: (message: any, ...args: any[]) => log(message, ...args),
+          error: (message: any, ...args: any[]) => log(message, ...args),
+        },
+        pollingQuery: () => queryTaskStatus(taskId, apiKey, dashscopeURL),
+      });
+
+      return result;
+    }
 
-    return result;
+    log('Using multimodal-generation API for model: %s', model);
+    return await createMultimodalGeneration(payload, apiKey, dashscopeURL);
   } catch (error) {
     log('Error in createQwenImage: %O', error);
 
