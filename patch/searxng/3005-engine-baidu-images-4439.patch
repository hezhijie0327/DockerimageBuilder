diff --git a/searx/engines/baidu.py b/searx/engines/baidu.py
index 6aa0716fd94..1b43b044b17 100644
--- a/searx/engines/baidu.py
+++ b/searx/engines/baidu.py
@@ -9,6 +9,7 @@
 
 from urllib.parse import urlencode
 from datetime import datetime
+import time
 
 from searx.exceptions import SearxEngineAPIException
 
@@ -26,6 +27,9 @@
 base_url = "https://www.baidu.com/s"
 results_per_page = 10
 
+time_range_support = True
+time_range_dict = {"day": 86400, "week": 604800, "month": 2592000, "year": 31536000}
+
 
 def request(query, params):
     keyword = query.strip()
@@ -37,6 +41,11 @@ def request(query, params):
         "tn": "json",
     }
 
+    if params.get("time_range") in time_range_dict:
+        now = int(time.time())
+        past = now - time_range_dict[params["time_range"]]
+        query_params["gpc"] = f"stf={past},{now}|stftype=1"
+
     params["url"] = f"{base_url}?{urlencode(query_params)}"
     return params
 
diff --git a/searx/engines/baidu_images.py b/searx/engines/baidu_images.py
new file mode 100644
index 00000000000..518492212b5
--- /dev/null
+++ b/searx/engines/baidu_images.py
@@ -0,0 +1,63 @@
+# SPDX-License-Identifier: AGPL-3.0-or-later
+"""Baidu-Images: A search engine for retrieving images from Baidu."""
+
+from urllib.parse import urlencode
+
+import json
+
+from searx.exceptions import SearxEngineAPIException
+from searx.utils import html_to_text
+
+about = {
+    "website": "https://image.baidu.com/",
+    "wikidata_id": "Q109342769",
+    "use_official_api": False,
+    "require_api_key": False,
+    "results": "JSON",
+}
+
+paging = True
+results_per_page = 10
+categories = ["images"]
+
+base_url = "https://image.baidu.com"
+
+
+def request(query, params):
+    query_params = {
+        "tn": "resultjson_com",
+        "word": query,
+        "pn": (params["pageno"] - 1) * results_per_page,
+        "rn": results_per_page,
+    }
+
+    params["url"] = f"{base_url}/search/acjson?{urlencode(query_params)}"
+    return params
+
+
+def response(resp):
+    try:
+        data = json.loads(resp.text, strict=False)
+    except Exception as e:
+        raise SearxEngineAPIException(f"Invalid response: {e}") from e
+    results = []
+
+    if "data" in data:
+        for item in data["data"]:
+            replace_url = item.get("replaceUrl", [{}])[0]
+            from_url = replace_url.get("FromURL", "").replace("\\/", "/")
+            img_src = replace_url.get("ObjURL", "").replace("\\/", "/")
+
+            results.append(
+                {
+                    "template": "images.html",
+                    "url": from_url,
+                    "thumbnail_src": img_src,
+                    "img_src": img_src,
+                    "content": html_to_text(item.get("fromPageTitleEnc", "")),
+                    "title": html_to_text(item.get("fromPageTitle", "")),
+                    "source": item.get("fromURLHost", ""),
+                }
+            )
+
+    return results
