diff --git a/src/config/aiModels/google.ts b/src/config/aiModels/google.ts
index 6a7398ede31db..f17d5d8cee2c4 100644
--- a/src/config/aiModels/google.ts
+++ b/src/config/aiModels/google.ts
@@ -11,7 +11,8 @@ const googleChatModels: AIChatModelCard[] = [
     contextWindowTokens: 1_048_576 + 65_536,
     description:
       'Gemini 2.5 Pro 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。',
-    displayName: 'Gemini 2.5 Pro (Paid)',
+    displayName: 'Gemini 2.5 Pro',
+    enabled: true,
     id: 'gemini-2.5-pro',
     maxOutput: 65_536,
     pricing: {
@@ -75,30 +76,6 @@ const googleChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
-  {
-    abilities: {
-      functionCall: true,
-      reasoning: true,
-      search: true,
-      vision: true,
-    },
-    contextWindowTokens: 1_048_576 + 65_536,
-    description:
-      'Gemini 2.5 Pro Experimental 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。',
-    displayName: 'Gemini 2.5 Pro Experimental 03-25',
-    id: 'gemini-2.5-pro-exp-03-25',
-    maxOutput: 65_536,
-    pricing: {
-      input: 0,
-      output: 0,
-    },
-    releasedAt: '2025-03-25',
-    settings: {
-      searchImpl: 'params',
-      searchProvider: 'google',
-    },
-    type: 'chat',
-  },
   {
     abilities: {
       functionCall: true,
@@ -202,7 +179,7 @@ const googleChatModels: AIChatModelCard[] = [
       search: true,
       vision: true,
     },
-    contextWindowTokens: 65_536 + 65_536,
+    contextWindowTokens: 1_048_576 + 65_536,
     description:
       'Gemini 2.5 Flash-Lite Preview 是 Google 最小、性价比最高的模型，专为大规模使用而设计。',
     displayName: 'Gemini 2.5 Flash-Lite Preview 06-17',
@@ -528,6 +505,18 @@ const googleChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
+  {
+    contextWindowTokens: 2048 + 8192,
+    displayName: 'Gemma 3n E2B',
+    id: 'gemma-3n-e2b-it',
+    maxOutput: 2048,
+    pricing: {
+      cachedInput: 0,
+      input: 0,
+      output: 0,
+    },
+    type: 'chat',
+  },
   {
     contextWindowTokens: 2048 + 8192,
     displayName: 'Gemma 3n E4B',
diff --git a/src/config/aiModels/groq.ts b/src/config/aiModels/groq.ts
index d65d9fb9cd5ac..838e79c0565d2 100644
--- a/src/config/aiModels/groq.ts
+++ b/src/config/aiModels/groq.ts
@@ -47,22 +47,6 @@ const groqChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
-  {
-    abilities: {
-      functionCall: true,
-      reasoning: true,
-    },
-    contextWindowTokens: 131_072,
-    displayName: 'Qwen QwQ 32B',
-    enabled: true,
-    id: 'qwen-qwq-32b',
-    maxOutput: 131_072,
-    pricing: {
-      input: 0.29,
-      output: 0.39,
-    },
-    type: 'chat',
-  },
   {
     abilities: {
       reasoning: true,
diff --git a/src/config/aiModels/hunyuan.ts b/src/config/aiModels/hunyuan.ts
index b2b17893b9ce7..431f54c7d8ebc 100644
--- a/src/config/aiModels/hunyuan.ts
+++ b/src/config/aiModels/hunyuan.ts
@@ -2,6 +2,25 @@ import { AIChatModelCard } from '@/types/aiModel';
 
 // https://cloud.tencent.com/document/product/1729/104753
 const hunyuanChatModels: AIChatModelCard[] = [
+  {
+    abilities: {
+      reasoning: true,
+      search: true,
+    },
+    contextWindowTokens: 256_000,
+    description:
+      '混元第一个混合推理模型，hunyuan-standard-256K 的升级版本，总参数80B，激活13B，默认是慢思考模式，支持通过参数或者指令进行快慢思考模式切换，慢快思考切换方式为 query 前加/ no_think；整体能力相对上一代全面提升，特别数学、科学、长文理解和 Agent 能力提升显著。',
+    displayName: 'Hunyuan A13B',
+    enabled: true,
+    id: 'hunyuan-a13b',
+    maxOutput: 32_000,
+    releasedAt: '2025-06-25',
+    settings: {
+      extendParams: ['enableReasoning'],
+      searchImpl: 'params',
+    },
+    type: 'chat',
+  },
   {
     abilities: {
       reasoning: true,
@@ -366,7 +385,6 @@ const hunyuanChatModels: AIChatModelCard[] = [
     contextWindowTokens: 8000,
     description: '混元最新多模态模型，支持多语种作答，中英文能力均衡。',
     displayName: 'Hunyuan Standard Vision',
-    enabled: true,
     id: 'hunyuan-standard-vision',
     maxOutput: 2000,
     releasedAt: '2024-12-31',
@@ -403,6 +421,25 @@ const hunyuanChatModels: AIChatModelCard[] = [
     releasedAt: '2025-05-26',
     type: 'chat',
   },
+  {
+    abilities: {
+      reasoning: true,
+      vision: true,
+    },
+    contextWindowTokens: 40_000,
+    description:
+      '混元最新版t1-vision多模态理解深度思考模型，支持多模态原生长思维链，相比上一代默认版本模型全面提升。',
+    displayName: 'Hunyuan T1 Vision 20250619',
+    id: 'hunyuan-t1-vision-20250619',
+    maxOutput: 24_000,
+    pricing: {
+      currency: 'CNY',
+      input: 1,
+      output: 4,
+    },
+    releasedAt: '2025-06-19',
+    type: 'chat',
+  },
   {
     abilities: {
       reasoning: true,
@@ -414,9 +451,50 @@ const hunyuanChatModels: AIChatModelCard[] = [
     displayName: 'Hunyuan T1 Vision',
     id: 'hunyuan-t1-vision',
     maxOutput: 24_000,
+    pricing: {
+      currency: 'CNY',
+      input: 1,
+      output: 4,
+    },
     releasedAt: '2025-05-16',
     type: 'chat',
   },
+  {
+    abilities: {
+      vision: true,
+    },
+    contextWindowTokens: 32_000,
+    description:
+      '混元最新版turbos-vision视觉语言旗舰大模型，在图文理解相关的任务上，包括基于图片的实体识别、知识问答、文案创作、拍照解题等上面相比上一代默认版本模型全面提升。',
+    displayName: 'Hunyuan TurboS Vision 20250619',
+    id: 'hunyuan-turbos-vision-20250619',
+    maxOutput: 16_000,
+    pricing: {
+      currency: 'CNY',
+      input: 3,
+      output: 9,
+    },
+    releasedAt: '2025-06-19',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      vision: true,
+    },
+    contextWindowTokens: 32_000,
+    description:
+      '此模型适用于图文理解场景，是基于混元最新 turbos 的新一代视觉语言旗舰大模型，聚焦图文理解相关任务，包括基于图片的实体识别、知识问答、文案创作、拍照解题等方面，相比前一代模型全面提升。',
+    displayName: 'Hunyuan TurboS Vision',
+    id: 'hunyuan-turbos-vision',
+    maxOutput: 24_000,
+    pricing: {
+      currency: 'CNY',
+      input: 3,
+      output: 9,
+    },
+    releasedAt: '2025-05-23',
+    type: 'chat',
+  },
   {
     abilities: {
       vision: true,
diff --git a/src/config/aiModels/novita.ts b/src/config/aiModels/novita.ts
index 9b16c6a9a5341..c5d38739d6cc8 100644
--- a/src/config/aiModels/novita.ts
+++ b/src/config/aiModels/novita.ts
@@ -2,6 +2,20 @@ import { AIChatModelCard } from '@/types/aiModel';
 
 // https://novita.ai/pricing
 const novitaChatModels: AIChatModelCard[] = [
+  {
+    abilities: {
+      reasoning: true,
+      vision: true,
+    },
+    contextWindowTokens: 65_536,
+    displayName: 'GLM 4.1V 9B Thinking',
+    id: 'thudm/glm-4.1v-9b-thinking',
+    pricing: {
+      input: 0.035,
+      output: 0.138,
+    },
+    type: 'chat',
+  },
   {
     contextWindowTokens: 120_000,
     displayName: 'ERNIE 4.5 0.3B',
@@ -27,8 +41,8 @@ const novitaChatModels: AIChatModelCard[] = [
     displayName: 'ERNIE 4.5 300B A47B Paddle',
     id: 'baidu/ernie-4.5-300b-a47b-paddle',
     pricing: {
-      input: 0.3,
-      output: 1,
+      input: 0.28,
+      output: 1.1,
     },
     type: 'chat',
   },
@@ -64,7 +78,7 @@ const novitaChatModels: AIChatModelCard[] = [
     abilities: {
       reasoning: true,
     },
-    contextWindowTokens: 128_000,
+    contextWindowTokens: 1_000_000,
     displayName: 'MiniMax M1 80K',
     id: 'minimaxai/minimax-m1-80k',
     pricing: {
@@ -220,6 +234,17 @@ const novitaChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
+  {
+    contextWindowTokens: 32_768,
+    description: 'Gemma 3 1B 是谷歌的一款开源语言模型，以其在效率和性能方面设立了新的标准。',
+    displayName: 'Gemma 3 1B',
+    id: 'google/gemma-3-1b-it',
+    pricing: {
+      input: 0,
+      output: 0,
+    },
+    type: 'chat',
+  },
   {
     contextWindowTokens: 60_288,
     description: 'Mistral Nemo 是多语言支持和高性能编程的7.3B参数模型。',
@@ -318,8 +343,8 @@ const novitaChatModels: AIChatModelCard[] = [
     enabled: true,
     id: 'deepseek/deepseek-v3-0324',
     pricing: {
-      input: 0.33,
-      output: 1.3,
+      input: 0.28,
+      output: 1.14,
     },
     type: 'chat',
   },
@@ -537,45 +562,6 @@ const novitaChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
-  {
-    abilities: {
-      functionCall: true,
-    },
-    contextWindowTokens: 32_000,
-    displayName: 'GLM 4 9B 0414',
-    id: 'thudm/glm-4-9b-0414',
-    pricing: {
-      input: 0,
-      output: 0,
-    },
-    type: 'chat',
-  },
-  {
-    abilities: {
-      functionCall: true,
-    },
-    contextWindowTokens: 32_000,
-    displayName: 'GLM Z1 9B 0414',
-    id: 'thudm/glm-z1-9b-0414',
-    pricing: {
-      input: 0,
-      output: 0,
-    },
-    type: 'chat',
-  },
-  {
-    abilities: {
-      functionCall: true,
-    },
-    contextWindowTokens: 32_000,
-    displayName: 'GLM Z1 32B 0414',
-    id: 'thudm/glm-z1-32b-0414',
-    pricing: {
-      input: 0.24,
-      output: 0.24,
-    },
-    type: 'chat',
-  },
   {
     abilities: {
       functionCall: true,
@@ -589,19 +575,6 @@ const novitaChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
-  {
-    abilities: {
-      functionCall: true,
-    },
-    contextWindowTokens: 32_000,
-    displayName: 'GLM Z1 Rumination 32B 0414',
-    id: 'thudm/glm-z1-rumination-32b-0414',
-    pricing: {
-      input: 0.24,
-      output: 0.24,
-    },
-    type: 'chat',
-  },
 ];
 
 export const allModels = [...novitaChatModels];
diff --git a/src/config/aiModels/qwen.ts b/src/config/aiModels/qwen.ts
index 9158c963349bc..4ffb387343c1e 100644
--- a/src/config/aiModels/qwen.ts
+++ b/src/config/aiModels/qwen.ts
@@ -18,8 +18,8 @@ const qwenChatModels: AIChatModelCard[] = [
     organization: 'Qwen',
     pricing: {
       currency: 'CNY',
-      input: 4,
-      output: 40, // Thinking mode pricing
+      input: 2,
+      output: 20, // Thinking mode pricing
     },
     releasedAt: '2025-04-28',
     settings: {
@@ -36,7 +36,6 @@ const qwenChatModels: AIChatModelCard[] = [
     description:
       'Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。',
     displayName: 'Qwen3 32B',
-    enabled: true,
     id: 'qwen3-32b',
     maxOutput: 8192,
     organization: 'Qwen',
@@ -66,8 +65,8 @@ const qwenChatModels: AIChatModelCard[] = [
     organization: 'Qwen',
     pricing: {
       currency: 'CNY',
-      input: 1.5,
-      output: 15, // Thinking mode pricing
+      input: 0.75,
+      output: 7.5, // Thinking mode pricing
     },
     releasedAt: '2025-04-28',
     settings: {
@@ -203,7 +202,6 @@ const qwenChatModels: AIChatModelCard[] = [
     description:
       '基于 Qwen2.5 模型训练的 QwQ 推理模型，通过强化学习大幅度提升了模型推理能力。模型数学代码等核心指标（AIME 24/25、LiveCodeBench）以及部分通用指标（IFEval、LiveBench等）达到DeepSeek-R1 满血版水平。',
     displayName: 'QwQ Plus',
-    enabled: true,
     id: 'qwq-plus',
     maxOutput: 8192,
     organization: 'Qwen',
@@ -237,7 +235,7 @@ const qwenChatModels: AIChatModelCard[] = [
     pricing: {
       currency: 'CNY',
       input: 0.3,
-      output: 6, // Thinking mode pricing
+      output: 3, // Thinking mode pricing
     },
     releasedAt: '2025-04-28',
     settings: {
@@ -265,7 +263,7 @@ const qwenChatModels: AIChatModelCard[] = [
     pricing: {
       currency: 'CNY',
       input: 0.8,
-      output: 16, // Thinking mode pricing
+      output: 8, // Thinking mode pricing
     },
     releasedAt: '2025-04-28',
     settings: {
@@ -311,7 +309,6 @@ const qwenChatModels: AIChatModelCard[] = [
     description:
       '通义千问超大规模语言模型，支持长文本上下文，以及基于长文档、多文档等多个场景的对话功能。',
     displayName: 'Qwen Long',
-    enabled: true,
     id: 'qwen-long',
     maxOutput: 8192,
     organization: 'Qwen',
@@ -327,7 +324,7 @@ const qwenChatModels: AIChatModelCard[] = [
       vision: true,
     },
     config: {
-      deploymentName: 'qwen-omni-turbo-latest',
+      deploymentName: 'qwen-omni-turbo-latest', // expired on 2025-08-13
     },
     contextWindowTokens: 32_768,
     description:
@@ -357,7 +354,7 @@ const qwenChatModels: AIChatModelCard[] = [
     organization: 'Qwen',
     pricing: {
       currency: 'CNY',
-      input: 0.6,
+      input: 2, // use image input price
       output: 6,
     },
     type: 'chat',
@@ -818,12 +815,12 @@ const qwenChatModels: AIChatModelCard[] = [
     abilities: {
       reasoning: true,
     },
-    contextWindowTokens: 65_536,
+    contextWindowTokens: 131_072,
     description:
       '685B 满血版模型，2025年5月28日发布。DeepSeek-R1 在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能较高，能力较强。',
     displayName: 'DeepSeek R1 0528',
     id: 'deepseek-r1-0528',
-    maxOutput: 8192,
+    maxOutput: 16_384,
     organization: 'DeepSeek',
     pricing: {
       currency: 'CNY',
@@ -833,25 +830,6 @@ const qwenChatModels: AIChatModelCard[] = [
     releasedAt: '2025-05-28',
     type: 'chat',
   },
-  {
-    abilities: {
-      reasoning: true,
-    },
-    contextWindowTokens: 65_536,
-    description:
-      '671B 满血版模型，2025年1月20日发布。DeepSeek-R1 在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能较高，能力较强。',
-    displayName: 'DeepSeek R1',
-    id: 'deepseek-r1',
-    maxOutput: 8192,
-    organization: 'DeepSeek',
-    pricing: {
-      currency: 'CNY',
-      input: 4,
-      output: 16,
-    },
-    releasedAt: '2025-01-27',
-    type: 'chat',
-  },
   {
     contextWindowTokens: 65_536,
     description:
diff --git a/src/config/aiModels/siliconcloud.ts b/src/config/aiModels/siliconcloud.ts
index 226c87db74dba..261f708f7d827 100644
--- a/src/config/aiModels/siliconcloud.ts
+++ b/src/config/aiModels/siliconcloud.ts
@@ -2,6 +2,37 @@ import { AIChatModelCard } from '@/types/aiModel';
 
 // https://siliconflow.cn/zh-cn/models
 const siliconcloudChatModels: AIChatModelCard[] = [
+  {
+    abilities: {
+      reasoning: true,
+    },
+    contextWindowTokens: 131_072,
+    description:
+      'Pangu-Pro-MoE 72B-A16B 是一款 720 亿参数、激活 160 亿参的稀疏大语言模型，它基于分组混合专家（MoGE）架构，它在专家选择阶段对专家进行分组，并约束 token 在每个组内激活等量专家，从而实现专家负载均衡，显著提升模型在昇腾平台的部署效率。',
+    displayName: 'Pangu Pro MoE 72B A16B',
+    id: 'ascend-tribe/pangu-pro-moe',
+    pricing: {
+      currency: 'CNY',
+      input: 1,
+      output: 4,
+    },
+    releasedAt: '2025-06-17',
+    type: 'chat',
+  },
+  {
+    contextWindowTokens: 131_072,
+    description:
+      'ERNIE-4.5-300B-A47B 是由百度公司开发的一款基于混合专家（MoE）架构的大语言模型。该模型总参数量为 3000 亿，但在推理时每个 token 仅激活 470 亿参数，从而在保证强大性能的同时兼顾了计算效率。作为 ERNIE 4.5 系列的核心模型之一，在文本理解、生成、推理和编程等任务上展现出卓越的能力。该模型采用了一种创新的多模态异构 MoE 预训练方法，通过文本与视觉模态的联合训练，有效提升了模型的综合能力，尤其在指令遵循和世界知识记忆方面效果突出。',
+    displayName: 'ERNIE 4.5 300B A47B',
+    id: 'baidu/ERNIE-4.5-300B-A47B',
+    pricing: {
+      currency: 'CNY',
+      input: 2,
+      output: 8,
+    },
+    releasedAt: '2025-06-30',
+    type: 'chat',
+  },
   {
     abilities: {
       reasoning: true,
@@ -166,7 +197,7 @@ const siliconcloudChatModels: AIChatModelCard[] = [
     contextWindowTokens: 131_072,
     description:
       'Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。',
-    displayName: 'Qwen3 8B',
+    displayName: 'Qwen3 8B (Free)',
     enabled: true,
     id: 'Qwen/Qwen3-8B',
     organization: 'Qwen',
@@ -181,6 +212,43 @@ const siliconcloudChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
+  {
+    abilities: {
+      reasoning: true,
+      vision: true,
+    },
+    contextWindowTokens: 65_536,
+    description:
+      'GLM-4.1V-9B-Thinking 是由智谱 AI 和清华大学 KEG 实验室联合发布的一款开源视觉语言模型（VLM），专为处理复杂的多模态认知任务而设计。该模型基于 GLM-4-9B-0414 基础模型，通过引入“思维链”（Chain-of-Thought）推理机制和采用强化学习策略，显著提升了其跨模态的推理能力和稳定性。',
+    displayName: 'GLM-4.1V 9B Thinking (Free)',
+    enabled: true,
+    id: 'THUDM/GLM-4.1V-9B-Thinking',
+    pricing: {
+      currency: 'CNY',
+      input: 0,
+      output: 0,
+    },
+    releasedAt: '2025-07-02',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+      vision: true,
+    },
+    contextWindowTokens: 65_536,
+    description:
+      'GLM-4.1V-9B-Thinking 是由智谱 AI 和清华大学 KEG 实验室联合发布的一款开源视觉语言模型（VLM），专为处理复杂的多模态认知任务而设计。该模型基于 GLM-4-9B-0414 基础模型，通过引入“思维链”（Chain-of-Thought）推理机制和采用强化学习策略，显著提升了其跨模态的推理能力和稳定性。',
+    displayName: 'GLM-4.1V 9B Thinking (Pro)',
+    id: 'Pro/THUDM/GLM-4.1V-9B-Thinking',
+    pricing: {
+      currency: 'CNY',
+      input: 0.25,
+      output: 1,
+    },
+    releasedAt: '2025-07-02',
+    type: 'chat',
+  },
   {
     abilities: {
       reasoning: true,
@@ -195,6 +263,7 @@ const siliconcloudChatModels: AIChatModelCard[] = [
       input: 1,
       output: 4,
     },
+    releasedAt: '2025-04-14',
     type: 'chat',
   },
   {
@@ -212,6 +281,7 @@ const siliconcloudChatModels: AIChatModelCard[] = [
       input: 1,
       output: 4,
     },
+    releasedAt: '2025-04-14',
     type: 'chat',
   },
   {
@@ -222,13 +292,14 @@ const siliconcloudChatModels: AIChatModelCard[] = [
     contextWindowTokens: 131_072,
     description:
       'GLM-Z1-9B-0414 是 GLM 系列的小型模型，仅有 90 亿参数，但保持了开源传统的同时展现出惊人的能力。尽管规模较小，该模型在数学推理和通用任务上仍表现出色，其总体性能在同等规模的开源模型中已处于领先水平。',
-    displayName: 'GLM-Z1 9B 0414',
+    displayName: 'GLM-Z1 9B 0414 (Free)',
     id: 'THUDM/GLM-Z1-9B-0414',
     pricing: {
       currency: 'CNY',
       input: 0,
       output: 0,
     },
+    releasedAt: '2025-04-14',
     type: 'chat',
   },
   {
@@ -245,6 +316,7 @@ const siliconcloudChatModels: AIChatModelCard[] = [
       input: 1.89,
       output: 1.89,
     },
+    releasedAt: '2025-04-14',
     type: 'chat',
   },
   {
@@ -254,14 +326,48 @@ const siliconcloudChatModels: AIChatModelCard[] = [
     contextWindowTokens: 32_768,
     description:
       'GLM-4-9B-0414 是 GLM 系列的小型模型，拥有 90 亿参数。该模型继承了 GLM-4-32B 系列的技术特点，但提供了更轻量级的部署选择。尽管规模较小，GLM-4-9B-0414 仍在代码生成、网页设计、SVG 图形生成和基于搜索的写作等任务上展现出色能力。',
-    displayName: 'GLM-4 9B 0414',
-    enabled: true,
+    displayName: 'GLM-4 9B 0414 (Free)',
     id: 'THUDM/GLM-4-9B-0414',
     pricing: {
       currency: 'CNY',
       input: 0,
       output: 0,
     },
+    releasedAt: '2025-04-14',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      functionCall: true,
+    },
+    contextWindowTokens: 131_072,
+    description:
+      'GLM-4-9B-Chat 是智谱 AI 推出的 GLM-4 系列预训练模型中的开源版本。该模型在语义、数学、推理、代码和知识等多个方面表现出色。除了支持多轮对话外，GLM-4-9B-Chat 还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理等高级功能。模型支持 26 种语言，包括中文、英文、日语、韩语和德语等。在多项基准测试中，GLM-4-9B-Chat 展现了优秀的性能，如 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等。该模型支持最大 128K 的上下文长度，适用于学术研究和商业应用',
+    displayName: 'GLM-4 9B Chat (Free)',
+    id: 'THUDM/glm-4-9b-chat',
+    pricing: {
+      currency: 'CNY',
+      input: 0,
+      output: 0,
+    },
+    releasedAt: '2024-06-04',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      functionCall: true,
+    },
+    contextWindowTokens: 131_072,
+    description:
+      'GLM-4-9B-Chat 是智谱 AI 推出的 GLM-4 系列预训练模型中的开源版本。该模型在语义、数学、推理、代码和知识等多个方面表现出色。除了支持多轮对话外，GLM-4-9B-Chat 还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理等高级功能。模型支持 26 种语言，包括中文、英文、日语、韩语和德语等。在多项基准测试中，GLM-4-9B-Chat 展现了优秀的性能，如 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等。该模型支持最大 128K 的上下文长度，适用于学术研究和商业应用',
+    displayName: 'GLM-4 9B Chat (Pro)',
+    id: 'Pro/THUDM/glm-4-9b-chat',
+    pricing: {
+      currency: 'CNY',
+      input: 0.6,
+      output: 0.6,
+    },
+    releasedAt: '2024-06-04',
     type: 'chat',
   },
   {
@@ -271,7 +377,7 @@ const siliconcloudChatModels: AIChatModelCard[] = [
     contextWindowTokens: 131_072,
     description:
       'DeepSeek-R1-0528-Qwen3-8B 是通过从 DeepSeek-R1-0528 模型蒸馏思维链到 Qwen3 8B Base 获得的模型。该模型在开源模型中达到了最先进（SOTA）的性能，在 AIME 2024 测试中超越了 Qwen3 8B 10%，并达到了 Qwen3-235B-thinking 的性能水平。该模型在数学推理、编程和通用逻辑等多个基准测试中表现出色，其架构与 Qwen3-8B 相同，但共享 DeepSeek-R1-0528 的分词器配置。',
-    displayName: 'DeepSeek R1 0528 Qwen3 8B',
+    displayName: 'DeepSeek R1 0528 Qwen3 8B (Free)',
     enabled: true,
     id: 'deepseek-ai/DeepSeek-R1-0528-Qwen3-8B',
     pricing: {
@@ -331,23 +437,6 @@ const siliconcloudChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
-  {
-    abilities: {
-      functionCall: true,
-      reasoning: true,
-    },
-    contextWindowTokens: 98_304,
-    description:
-      'DeepSeek-R1 是一款强化学习（RL）驱动的推理模型，解决了模型中的重复性和可读性问题。在 RL 之前，DeepSeek-R1 引入了冷启动数据，进一步优化了推理性能。它在数学、代码和推理任务中与 OpenAI-o1 表现相当，并且通过精心设计的训练方法，提升了整体效果。',
-    displayName: 'DeepSeek R1 0120 (Pro)',
-    id: 'Pro/deepseek-ai/DeepSeek-R1-0120',
-    pricing: {
-      currency: 'CNY',
-      input: 4,
-      output: 16,
-    },
-    type: 'chat',
-  },
   {
     abilities: {
       functionCall: true,
@@ -364,22 +453,6 @@ const siliconcloudChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
-  {
-    abilities: {
-      functionCall: true,
-    },
-    contextWindowTokens: 65_536,
-    description:
-      'DeepSeek-V3 是一款拥有 6710 亿参数的混合专家（MoE）语言模型，采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，结合无辅助损失的负载平衡策略，优化推理和训练效率。通过在 14.8 万亿高质量tokens上预训练，并进行监督微调和强化学习，DeepSeek-V3 在性能上超越其他开源模型，接近领先闭源模型。',
-    displayName: 'DeepSeek V3 1226 (Pro)',
-    id: 'Pro/deepseek-ai/DeepSeek-V3-1226',
-    pricing: {
-      currency: 'CNY',
-      input: 2,
-      output: 8,
-    },
-    type: 'chat',
-  },
   {
     abilities: {
       functionCall: true,
@@ -514,22 +587,6 @@ const siliconcloudChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
-  {
-    abilities: {
-      reasoning: true,
-    },
-    contextWindowTokens: 32_768,
-    description:
-      'QwQ-32B-Preview 是 Qwen 最新的实验性研究模型，专注于提升AI推理能力。通过探索语言混合、递归推理等复杂机制，主要优势包括强大的推理分析能力、数学和编程能力。与此同时，也存在语言切换问题、推理循环、安全性考虑、其他能力方面的差异。',
-    displayName: 'QwQ 32B Preview',
-    id: 'Qwen/QwQ-32B-Preview',
-    pricing: {
-      currency: 'CNY',
-      input: 1.26,
-      output: 1.26,
-    },
-    type: 'chat',
-  },
   {
     abilities: {
       functionCall: true,
@@ -771,38 +828,6 @@ const siliconcloudChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
-  {
-    abilities: {
-      functionCall: true,
-    },
-    contextWindowTokens: 131_072,
-    description:
-      'GLM-4-9B-Chat 是智谱 AI 推出的 GLM-4 系列预训练模型中的开源版本。该模型在语义、数学、推理、代码和知识等多个方面表现出色。除了支持多轮对话外，GLM-4-9B-Chat 还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理等高级功能。模型支持 26 种语言，包括中文、英文、日语、韩语和德语等。在多项基准测试中，GLM-4-9B-Chat 展现了优秀的性能，如 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等。该模型支持最大 128K 的上下文长度，适用于学术研究和商业应用',
-    displayName: 'GLM-4 9B Chat (Free)',
-    id: 'THUDM/glm-4-9b-chat',
-    pricing: {
-      currency: 'CNY',
-      input: 0,
-      output: 0,
-    },
-    type: 'chat',
-  },
-  {
-    abilities: {
-      functionCall: true,
-    },
-    contextWindowTokens: 131_072,
-    description:
-      'GLM-4-9B-Chat 是智谱 AI 推出的 GLM-4 系列预训练模型中的开源版本。该模型在语义、数学、推理、代码和知识等多个方面表现出色。除了支持多轮对话外，GLM-4-9B-Chat 还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理等高级功能。模型支持 26 种语言，包括中文、英文、日语、韩语和德语等。在多项基准测试中，GLM-4-9B-Chat 展现了优秀的性能，如 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等。该模型支持最大 128K 的上下文长度，适用于学术研究和商业应用',
-    displayName: 'GLM-4 9B Chat (Pro)',
-    id: 'Pro/THUDM/glm-4-9b-chat',
-    pricing: {
-      currency: 'CNY',
-      input: 0.6,
-      output: 0.6,
-    },
-    type: 'chat',
-  },
 ];
 
 export const allModels = [...siliconcloudChatModels];
diff --git a/src/config/aiModels/zhipu.ts b/src/config/aiModels/zhipu.ts
index fd3c03fab4601..2765c2bc20cf6 100644
--- a/src/config/aiModels/zhipu.ts
+++ b/src/config/aiModels/zhipu.ts
@@ -1,6 +1,47 @@
 import { AIChatModelCard } from '@/types/aiModel';
 
 const zhipuChatModels: AIChatModelCard[] = [
+  {
+    abilities: {
+      reasoning: true,
+      search: true,
+      vision: true,
+    },
+    contextWindowTokens: 64_000,
+    description: 'GLM-4.1V-Thinking 系列模型是目前已知10B级别的VLM模型中性能最强的视觉模型，融合了同级别SOTA的各项视觉语言任务，包括视频理解、图片问答、学科解题、OCR文字识别、文档和图表解读、GUI Agent、前端网页Coding、Grounding等，多项任务能力甚至超过8倍参数量的Qwen2.5-VL-72B。通过领先的强化学习技术，模型掌握了通过思维链推理的方式提升回答的准确性和丰富度，从最终效果和可解释性等维度都显著超过传统的非thinking模型。',
+    displayName: 'GLM-4.1V-Thinking-FlashX',
+    id: 'glm-4.1v-thinking-flashx',
+    pricing: {
+      currency: 'CNY',
+      input: 2,
+      output: 2,
+    },
+    settings: {
+      searchImpl: 'params',
+    },
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+      search: true,
+      vision: true,
+    },
+    contextWindowTokens: 64_000,
+    description: 'GLM-4.1V-Thinking 系列模型是目前已知10B级别的VLM模型中性能最强的视觉模型，融合了同级别SOTA的各项视觉语言任务，包括视频理解、图片问答、学科解题、OCR文字识别、文档和图表解读、GUI Agent、前端网页Coding、Grounding等，多项任务能力甚至超过8倍参数量的Qwen2.5-VL-72B。通过领先的强化学习技术，模型掌握了通过思维链推理的方式提升回答的准确性和丰富度，从最终效果和可解释性等维度都显著超过传统的非thinking模型。',
+    displayName: 'GLM-4.1V-Thinking-Flash',
+    enabled: true,
+    id: 'glm-4.1v-thinking-flash',
+    pricing: {
+      currency: 'CNY',
+      input: 0,
+      output: 0,
+    },
+    settings: {
+      searchImpl: 'params',
+    },
+    type: 'chat',
+  },
   {
     abilities: {
       reasoning: true,
@@ -21,11 +62,11 @@ const zhipuChatModels: AIChatModelCard[] = [
       reasoning: true,
       search: true,
     },
-    contextWindowTokens: 32_000,
+    contextWindowTokens: 128_000,
     description: '推理模型: 具备强大推理能力，适用于需要深度推理的任务。',
     displayName: 'GLM-Z1-Air',
     id: 'glm-z1-air',
-    maxOutput: 30_000,
+    maxOutput: 32_000,
     pricing: {
       currency: 'CNY',
       input: 0.5,
@@ -61,13 +102,34 @@ const zhipuChatModels: AIChatModelCard[] = [
       reasoning: true,
       search: true,
     },
-    contextWindowTokens: 32_000,
+    contextWindowTokens: 128_000,
+    description:
+      '高速低价：Flash增强版本，超快推理速度，更快并发保障。',
+    displayName: 'GLM-Z1-FlashX',
+    id: 'glm-z1-flashx',
+    maxOutput: 32_000,
+    pricing: {
+      currency: 'CNY',
+      input: 0.1,
+      output: 0.1,
+    },
+    settings: {
+      searchImpl: 'params',
+    },
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+      search: true,
+    },
+    contextWindowTokens: 128_000,
     description:
       'GLM-Z1 系列具备强大的复杂推理能力，在逻辑推理、数学、编程等领域表现优异。最大上下文长度为32K。',
     displayName: 'GLM-Z1-Flash',
     enabled: true,
     id: 'glm-z1-flash',
-    maxOutput: 30_000,
+    maxOutput: 32_000,
     pricing: {
       currency: 'CNY',
       input: 0,
@@ -88,7 +150,7 @@ const zhipuChatModels: AIChatModelCard[] = [
     displayName: 'GLM-4-Flash-250414',
     enabled: true,
     id: 'glm-4-flash-250414',
-    maxOutput: 4000,
+    maxOutput: 16_000,
     pricing: {
       currency: 'CNY',
       input: 0,
@@ -106,9 +168,9 @@ const zhipuChatModels: AIChatModelCard[] = [
     },
     contextWindowTokens: 128_000,
     description: 'GLM-4-FlashX 是Flash的增强版本，超快推理速度。',
-    displayName: 'GLM-4-FlashX',
+    displayName: 'GLM-4-FlashX-250414',
     id: 'glm-4-flashx',
-    maxOutput: 4000,
+    maxOutput: 16_000,
     pricing: {
       currency: 'CNY',
       input: 0.1,
@@ -144,11 +206,11 @@ const zhipuChatModels: AIChatModelCard[] = [
       functionCall: true,
       search: true,
     },
-    contextWindowTokens: 32_000,
+    contextWindowTokens: 128_000,
     description: 'GLM-4-Air 是性价比高的版本，性能接近GLM-4，提供快速度和实惠的价格。',
     displayName: 'GLM-4-Air-250414',
     id: 'glm-4-air-250414',
-    maxOutput: 4000,
+    maxOutput: 16_000,
     pricing: {
       currency: 'CNY',
       input: 0.5,
@@ -211,8 +273,8 @@ const zhipuChatModels: AIChatModelCard[] = [
     maxOutput: 4000,
     pricing: {
       currency: 'CNY',
-      input: 50,
-      output: 50,
+      input: 5,
+      output: 5,
     },
     settings: {
       searchImpl: 'params',
@@ -279,7 +341,7 @@ const zhipuChatModels: AIChatModelCard[] = [
     abilities: {
       vision: true,
     },
-    contextWindowTokens: 8192,
+    contextWindowTokens: 16_000,
     description: 'GLM-4V-Plus 具备对视频内容及多图片的理解能力，适合多模态任务。',
     displayName: 'GLM-4V-Plus-0111',
     id: 'glm-4v-plus-0111',
diff --git a/src/config/modelProviders/zhipu.ts b/src/config/modelProviders/zhipu.ts
index a2705e0c5a11e..026ae455a512e 100644
--- a/src/config/modelProviders/zhipu.ts
+++ b/src/config/modelProviders/zhipu.ts
@@ -9,7 +9,6 @@ const ZhiPu: ModelProviderCard = {
       contextWindowTokens: 16_384,
       description: 'GLM-Zero-Preview具备强大的复杂推理能力，在逻辑推理、数学、编程等领域表现优异。',
       displayName: 'GLM-Zero-Preview',
-      enabled: true,
       id: 'glm-zero-preview',
       pricing: {
         currency: 'CNY',
@@ -207,7 +206,7 @@ const ZhiPu: ModelProviderCard = {
       },
     },
   ],
-  checkModel: 'glm-4-flash',
+  checkModel: 'glm-4-flash-250414',
   description:
     '智谱 AI 提供多模态与语言模型的开放平台，支持广泛的AI应用场景，包括文本处理、图像理解与编程辅助等。',
   id: 'zhipu',
diff --git a/src/libs/model-runtime/hunyuan/index.ts b/src/libs/model-runtime/hunyuan/index.ts
index 4f89814b5cc89..0b2106088d8f0 100644
--- a/src/libs/model-runtime/hunyuan/index.ts
+++ b/src/libs/model-runtime/hunyuan/index.ts
@@ -12,11 +12,12 @@ export const LobeHunyuanAI = createOpenAICompatibleRuntime({
   chatCompletion: {
     handlePayload: (payload) => {
       // eslint-disable-next-line unused-imports/no-unused-vars, @typescript-eslint/no-unused-vars
-      const { enabledSearch, frequency_penalty, presence_penalty, ...rest } = payload;
+      const { enabledSearch, frequency_penalty, model, presence_penalty, thinking, ...rest } = payload;
 
       return {
         ...rest,
         frequency_penalty: undefined,
+        model,
         presence_penalty: undefined,
         stream: true,
         ...(enabledSearch && {
@@ -28,6 +29,13 @@ export const LobeHunyuanAI = createOpenAICompatibleRuntime({
           enable_speed_search: process.env.HUNYUAN_ENABLE_SPEED_SEARCH === '1',
           search_info: true,
         }),
+        ...(model === 'hunyuan-a13b' && {
+          enable_thinking: thinking?.type === 'enabled' 
+            ? true 
+            : thinking?.type === 'disabled' 
+              ? false 
+              : undefined
+        }),
       } as any;
     },
   },
