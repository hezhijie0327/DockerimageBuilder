diff --git a/src/config/modelProviders/ai21.ts b/src/config/modelProviders/ai21.ts
index 28dfedcb182d..743a486fa5f8 100644
--- a/src/config/modelProviders/ai21.ts
+++ b/src/config/modelProviders/ai21.ts
@@ -29,12 +29,10 @@ const Ai21: ModelProviderCard = {
   checkModel: 'jamba-1.5-mini',
   description: 'AI21 Labs 为企业构建基础模型和人工智能系统，加速生成性人工智能在生产中的应用。',
   id: 'ai21',
-  modelList: { showModelFetcher: true },
   modelsUrl: 'https://docs.ai21.com/reference',
   name: 'Ai21Labs',
   settings: {
     sdkType: 'openai',
-    showModelFetcher: true,
   },
   url: 'https://studio.ai21.com',
 };
diff --git a/src/config/modelProviders/ai360.ts b/src/config/modelProviders/ai360.ts
index b0a8712287c6..d1a686733ad2 100644
--- a/src/config/modelProviders/ai360.ts
+++ b/src/config/modelProviders/ai360.ts
@@ -4,59 +4,55 @@ import { ModelProviderCard } from '@/types/llm';
 const Ai360: ModelProviderCard = {
   chatModels: [
     {
-      contextWindowTokens: 8192,
+      contextWindowTokens: 8000,
       description:
-        '360GPT2 Pro 是 360 公司推出的高级自然语言处理模型，具备卓越的文本生成和理解能力，尤其在生成与创作领域表现出色，能够处理复杂的语言转换和角色演绎任务。',
-      displayName: '360GPT2 Pro',
+        '360gpt2-o1 使用树搜索构建思维链，并引入了反思机制，使用强化学习训练，模型具备自我反思与纠错的能力。',
+      displayName: '360GPT2 o1',
       enabled: true,
-      id: '360gpt2-pro',
-      maxOutput: 7000,
+      id: '360gpt2-o1',
       pricing: {
         currency: 'CNY',
-        input: 5,
-        output: 5,
+        input: 20,
+        output: 50,
       },
     },
     {
-      contextWindowTokens: 8192,
+      contextWindowTokens: 8000,
       description:
-        '360GPT Pro 作为 360 AI 模型系列的重要成员，以高效的文本处理能力满足多样化的自然语言应用场景，支持长文本理解和多轮对话等功能。',
-      displayName: '360GPT Pro',
+        '360智脑系列效果最好的主力千亿级大模型，广泛适用于各领域复杂任务场景。',
+      displayName: '360GPT2 Pro',
       enabled: true,
-      functionCall: true,
-      id: '360gpt-pro',
-      maxOutput: 7000,
+      id: '360gpt2-pro',
       pricing: {
         currency: 'CNY',
-        input: 5,
+        input: 2,
         output: 5,
       },
     },
     {
-      contextWindowTokens: 8192,
+      contextWindowTokens: 8000,
       description:
-        '360GPT Turbo 提供强大的计算和对话能力，具备出色的语义理解和生成效率，是企业和开发者理想的智能助理解决方案。',
-      displayName: '360GPT Turbo',
+        '360智脑系列效果最好的主力千亿级大模型，广泛适用于各领域复杂任务场景。',
+      displayName: '360GPT Pro',
       enabled: true,
-      id: '360gpt-turbo',
-      maxOutput: 7000,
+      functionCall: true,
+      id: '360gpt-pro',
       pricing: {
         currency: 'CNY',
         input: 2,
-        output: 2,
+        output: 5,
       },
     },
     {
-      contextWindowTokens: 8192,
+      contextWindowTokens: 7000,
       description:
-        '360GPT Turbo Responsibility 8K 强调语义安全和责任导向，专为对内容安全有高度要求的应用场景设计，确保用户体验的准确性与稳健性。',
-      displayName: '360GPT Turbo Responsibility 8K',
+        '兼顾性能和效果的百亿级大模型，适合对性能/成本要求较高 的场景。',
+      displayName: '360GPT Turbo',
       enabled: true,
-      id: '360gpt-turbo-responsibility-8k',
-      maxOutput: 2048,
+      id: '360gpt-turbo',
       pricing: {
         currency: 'CNY',
-        input: 2,
+        input: 1,
         output: 2,
       },
     },
diff --git a/src/config/modelProviders/anthropic.ts b/src/config/modelProviders/anthropic.ts
index 0aef41f19ceb..e59a401cff8e 100644
--- a/src/config/modelProviders/anthropic.ts
+++ b/src/config/modelProviders/anthropic.ts
@@ -142,7 +142,6 @@ const Anthropic: ModelProviderCard = {
       placeholder: 'https://api.anthropic.com',
     },
     sdkType: 'anthropic',
-    showModelFetcher: true,
     smoothing: {
       speed: 5,
       text: true,
diff --git a/src/config/modelProviders/baichuan.ts b/src/config/modelProviders/baichuan.ts
index ce218da96c20..abd9055b3356 100644
--- a/src/config/modelProviders/baichuan.ts
+++ b/src/config/modelProviders/baichuan.ts
@@ -93,12 +93,10 @@ const Baichuan: ModelProviderCard = {
   description:
     '百川智能是一家专注于人工智能大模型研发的公司，其模型在国内知识百科、长文本处理和生成创作等中文任务上表现卓越，超越了国外主流模型。百川智能还具备行业领先的多模态能力，在多项权威评测中表现优异。其模型包括 Baichuan 4、Baichuan 3 Turbo 和 Baichuan 3 Turbo 128k 等，分别针对不同应用场景进行优化，提供高性价比的解决方案。',
   id: 'baichuan',
-  modelList: { showModelFetcher: true },
   modelsUrl: 'https://platform.baichuan-ai.com/price',
   name: 'Baichuan',
   settings: {
     sdkType: 'openai',
-    showModelFetcher: true,
     smoothing: {
       speed: 2,
       text: true,
diff --git a/src/config/modelProviders/fireworksai.ts b/src/config/modelProviders/fireworksai.ts
index 615efb69c41a..41bb6e30ab14 100644
--- a/src/config/modelProviders/fireworksai.ts
+++ b/src/config/modelProviders/fireworksai.ts
@@ -215,12 +215,10 @@ const FireworksAI: ModelProviderCard = {
   description:
     'Fireworks AI 是一家领先的高级语言模型服务商，专注于功能调用和多模态处理。其最新模型 Firefunction V2 基于 Llama-3，优化用于函数调用、对话及指令跟随。视觉语言模型 FireLLaVA-13B 支持图像和文本混合输入。其他 notable 模型包括 Llama 系列和 Mixtral 系列，提供高效的多语言指令跟随与生成支持。',
   id: 'fireworksai',
-  modelList: { showModelFetcher: true },
   modelsUrl: 'https://fireworks.ai/models?show=Serverless',
   name: 'Fireworks AI',
   settings: {
     sdkType: 'openai',
-    showModelFetcher: true,
   },
   url: 'https://fireworks.ai',
 };
diff --git a/src/config/modelProviders/giteeai.ts b/src/config/modelProviders/giteeai.ts
index dde54eedc4c0..224287c4c301 100644
--- a/src/config/modelProviders/giteeai.ts
+++ b/src/config/modelProviders/giteeai.ts
@@ -6,28 +6,14 @@ const GiteeAI: ModelProviderCard = {
     {
       contextWindowTokens: 16_000,
       description:
-        'Qwen2.5-72B-Instruct 支持 16k 上下文, 生成长文本超过 8K 。支持 function call 与外部系统无缝交互，极大提升了灵活性和扩展性。模型知识明显增加，并且大大提高了编码和数学能力, 多语言支持超过 29 种',
+        'Qwen2.5-72B-Instruct  支持 16k 上下文, 生成长文本超过 8K 。支持 function call 与外部系统无缝交互，极大提升了灵活性和扩展性。模型知识明显增加，并且大大提高了编码和数学能力, 多语言支持超过 29 种',
       displayName: 'Qwen2.5 72B Instruct',
       enabled: true,
       functionCall: true,
       id: 'Qwen2.5-72B-Instruct',
     },
     {
-      description:
-        'Qwen2.5-Coder-32B-Instruct 是一款专为代码生成、代码理解和高效开发场景设计的大型语言模型，采用了业界领先的32B参数规模，能够满足多样化的编程需求。',
-      displayName: 'Qwen2.5 Coder 32B Instruct',
-      enabled: true,
-      id: 'Qwen2.5-Coder-32B-Instruct',
-    },
-    {
-      description:
-        'Qwen2.5-7B-Instruct 是一款 70 亿参数的大语言模型，支持 function call 与外部系统无缝交互，极大提升了灵活性和扩展性。优化中文和多语言场景，支持智能问答、内容生成等应用。',
-      displayName: 'Qwen2.5 7B Instruct',
-      enabled: true,
-      functionCall: true,
-      id: 'Qwen2.5-7B-Instruct',
-    },
-    {
+      contextWindowTokens: 32_000,
       description:
         'Qwen2.5-32B-Instruct 是一款 320 亿参数的大语言模型，性能表现均衡，优化中文和多语言场景，支持智能问答、内容生成等应用。',
       displayName: 'Qwen2.5 32B Instruct',
@@ -35,6 +21,7 @@ const GiteeAI: ModelProviderCard = {
       id: 'Qwen2.5-32B-Instruct',
     },
     {
+      contextWindowTokens: 24_000,
       description:
         'Qwen2.5-14B-Instruct 是一款 140 亿参数的大语言模型，性能表现优秀，优化中文和多语言场景，支持智能问答、内容生成等应用。',
       displayName: 'Qwen2.5 14B Instruct',
@@ -42,35 +29,71 @@ const GiteeAI: ModelProviderCard = {
       id: 'Qwen2.5-14B-Instruct',
     },
     {
-      contextWindowTokens: 6000,
+      contextWindowTokens: 32_000,
       description:
-        'Qwen2 是 Qwen 模型的最新系列，支持 128k 上下文，对比当前最优的开源模型，Qwen2-72B 在自然语言理解、知识、代码、数学及多语言等多项能力上均显著超越当前领先的模型。',
+        'Qwen2.5-7B-Instruct 是一款 70 亿参数的大语言模型，支持 function call 与外部系统无缝交互，极大提升了灵活性和扩展性。优化中文和多语言场景，支持智能问答、内容生成等应用。',
+      displayName: 'Qwen2.5 7B Instruct',
+      enabled: true,
+      functionCall: true,
+      id: 'Qwen2.5-7B-Instruct',
+    },
+    {
+      contextWindowTokens: 32_000,
+      description:
+        'Qwen2 是 Qwen 模型的最新系列，对比当前最优的开源模型，Qwen2-72B 在自然语言理解、知识、代码、数学及多语言等多项能力上均显著超越当前领先的模型。',
       displayName: 'Qwen2 72B Instruct',
       id: 'Qwen2-72B-Instruct',
     },
     {
-      contextWindowTokens: 32_000,
+      contextWindowTokens: 24_000,
       description:
         'Qwen2 是 Qwen 模型的最新系列，能够超越同等规模的最优开源模型甚至更大规模的模型，Qwen2 7B 在多个评测上取得显著的优势，尤其是代码及中文理解上。',
       displayName: 'Qwen2 7B Instruct',
       id: 'Qwen2-7B-Instruct',
     },
     {
+      contextWindowTokens: 32_000,
       description:
-        'InternVL2-8B 是一款强大的视觉语言模型，支持图像与文本的多模态处理，能够精确识别图像内容并生成相关描述或回答。',
-      displayName: 'InternVL2 8B',
+        'Qwen2.5-Coder-32B-Instruct 是一款专为代码生成、代码理解和高效开发场景设计的大型语言模型，采用了业界领先的32B参数规模，能够满足多样化的编程需求。',
+      displayName: 'Qwen2.5 Coder 32B Instruct',
       enabled: true,
-      id: 'InternVL2-8B',
+      id: 'Qwen2.5-Coder-32B-Instruct',
+    },
+    {
+      contextWindowTokens: 24_000,
+      description:
+        'Qwen2.5-Coder-14B-Instruct 是一款基于大规模预训练的编程指令模型，具备强大的代码理解和生成能力，能够高效地处理各种编程任务，特别适合智能代码编写、自动化脚本生成和编程问题解答。',
+      displayName: 'Qwen2.5 Coder 14B Instruct',
+      enabled: true,
+      id: 'Qwen2.5-Coder-14B-Instruct',
+    },
+    {
+      contextWindowTokens: 32_000,
+      description:
+        'Qwen2-VL-72B是一款强大的视觉语言模型，支持图像与文本的多模态处理，能够精确识别图像内容并生成相关描述或回答。',
+      displayName: 'Qwen2 VL 72B',
+      enabled: true,
+      id: 'Qwen2-VL-72B',
       vision: true,
     },
     {
+      contextWindowTokens: 32_000,
       description:
-        'InternVL2.5-26B 是一款强大的视觉语言模型，支持图像与文本的多模态处理，能够精确识别图像内容并生成相关描述或回答。',
+        'InternVL2.5-26B是一款强大的视觉语言模型，支持图像与文本的多模态处理，能够精确识别图像内容并生成相关描述或回答。',
       displayName: 'InternVL2.5 26B',
       enabled: true,
       id: 'InternVL2.5-26B',
       vision: true,
     },
+    {
+      contextWindowTokens: 32_000,
+      description:
+        'InternVL2-8B 是一款强大的视觉语言模型，支持图像与文本的多模态处理，能够精确识别图像内容并生成相关描述或回答。',
+      displayName: 'InternVL2 8B',
+      enabled: true,
+      id: 'InternVL2-8B',
+      vision: true,
+    },
     {
       contextWindowTokens: 32_000,
       description:
@@ -82,28 +105,31 @@ const GiteeAI: ModelProviderCard = {
     {
       contextWindowTokens: 4000,
       description:
-        'Yi-1.5-34B 在保持原系列模型优秀的通用语言能力的前提下，通过增量训练 5 千亿高质量 token，大幅提高了数学逻辑、代码能力。',
+        'Yi-1.5-34B-Chat 在保持原系列模型优秀的通用语言能力的前提下，通过增量训练 5 千亿高质量 token，大幅提高了数学逻辑、代码能力。',
       displayName: 'Yi 34B Chat',
       enabled: true,
       id: 'Yi-34B-Chat',
     },
+/*
+    // not compatible with OpenAI SDK
     {
-      contextWindowTokens: 8000,
       description:
-        'DeepSeek Coder 33B 是一个代码语言模型， 基于 2 万亿数据训练而成，其中 87% 为代码， 13% 为中英文语言。模型引入 16K 窗口大小和填空任务，提供项目级别的代码补全和片段填充功能。',
-      displayName: 'DeepSeek Coder 33B Instruct',
+        '代码小浣熊是基于商汤大语言模型的软件智能研发助手，覆盖软件需求分析、架构设计、代码编写、软件测试等环节，满足用户代码编写、编程学习等各类需求。代码小浣熊支持 Python、Java、JavaScript、C++、Go、SQL 等 90+主流编程语言和 VS Code、IntelliJ IDEA 等主流 IDE。在实际应用中，代码小浣熊可帮助开发者提升编程效率超 50%。',
+      displayName: 'Code Raccoon v1',
       enabled: true,
-      id: 'deepseek-coder-33B-instruct',
+      id: 'code-raccoon-v1',
     },
+*/
     {
+      contextWindowTokens: 8000,
       description:
-        '代码小浣熊是基于商汤大语言模型的软件智能研发助手，覆盖软件需求分析、架构设计、代码编写、软件测试等环节，满足用户代码编写、编程学习等各类需求。代码小浣熊支持 Python、Java、JavaScript、C++、Go、SQL 等 90+主流编程语言和 VS Code、IntelliJ IDEA 等主流 IDE。在实际应用中，代码小浣熊可帮助开发者提升编程效率超 50%。',
-      displayName: 'code raccoon v1',
+        'DeepSeek Coder 33B 是一个代码语言模型， 基于 2 万亿数据训练而成，其中 87% 为代码， 13% 为中英文语言。模型引入 16K 窗口大小和填空任务，提供项目级别的代码补全和片段填充功能。',
+      displayName: 'DeepSeek Coder 33B Instruct',
       enabled: true,
-      id: 'code-raccoon-v1',
+      id: 'deepseek-coder-33B-instruct',
     },
     {
-      contextWindowTokens: 40_000,
+      contextWindowTokens: 32_000,
       description:
         'CodeGeeX4-ALL-9B 是一个多语言代码生成模型，支持包括代码补全和生成、代码解释器、网络搜索、函数调用、仓库级代码问答在内的全面功能，覆盖软件开发的各种场景。是参数少于 10B 的顶尖代码生成模型。',
       displayName: 'CodeGeeX4 All 9B',
@@ -115,13 +141,11 @@ const GiteeAI: ModelProviderCard = {
   description: 'Gitee AI 的 Serverless API 为 AI 开发者提供开箱即用的大模型推理 API 服务。',
   disableBrowserRequest: true,
   id: 'giteeai',
-  modelList: { showModelFetcher: true },
   modelsUrl: 'https://ai.gitee.com/docs/openapi/v1#tag/serverless/POST/chat/completions',
   name: 'Gitee AI',
   settings: {
     disableBrowserRequest: true,
     sdkType: 'openai',
-    showModelFetcher: true,
   },
   url: 'https://ai.gitee.com',
 };
diff --git a/src/config/modelProviders/huggingface.ts b/src/config/modelProviders/huggingface.ts
index ace8370720c0..cba039ac7414 100644
--- a/src/config/modelProviders/huggingface.ts
+++ b/src/config/modelProviders/huggingface.ts
@@ -49,13 +49,11 @@ const HuggingFace: ModelProviderCard = {
     'HuggingFace Inference API 提供了一种快速且免费的方式，让您可以探索成千上万种模型，适用于各种任务。无论您是在为新应用程序进行原型设计，还是在尝试机器学习的功能，这个 API 都能让您即时访问多个领域的高性能模型。',
   disableBrowserRequest: true,
   id: 'huggingface',
-  modelList: { showModelFetcher: true },
   modelsUrl: 'https://huggingface.co/docs/api-inference/en/supported-models',
   name: 'HuggingFace',
   settings: {
     disableBrowserRequest: true,
     sdkType: 'huggingface',
-    showModelFetcher: true,
   },
   url: 'https://huggingface.co',
 };
diff --git a/src/config/modelProviders/hunyuan.ts b/src/config/modelProviders/hunyuan.ts
index 684c385b2894..6581c25e9b02 100644
--- a/src/config/modelProviders/hunyuan.ts
+++ b/src/config/modelProviders/hunyuan.ts
@@ -135,13 +135,11 @@ const Hunyuan: ModelProviderCard = {
     '由腾讯研发的大语言模型，具备强大的中文创作能力，复杂语境下的逻辑推理能力，以及可靠的任务执行能力',
   disableBrowserRequest: true,
   id: 'hunyuan',
-  modelList: { showModelFetcher: true },
   modelsUrl: 'https://cloud.tencent.com/document/product/1729/104753',
   name: 'Hunyuan',
   settings: {
     disableBrowserRequest: true,
     sdkType: 'openai',
-    showModelFetcher: true,
   },
   url: 'https://hunyuan.tencent.com',
 };
diff --git a/src/config/modelProviders/moonshot.ts b/src/config/modelProviders/moonshot.ts
index 7fbeaa9fa735..272eaebbbbf0 100644
--- a/src/config/modelProviders/moonshot.ts
+++ b/src/config/modelProviders/moonshot.ts
@@ -35,6 +35,7 @@ const Moonshot: ModelProviderCard = {
   description:
     'Moonshot 是由北京月之暗面科技有限公司推出的开源平台，提供多种自然语言处理模型，应用领域广泛，包括但不限于内容创作、学术研究、智能推荐、医疗诊断等，支持长文本处理和复杂生成任务。',
   id: 'moonshot',
+  modelList: { showModelFetcher: true },
   modelsUrl: 'https://platform.moonshot.cn/docs/intro',
   name: 'Moonshot',
   proxyUrl: {
@@ -45,6 +46,7 @@ const Moonshot: ModelProviderCard = {
       placeholder: 'https://api.moonshot.cn/v1',
     },
     sdkType: 'openai',
+    showModelFetcher: true,
     smoothing: {
       speed: 2,
       text: true,
diff --git a/src/config/modelProviders/sensenova.ts b/src/config/modelProviders/sensenova.ts
index c755262ce9d1..d0cfc610f5a9 100644
--- a/src/config/modelProviders/sensenova.ts
+++ b/src/config/modelProviders/sensenova.ts
@@ -121,13 +121,11 @@ const SenseNova: ModelProviderCard = {
   description: '商汤日日新，依托商汤大装置的强大的基础支撑，提供高效易用的全栈大模型服务。',
   disableBrowserRequest: true,
   id: 'sensenova',
-  modelList: { showModelFetcher: true },
   modelsUrl: 'https://platform.sensenova.cn/pricing',
   name: 'SenseNova',
   settings: {
     disableBrowserRequest: true,
     sdkType: 'openai',
-    showModelFetcher: true,
   },
   url: 'https://platform.sensenova.cn/home',
 };
diff --git a/src/config/modelProviders/siliconcloud.ts b/src/config/modelProviders/siliconcloud.ts
index 3116a7359d94..9de8fda0a476 100644
--- a/src/config/modelProviders/siliconcloud.ts
+++ b/src/config/modelProviders/siliconcloud.ts
@@ -592,7 +592,6 @@ const SiliconCloud: ModelProviderCard = {
   checkModel: 'Qwen/Qwen2.5-7B-Instruct',
   description: 'SiliconCloud，基于优秀开源基础模型的高性价比 GenAI 云服务',
   id: 'siliconcloud',
-  modelList: { showModelFetcher: true },
   modelsUrl: 'https://siliconflow.cn/zh-cn/models',
   name: 'SiliconCloud',
   proxyUrl: {
@@ -603,7 +602,6 @@ const SiliconCloud: ModelProviderCard = {
       placeholder: 'https://api.siliconflow.cn/v1',
     },
     sdkType: 'openai',
-    showModelFetcher: true,
   },
   url: 'https://siliconflow.cn/zh-cn/siliconcloud',
 };
diff --git a/src/config/modelProviders/spark.ts b/src/config/modelProviders/spark.ts
index 74ac52e65ddf..f2a53796d339 100644
--- a/src/config/modelProviders/spark.ts
+++ b/src/config/modelProviders/spark.ts
@@ -66,12 +66,10 @@ const Spark: ModelProviderCard = {
   description:
     '科大讯飞星火大模型提供多领域、多语言的强大 AI 能力，利用先进的自然语言处理技术，构建适用于智能硬件、智慧医疗、智慧金融等多种垂直场景的创新应用。',
   id: 'spark',
-  modelList: { showModelFetcher: true },
   modelsUrl: 'https://xinghuo.xfyun.cn/spark',
   name: 'Spark',
   settings: {
     sdkType: 'openai',
-    showModelFetcher: true,
     smoothing: {
       speed: 2,
       text: true,
diff --git a/src/config/modelProviders/taichu.ts b/src/config/modelProviders/taichu.ts
index cdf1359593aa..42d24e301e01 100644
--- a/src/config/modelProviders/taichu.ts
+++ b/src/config/modelProviders/taichu.ts
@@ -5,34 +5,39 @@ const Taichu: ModelProviderCard = {
   chatModels: [
     {
       contextWindowTokens: 32_768,
-      description: 'Taichu 2.0 基于海量高质数据训练，具有更强的文本理解、内容创作、对话问答等能力',
+      description: '基于海量高质数据训练，具有更强的文本理解、内容创作、对话问答等能力',
       displayName: 'Taichu 2.0',
       enabled: true,
       functionCall: true,
       id: 'taichu_llm',
+      pricing: {
+        currency: 'CNY',
+        input: 2,
+        output: 2,
+      },
     },
-    /*
-    // TODO: Not support for now
     {
-      description:
-        'Taichu 2.0V 融合了图像理解、知识迁移、逻辑归因等能力，在图文问答领域表现突出',
+      contextWindowTokens: 4096,
+      description: '融合了图像理解、知识迁移、逻辑归因等能力，在图文问答领域表现突出',
       displayName: 'Taichu 2.0V',
-      id: 'taichu_vqa',
-      tokens: 4096,
+      enabled: true,
+      id: 'taichu2_mm',
+      pricing: {
+        currency: 'CNY',
+        input: 5,
+        output: 5,
+      },
       vision: true,
     },
-*/
   ],
   checkModel: 'taichu_llm',
   description:
     '中科院自动化研究所和武汉人工智能研究院推出新一代多模态大模型，支持多轮问答、文本创作、图像生成、3D理解、信号分析等全面问答任务，拥有更强的认知、理解、创作能力，带来全新互动体验。',
   id: 'taichu',
-  modelList: { showModelFetcher: true },
   modelsUrl: 'https://ai-maas.wair.ac.cn/#/doc',
   name: 'Taichu',
   settings: {
     sdkType: 'openai',
-    showModelFetcher: true,
   },
   url: 'https://ai-maas.wair.ac.cn',
 };
diff --git a/src/config/modelProviders/upstage.ts b/src/config/modelProviders/upstage.ts
index 9ecd018ac7ee..f3ac38b71b48 100644
--- a/src/config/modelProviders/upstage.ts
+++ b/src/config/modelProviders/upstage.ts
@@ -21,7 +21,7 @@ const Upstage: ModelProviderCard = {
       id: 'solar-1-mini-chat-ja',
     },
     {
-      contextWindowTokens: 4096,
+      contextWindowTokens: 32_768,
       description:
         'Solar Pro 是 Upstage 推出的一款高智能LLM，专注于单GPU的指令跟随能力，IFEval得分80以上。目前支持英语，正式版本计划于2024年11月推出，将扩展语言支持和上下文长度。',
       displayName: 'Solar Pro',
@@ -34,12 +34,10 @@ const Upstage: ModelProviderCard = {
   description:
     'Upstage 专注于为各种商业需求开发AI模型，包括 Solar LLM 和文档 AI，旨在实现工作的人造通用智能（AGI）。通过 Chat API 创建简单的对话代理，并支持功能调用、翻译、嵌入以及特定领域应用。',
   id: 'upstage',
-  modelList: { showModelFetcher: true },
   modelsUrl: 'https://developers.upstage.ai/docs/getting-started/models',
   name: 'Upstage',
   settings: {
     sdkType: 'openai',
-    showModelFetcher: true,
   },
   url: 'https://upstage.ai',
 };
diff --git a/src/config/modelProviders/zeroone.ts b/src/config/modelProviders/zeroone.ts
index af3c3e1edba8..e267e503f2eb 100644
--- a/src/config/modelProviders/zeroone.ts
+++ b/src/config/modelProviders/zeroone.ts
@@ -141,9 +141,13 @@ const ZeroOne: ModelProviderCard = {
   description:
     '零一万物致力于推动以人为本的AI 2.0技术革命，旨在通过大语言模型创造巨大的经济和社会价值，并开创新的AI生态与商业模式。',
   id: 'zeroone',
+  modelList: { showModelFetcher: true },
   modelsUrl: 'https://platform.lingyiwanwu.com/docs#模型与计费',
   name: '01.AI',
-  settings: { sdkType: 'openai' },
+  settings: {
+    sdkType: 'openai',
+    showModelFetcher: true,
+  },
   url: 'https://www.lingyiwanwu.com/',
 };
 
diff --git a/src/libs/agent-runtime/ai360/index.ts b/src/libs/agent-runtime/ai360/index.ts
index 175ad951040a..8cc18c87055d 100644
--- a/src/libs/agent-runtime/ai360/index.ts
+++ b/src/libs/agent-runtime/ai360/index.ts
@@ -1,6 +1,14 @@
 import { ModelProvider } from '../types';
 import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
 
+import { LOBE_DEFAULT_MODEL_LIST } from '@/config/modelProviders';
+
+export interface Ai360ModelCard {
+  id: string;
+  max_tokens: number;
+  total_tokens: number;
+}
+
 export const LobeAi360AI = LobeOpenAICompatibleFactory({
   baseURL: 'https://api.360.cn/v1',
   chatCompletion: {
@@ -14,5 +22,21 @@ export const LobeAi360AI = LobeOpenAICompatibleFactory({
   debug: {
     chatCompletion: () => process.env.DEBUG_AI360_CHAT_COMPLETION === '1',
   },
+  models: {
+    transformModel: (m) => {
+      const model = m as unknown as Ai360ModelCard;
+
+      return {
+        contextWindowTokens: model.total_tokens,
+        enabled: LOBE_DEFAULT_MODEL_LIST.find((m) => model.id.endsWith(m.id))?.enabled || false,
+        functionCall: model.id === '360gpt-pro',
+        id: model.id,
+        maxTokens:
+          typeof model.max_tokens === 'number'
+            ? model.max_tokens
+            : undefined,
+      };
+    },
+  },
   provider: ModelProvider.Ai360,
 });
diff --git a/src/libs/agent-runtime/deepseek/index.ts b/src/libs/agent-runtime/deepseek/index.ts
index 9f312cbd28fd..5c29b0a8cf4b 100644
--- a/src/libs/agent-runtime/deepseek/index.ts
+++ b/src/libs/agent-runtime/deepseek/index.ts
@@ -1,10 +1,27 @@
 import { ModelProvider } from '../types';
 import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
 
+import { LOBE_DEFAULT_MODEL_LIST } from '@/config/modelProviders';
+
+export interface DeepSeekModelCard {
+  id: string;
+}
+
 export const LobeDeepSeekAI = LobeOpenAICompatibleFactory({
   baseURL: 'https://api.deepseek.com/v1',
   debug: {
     chatCompletion: () => process.env.DEBUG_DEEPSEEK_CHAT_COMPLETION === '1',
   },
+  models: {
+    transformModel: (m) => {
+      const model = m as unknown as DeepSeekModelCard;
+
+      return {
+        enabled: LOBE_DEFAULT_MODEL_LIST.find((m) => model.id.endsWith(m.id))?.enabled || false,
+        functionCall: true,
+        id: model.id,
+      };
+    },
+  },
   provider: ModelProvider.DeepSeek,
 });
diff --git a/src/libs/agent-runtime/groq/index.ts b/src/libs/agent-runtime/groq/index.ts
index de6700fe7a8a..d890a8f4105e 100644
--- a/src/libs/agent-runtime/groq/index.ts
+++ b/src/libs/agent-runtime/groq/index.ts
@@ -2,6 +2,13 @@ import { AgentRuntimeErrorType } from '../error';
 import { ModelProvider } from '../types';
 import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
 
+import { LOBE_DEFAULT_MODEL_LIST } from '@/config/modelProviders';
+
+export interface GroqModelCard {
+  context_window: number;
+  id: string;
+}
+
 export const LobeGroq = LobeOpenAICompatibleFactory({
   baseURL: 'https://api.groq.com/openai/v1',
   chatCompletion: {
@@ -24,5 +31,27 @@ export const LobeGroq = LobeOpenAICompatibleFactory({
   debug: {
     chatCompletion: () => process.env.DEBUG_GROQ_CHAT_COMPLETION === '1',
   },
+  models: {
+    transformModel: (m) => {
+      const functionCallKeywords = [
+        'tool',
+        'llama-3.3',
+        'llama-3.1',
+        'llama3-',
+        'mixtral-8x7b-32768',
+        'gemma2-9b-it',
+      ];
+
+      const model = m as unknown as GroqModelCard;
+
+      return {
+        contextWindowTokens: model.context_window,
+        enabled: LOBE_DEFAULT_MODEL_LIST.find((m) => model.id.endsWith(m.id))?.enabled || false,
+        functionCall: functionCallKeywords.some(keyword => model.id.includes(keyword)),
+        id: model.id,
+        vision: model.id.includes('vision'),
+      };
+    },
+  },
   provider: ModelProvider.Groq,
 });
diff --git a/src/libs/agent-runtime/internlm/index.ts b/src/libs/agent-runtime/internlm/index.ts
index 3dfaf0edda41..7610da9e3c2d 100644
--- a/src/libs/agent-runtime/internlm/index.ts
+++ b/src/libs/agent-runtime/internlm/index.ts
@@ -1,6 +1,12 @@
 import { ModelProvider } from '../types';
 import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
 
+import { LOBE_DEFAULT_MODEL_LIST } from '@/config/modelProviders';
+
+export interface InternLMModelCard {
+  id: string;
+}
+
 export const LobeInternLMAI = LobeOpenAICompatibleFactory({
   baseURL: 'https://internlm-chat.intern-ai.org.cn/puyu/api/v1',
   chatCompletion: {
@@ -14,5 +20,16 @@ export const LobeInternLMAI = LobeOpenAICompatibleFactory({
   debug: {
     chatCompletion: () => process.env.DEBUG_INTERNLM_CHAT_COMPLETION === '1',
   },
+  models: {
+    transformModel: (m) => {
+      const model = m as unknown as InternLMModelCard;
+
+      return {
+        enabled: LOBE_DEFAULT_MODEL_LIST.find((m) => model.id.endsWith(m.id))?.enabled || false,
+        functionCall: true,
+        id: model.id,
+      };
+    },
+  },
   provider: ModelProvider.InternLM,
 });
diff --git a/src/libs/agent-runtime/moonshot/index.ts b/src/libs/agent-runtime/moonshot/index.ts
index 28c976d9dcf5..9e024190762a 100644
--- a/src/libs/agent-runtime/moonshot/index.ts
+++ b/src/libs/agent-runtime/moonshot/index.ts
@@ -3,6 +3,12 @@ import OpenAI from 'openai';
 import { ChatStreamPayload, ModelProvider } from '../types';
 import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
 
+import { LOBE_DEFAULT_MODEL_LIST } from '@/config/modelProviders';
+
+export interface MoonshotModelCard {
+  id: string;
+}
+
 export const LobeMoonshotAI = LobeOpenAICompatibleFactory({
   baseURL: 'https://api.moonshot.cn/v1',
   chatCompletion: {
@@ -18,5 +24,16 @@ export const LobeMoonshotAI = LobeOpenAICompatibleFactory({
   debug: {
     chatCompletion: () => process.env.DEBUG_MOONSHOT_CHAT_COMPLETION === '1',
   },
+  models: {
+    transformModel: (m) => {
+      const model = m as unknown as MoonshotModelCard;
+
+      return {
+        enabled: LOBE_DEFAULT_MODEL_LIST.find((m) => model.id.endsWith(m.id))?.enabled || false,
+        functionCall: true,
+        id: model.id,
+      };
+    },
+  },
   provider: ModelProvider.Moonshot,
 });
diff --git a/src/libs/agent-runtime/qwen/index.ts b/src/libs/agent-runtime/qwen/index.ts
index b0cc566f5b0b..86ab4e2e24ff 100644
--- a/src/libs/agent-runtime/qwen/index.ts
+++ b/src/libs/agent-runtime/qwen/index.ts
@@ -3,6 +3,12 @@ import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
 
 import { QwenAIStream } from '../utils/streams';
 
+import { LOBE_DEFAULT_MODEL_LIST } from '@/config/modelProviders';
+
+export interface QwenModelCard {
+  id: string;
+}
+
 /*
   QwenLegacyModels: A set of legacy Qwen models that do not support presence_penalty.
   Currently, presence_penalty is only supported on Qwen commercial models and open-source models starting from Qwen 1.5 and later.
@@ -45,6 +51,25 @@ export const LobeQwenAI = LobeOpenAICompatibleFactory({
   },
   debug: {
     chatCompletion: () => process.env.DEBUG_QWEN_CHAT_COMPLETION === '1',
+  },
+    models: {
+    transformModel: (m) => {
+      const functionCallKeywords = [
+        'qwen-max',
+        'qwen-plus',
+        'qwen-turbo',
+        'qwen2.5',
+      ];
+
+      const model = m as unknown as QwenModelCard;
+
+      return {
+        enabled: LOBE_DEFAULT_MODEL_LIST.find((m) => model.id.endsWith(m.id))?.enabled || false,
+        functionCall: functionCallKeywords.some(keyword => model.id.includes(keyword)),
+        id: model.id,
+        vision: model.id.includes('vl'),
+      };
+    },
   },
   provider: ModelProvider.Qwen,
 });
diff --git a/src/libs/agent-runtime/stepfun/index.ts b/src/libs/agent-runtime/stepfun/index.ts
index 4ae98b6fe3c7..52114c5e3a7f 100644
--- a/src/libs/agent-runtime/stepfun/index.ts
+++ b/src/libs/agent-runtime/stepfun/index.ts
@@ -1,6 +1,12 @@
 import { ModelProvider } from '../types';
 import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
 
+import { LOBE_DEFAULT_MODEL_LIST } from '@/config/modelProviders';
+
+export interface StepfunModelCard {
+  id: string;
+}
+
 export const LobeStepfunAI = LobeOpenAICompatibleFactory({
   baseURL: 'https://api.stepfun.com/v1',
   chatCompletion: {
@@ -14,5 +20,17 @@ export const LobeStepfunAI = LobeOpenAICompatibleFactory({
   debug: {
     chatCompletion: () => process.env.DEBUG_STEPFUN_CHAT_COMPLETION === '1',
   },
+  models: {
+    transformModel: (m) => {
+      const model = m as unknown as StepfunModelCard;
+
+      return {
+        enabled: LOBE_DEFAULT_MODEL_LIST.find((m) => model.id.endsWith(m.id))?.enabled || false,
+        functionCall: model.id !== 'step-1.5v-mini',
+        id: model.id,
+        vision: model.id.includes('v'),
+      };
+    },
+  },
   provider: ModelProvider.Stepfun,
 });
diff --git a/src/libs/agent-runtime/xai/index.ts b/src/libs/agent-runtime/xai/index.ts
index ed52caa342b4..8d69170c53e0 100644
--- a/src/libs/agent-runtime/xai/index.ts
+++ b/src/libs/agent-runtime/xai/index.ts
@@ -1,10 +1,28 @@
 import { ModelProvider } from '../types';
 import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
 
+import { LOBE_DEFAULT_MODEL_LIST } from '@/config/modelProviders';
+
+export interface XAIModelCard {
+  id: string;
+}
+
 export const LobeXAI = LobeOpenAICompatibleFactory({
   baseURL: 'https://api.x.ai/v1',
   debug: {
     chatCompletion: () => process.env.DEBUG_XAI_CHAT_COMPLETION === '1',
   },
+  models: {
+    transformModel: (m) => {
+      const model = m as unknown as XAIModelCard;
+
+      return {
+        enabled: LOBE_DEFAULT_MODEL_LIST.find((m) => model.id.endsWith(m.id))?.enabled || false,
+        functionCall: true,
+        id: model.id,
+        vision: model.id.includes('vision'),
+      };
+    },
+  },
   provider: ModelProvider.XAI,
 });
diff --git a/src/libs/agent-runtime/zeroone/index.ts b/src/libs/agent-runtime/zeroone/index.ts
index 18c0f0a9d5d7..a9f1e563b02d 100644
--- a/src/libs/agent-runtime/zeroone/index.ts
+++ b/src/libs/agent-runtime/zeroone/index.ts
@@ -1,11 +1,28 @@
 import { ModelProvider } from '../types';
 import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
 
+import { LOBE_DEFAULT_MODEL_LIST } from '@/config/modelProviders';
+
+export interface ZeroOneModelCard {
+  id: string;
+}
+
 export const LobeZeroOneAI = LobeOpenAICompatibleFactory({
   baseURL: 'https://api.lingyiwanwu.com/v1',
   debug: {
     chatCompletion: () => process.env.DEBUG_ZEROONE_CHAT_COMPLETION === '1',
   },
+  models: {
+    transformModel: (m) => {
+      const model = m as unknown as ZeroOneModelCard;
 
+      return {
+        enabled: LOBE_DEFAULT_MODEL_LIST.find((m) => model.id.endsWith(m.id))?.enabled || false,
+        functionCall: model.id.includes('fc'),
+        id: model.id,
+        vision: model.id.includes('vision'),
+      };
+    },
+  },
   provider: ModelProvider.ZeroOne,
 });
