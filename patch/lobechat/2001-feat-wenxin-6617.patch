diff --git a/src/config/aiModels/wenxin.ts b/src/config/aiModels/wenxin.ts
index cd193788f9e53..431a8e2dc2c77 100644
--- a/src/config/aiModels/wenxin.ts
+++ b/src/config/aiModels/wenxin.ts
@@ -4,6 +4,7 @@ const wenxinChatModels: AIChatModelCard[] = [
   {
     abilities: {
       functionCall: true,
+      search: true,
     },
     contextWindowTokens: 8192,
     description:
@@ -16,11 +17,15 @@ const wenxinChatModels: AIChatModelCard[] = [
       input: 0.8,
       output: 2,
     },
+    settings: {
+      searchImpl: 'params',
+    },
     type: 'chat',
   },
   {
     abilities: {
       functionCall: true,
+      search: true,
     },
     contextWindowTokens: 8192,
     description:
@@ -32,11 +37,15 @@ const wenxinChatModels: AIChatModelCard[] = [
       input: 0.8,
       output: 2,
     },
+    settings: {
+      searchImpl: 'params',
+    },
     type: 'chat',
   },
   {
     abilities: {
       functionCall: true,
+      search: true,
     },
     contextWindowTokens: 128_000,
     description:
@@ -49,11 +58,15 @@ const wenxinChatModels: AIChatModelCard[] = [
       input: 0.8,
       output: 2,
     },
+    settings: {
+      searchImpl: 'params',
+    },
     type: 'chat',
   },
   {
     abilities: {
       functionCall: true,
+      search: true,
     },
     contextWindowTokens: 8192,
     description:
@@ -66,11 +79,15 @@ const wenxinChatModels: AIChatModelCard[] = [
       input: 30,
       output: 90,
     },
+    settings: {
+      searchImpl: 'params',
+    },
     type: 'chat',
   },
   {
     abilities: {
       functionCall: true,
+      search: true,
     },
     contextWindowTokens: 8192,
     description:
@@ -82,11 +99,15 @@ const wenxinChatModels: AIChatModelCard[] = [
       input: 30,
       output: 90,
     },
+    settings: {
+      searchImpl: 'params',
+    },
     type: 'chat',
   },
   {
     abilities: {
       functionCall: true,
+      search: true,
     },
     contextWindowTokens: 8192,
     description:
@@ -99,11 +120,15 @@ const wenxinChatModels: AIChatModelCard[] = [
       input: 20,
       output: 60,
     },
+    settings: {
+      searchImpl: 'params',
+    },
     type: 'chat',
   },
   {
     abilities: {
       functionCall: true,
+      search: true,
     },
     contextWindowTokens: 128_000,
     description:
@@ -116,11 +141,15 @@ const wenxinChatModels: AIChatModelCard[] = [
       input: 20,
       output: 60,
     },
+    settings: {
+      searchImpl: 'params',
+    },
     type: 'chat',
   },
   {
     abilities: {
       functionCall: true,
+      search: true,
     },
     contextWindowTokens: 8192,
     description:
@@ -132,6 +161,9 @@ const wenxinChatModels: AIChatModelCard[] = [
       input: 20,
       output: 60,
     },
+    settings: {
+      searchImpl: 'params',
+    },
     type: 'chat',
   },
   {
diff --git a/src/libs/agent-runtime/wenxin/index.ts b/src/libs/agent-runtime/wenxin/index.ts
index c324e9b9bc695..d84fc8109008c 100644
--- a/src/libs/agent-runtime/wenxin/index.ts
+++ b/src/libs/agent-runtime/wenxin/index.ts
@@ -3,6 +3,18 @@ import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
 
 export const LobeWenxinAI = LobeOpenAICompatibleFactory({
   baseURL: 'https://qianfan.baidubce.com/v2',
+  chatCompletion: {
+    handlePayload: (payload) => {
+      const { enabledSearch, ...rest } = payload;
+
+      return {
+        ...rest,
+        ...(enabledSearch && {
+          web_search: true,
+        }),
+      } as any;
+    },
+  },
   debug: {
     chatCompletion: () => process.env.DEBUG_WENXIN_CHAT_COMPLETION === '1',
   },
