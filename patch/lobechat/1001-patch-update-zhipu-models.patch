diff --git a/src/components/ModelIcon/index.tsx b/src/components/ModelIcon/index.tsx
index 6b528d462568..30dbce5ad637 100644
--- a/src/components/ModelIcon/index.tsx
+++ b/src/components/ModelIcon/index.tsx
@@ -9,6 +9,7 @@ import {
   ByteDance,
   ChatGLM,
   Claude,
+  // CodeGeex,
   Cohere,
   Dbrx,
   DeepSeek,
@@ -50,6 +51,7 @@ const ModelIcon = memo<ModelProviderIconProps>(({ model: originModel, size = 12
   if (model.includes('gpt-3')) return <OpenAI.Avatar size={size} type={'gpt3'} />;
   if (model.includes('gpt-4')) return <OpenAI.Avatar size={size} type={'gpt4'} />;
   if (model.startsWith('glm') || model.includes('chatglm')) return <ChatGLM.Avatar size={size} />;
+  // if (model.startsWith('codegeex')) return <CodeGeeX.Avatar size={size} />;
   if (model.includes('deepseek')) return <DeepSeek.Avatar size={size} />;
   if (model.includes('claude')) return <Claude.Avatar size={size} />;
   if (model.includes('titan')) return <Aws.Avatar size={size} />;
diff --git a/src/components/ModelTag/ModelIcon.tsx b/src/components/ModelTag/ModelIcon.tsx
index e666f77bce50..7b1a70645850 100644
--- a/src/components/ModelTag/ModelIcon.tsx
+++ b/src/components/ModelTag/ModelIcon.tsx
@@ -9,6 +9,7 @@ import {
   ByteDance,
   ChatGLM,
   Claude,
+  // CodeGeeX,
   Cohere,
   Dbrx,
   DeepSeek,
@@ -45,6 +46,7 @@ const ModelIcon = memo<ModelIconProps>(({ model, size = 12 }) => {
   // currently supported models, maybe not in its own provider
   if (model.startsWith('gpt')) return <OpenAI size={size} />;
   if (model.startsWith('glm') || model.includes('chatglm')) return <ChatGLM size={size} />;
+  //if (model.includes('codegeex')) return <CodeGeeX size={size} />;
   if (model.includes('claude')) return <Claude size={size} />;
   if (model.includes('deepseek')) return <DeepSeek size={size} />;
   if (model.includes('titan')) return <Aws size={size} />;
diff --git a/src/config/modelProviders/zhipu.ts b/src/config/modelProviders/zhipu.ts
index d8c1761c3ea0..ba2d0504d469 100644
--- a/src/config/modelProviders/zhipu.ts
+++ b/src/config/modelProviders/zhipu.ts
@@ -2,8 +2,17 @@ import { ModelProviderCard } from '@/types/llm';
 
 // ref https://open.bigmodel.cn/dev/howuse/model
 // api https://open.bigmodel.cn/dev/api#language
+// ref https://open.bigmodel.cn/modelcenter/square
 const ZhiPu: ModelProviderCard = {
   chatModels: [
+    {
+      description: 'GLM-4-AllTools 是专门为支持智能体和相关任务而进一步优化的模型版本。它能够自主理解用户的意图，规划复杂的指令，并能够调用一个或多个工具（例如网络浏览器、代码解释器和文本生图像）以完成复杂的任务。',
+      displayName: 'GLM-4-AllTools',
+      enabled: true,
+      functionCall: true,
+      id: 'glm-4-alltools',
+      tokens: 128_000,
+    },
     {
       description: '智谱当前最先进最智能的模型，指令遵从能力大幅提升18.6%，发布于20240605',
       displayName: 'GLM-4-0520',
@@ -29,10 +38,10 @@ const ZhiPu: ModelProviderCard = {
     },
     {
       description: 'GLM-4-Air 的高性能版本，效果不变，推理速度达到其2.6倍',
-      displayName: 'GLM-4-Airx',
+      displayName: 'GLM-4-AirX',
       functionCall: true,
       id: 'glm-4-airx',
-      tokens: 128_000,
+      tokens: 8192,
     },
     {
       description: '适用简单任务，速度最快，价格最实惠的版本',
@@ -55,6 +64,14 @@ const ZhiPu: ModelProviderCard = {
       id: 'glm-3-turbo',
       tokens: 128_000,
     },
+    {
+      description: 'CodeGeeX是一款强大的AI编程助手，提供智能问答和代码补全功能，支持多种编程语言，帮助开发者提高编程效率。',
+      displayName: 'CodeGeeX-4',
+      enabled: true,
+      functionCall: false,
+      id: 'codegeex-4',
+      tokens: 128_000,
+    },
   ],
   checkModel: 'glm-4-flash',
   id: 'zhipu',
