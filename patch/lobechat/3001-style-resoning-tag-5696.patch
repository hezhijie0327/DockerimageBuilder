diff --git a/src/config/aiModels/ai360.ts b/src/config/aiModels/ai360.ts
index 743cde3c05244..10c6613306348 100644
--- a/src/config/aiModels/ai360.ts
+++ b/src/config/aiModels/ai360.ts
@@ -2,6 +2,26 @@ import { AIChatModelCard } from '@/types/aiModel';
 
 const ai360ChatModels: AIChatModelCard[] = [
   {
+    abilities: {
+      reasoning: true,
+    },
+    contextWindowTokens: 8000,
+    description:
+      '360zhinao2-o1 使用树搜索构建思维链，并引入了反思机制，使用强化学习训练，模型具备自我反思与纠错的能力。',
+    displayName: '360Zhinao2 o1',
+    enabled: true,
+    id: '360zhinao2-o1',
+    pricing: {
+      currency: 'CNY',
+      input: 4,
+      output: 10,
+    },
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+    },
     contextWindowTokens: 8000,
     description:
       '360gpt2-o1 使用树搜索构建思维链，并引入了反思机制，使用强化学习训练，模型具备自我反思与纠错的能力。',
@@ -10,8 +30,8 @@ const ai360ChatModels: AIChatModelCard[] = [
     id: '360gpt2-o1',
     pricing: {
       currency: 'CNY',
-      input: 20,
-      output: 50,
+      input: 4,
+      output: 10,
     },
     type: 'chat',
   },
diff --git a/src/config/aiModels/fireworksai.ts b/src/config/aiModels/fireworksai.ts
index 2e3637b0e8bf8..0cfd8ec59518f 100644
--- a/src/config/aiModels/fireworksai.ts
+++ b/src/config/aiModels/fireworksai.ts
@@ -235,6 +235,9 @@ const fireworksaiChatModels: AIChatModelCard[] = [
     type: 'chat',
   },
   {
+    abilities: {
+      reasoning: true,
+    },
     contextWindowTokens: 32_768,
     description:
       'Qwen QwQ 模型专注于推动 AI 推理，并展示了开放模型在推理能力上与闭源前沿模型匹敌的力量。QwQ-32B-Preview 是一个实验性发布版本，在 GPQA、AIME、MATH-500 和 LiveCodeBench 基准测试中，在分析和推理能力上可与 o1 相媲美，并超越 GPT-4o 和 Claude 3.5 Sonnet。注意：该模型目前作为无服务器模型进行实验性提供。如果用于生产环境，请注意 Fireworks 可能会在短时间内取消部署该模型。',
diff --git a/src/config/aiModels/giteeai.ts b/src/config/aiModels/giteeai.ts
index badd9eb41312a..17b6c08c37334 100644
--- a/src/config/aiModels/giteeai.ts
+++ b/src/config/aiModels/giteeai.ts
@@ -1,6 +1,66 @@
 import { AIChatModelCard } from '@/types/aiModel';
 
 const giteeaiChatModels: AIChatModelCard[] = [
+  {
+    abilities: {
+      reasoning: true,
+    },
+    contextWindowTokens: 32_000,
+    description:
+      '基于 Qwen2.5-Math-1.5B 的 DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。',
+    displayName: 'DeepSeek R1 Distill Qwen 1.5B',
+    enabled: true,
+    id: 'DeepSeek-R1-Distill-Qwen-1.5B',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+    },
+    contextWindowTokens: 32_000,
+    description:
+      '基于 Qwen2.5-Math-7B 的 DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。',
+    displayName: 'DeepSeek R1 Distill Qwen 7B',
+    enabled: true,
+    id: 'DeepSeek-R1-Distill-Qwen-7B',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+    },
+    contextWindowTokens: 32_000,
+    description:
+      '基于 Qwen2.5-14B 的 DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。',
+    displayName: 'DeepSeek R1 Distill Qwen 14B',
+    enabled: true,
+    id: 'DeepSeek-R1-Distill-Qwen-14B',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+    },
+    contextWindowTokens: 32_000,
+    description:
+      'DeepSeek-R1 系列通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆，超越 OpenAI-o1-mini 水平。',
+    displayName: 'DeepSeek R1 Distill Qwen 32B',
+    enabled: true,
+    id: 'DeepSeek-R1-Distill-Qwen-32B',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+    },
+    contextWindowTokens: 32_000,
+    description:
+      'QwQ-32B-Preview 是一款独具创新的自然语言处理模型，能够高效处理复杂的对话生成与上下文理解任务。',
+    displayName: 'QwQ 32B Preview',
+    enabled: true,
+    id: 'QwQ-32B-Preview',
+    type: 'chat',
+  },
   {
     abilities: {
       functionCall: true,
diff --git a/src/config/aiModels/github.ts b/src/config/aiModels/github.ts
index 5725b8bd4100a..0e1c7dee78275 100644
--- a/src/config/aiModels/github.ts
+++ b/src/config/aiModels/github.ts
@@ -4,6 +4,7 @@ const githubChatModels: AIChatModelCard[] = [
   {
     abilities: {
       functionCall: true,
+      reasoning: true,
     },
     contextWindowTokens: 200_000,
     description:
@@ -17,6 +18,7 @@ const githubChatModels: AIChatModelCard[] = [
   },
   {
     abilities: {
+      reasoning: true,
       vision: true,
     },
     contextWindowTokens: 128_000,
@@ -29,6 +31,7 @@ const githubChatModels: AIChatModelCard[] = [
   },
   {
     abilities: {
+      reasoning: true,
       vision: true,
     },
     contextWindowTokens: 200_000,
@@ -42,6 +45,7 @@ const githubChatModels: AIChatModelCard[] = [
   },
   {
     abilities: {
+      reasoning: true,
       vision: true,
     },
     contextWindowTokens: 128_000,
diff --git a/src/config/aiModels/google.ts b/src/config/aiModels/google.ts
index 39fc95746d5a3..dd533290559fe 100644
--- a/src/config/aiModels/google.ts
+++ b/src/config/aiModels/google.ts
@@ -4,6 +4,7 @@ const googleChatModels: AIChatModelCard[] = [
   {
     abilities: {
       functionCall: true,
+      reasoning: true,
       vision: true,
     },
     contextWindowTokens: 1_048_576 + 65_536,
@@ -24,6 +25,7 @@ const googleChatModels: AIChatModelCard[] = [
   {
     abilities: {
       functionCall: true,
+      reasoning: true,
       vision: true,
     },
     contextWindowTokens: 40_959,
diff --git a/src/config/aiModels/groq.ts b/src/config/aiModels/groq.ts
index 28ac54134f3fe..8c23a0fe709e5 100644
--- a/src/config/aiModels/groq.ts
+++ b/src/config/aiModels/groq.ts
@@ -1,6 +1,18 @@
 import { AIChatModelCard } from '@/types/aiModel';
 
 const groqChatModels: AIChatModelCard[] = [
+  {
+    abilities: {
+      reasoning: true,
+    },
+    contextWindowTokens: 128_000,
+    description:
+      'DeepSeek R1——DeepSeek 套件中更大更智能的模型——被蒸馏到 Llama 70B 架构中。基于基准测试和人工评估，该模型比原始 Llama 70B 更智能，尤其在需要数学和事实精确性的任务上表现出色。',
+    displayName: 'DeepSeek R1 (Distil-Llama 70B)',
+    enabled: true,
+    id: 'deepseek-r1-distill-llama-70b',
+    type: 'chat',
+  },
   {
     abilities: {
       functionCall: true,
diff --git a/src/config/aiModels/huggingface.ts b/src/config/aiModels/huggingface.ts
index 602d2bb355ca4..88cb640174364 100644
--- a/src/config/aiModels/huggingface.ts
+++ b/src/config/aiModels/huggingface.ts
@@ -30,6 +30,9 @@ const huggingfaceChatModels: AIChatModelCard[] = [
     type: 'chat',
   },
   {
+    abilities: {
+      reasoning: true,
+    },
     contextWindowTokens: 32_768,
     description: 'Qwen QwQ 是由 Qwen 团队开发的实验研究模型，专注于提升AI推理能力。',
     displayName: 'QwQ 32B Preview',
@@ -50,6 +53,9 @@ const huggingfaceChatModels: AIChatModelCard[] = [
     type: 'chat',
   },
   {
+    abilities: {
+      reasoning: true,
+    },
     contextWindowTokens: 16_384,
     displayName: 'DeepSeek R1',
     enabled: true,
diff --git a/src/config/aiModels/internlm.ts b/src/config/aiModels/internlm.ts
index 6d12bf86d21b8..776c7eb44ff45 100644
--- a/src/config/aiModels/internlm.ts
+++ b/src/config/aiModels/internlm.ts
@@ -7,7 +7,24 @@ const internlmChatModels: AIChatModelCard[] = [
     },
     contextWindowTokens: 32_768,
     description:
-      '我们最新的模型系列，有着卓越的推理性能，支持 1M 的上下文长度以及更强的指令跟随和工具调用能力。',
+      '我们最新的模型系列，有着卓越的推理性能，领跑同量级开源模型。默认指向我们最新发布的 InternLM3 系列模型',
+    displayName: 'InternLM3',
+    enabled: true,
+    id: 'internlm3-latest',
+    maxOutput: 4096,
+    pricing: {
+      input: 0,
+      output: 0,
+    },
+    type: 'chat',
+  },
+  {
+    abilities: {
+      functionCall: true,
+    },
+    contextWindowTokens: 32_768,
+    description:
+      '我们仍在维护的老版本模型，经过多轮迭代有着极其优异且稳定的性能，包含 7B、20B 多种模型参数量可选，支持 1M 的上下文长度以及更强的指令跟随和工具调用能力。默认指向我们最新发布的 InternLM2.5 系列模型',
     displayName: 'InternLM2.5',
     enabled: true,
     id: 'internlm2.5-latest',
@@ -23,7 +40,7 @@ const internlmChatModels: AIChatModelCard[] = [
       functionCall: true,
     },
     contextWindowTokens: 32_768,
-    description: '我们仍在维护的老版本模型，有 7B、20B 多种模型参数量可选。',
+    description: 'InternLM2 版本最大的模型，专注于高度复杂的任务',
     displayName: 'InternLM2 Pro Chat',
     id: 'internlm2-pro-chat',
     maxOutput: 4096,
diff --git a/src/config/aiModels/ollama.ts b/src/config/aiModels/ollama.ts
index 12fd990bdfbcd..b555e8a464441 100644
--- a/src/config/aiModels/ollama.ts
+++ b/src/config/aiModels/ollama.ts
@@ -75,6 +75,7 @@ const ollamaChatModels: AIChatModelCard[] = [
   {
     abilities: {
       functionCall: true,
+      reasoning: true,
     },
     contextWindowTokens: 128_000,
     description: 'QwQ 是一个实验研究模型，专注于提高 AI 推理能力。',
diff --git a/src/config/aiModels/openai.ts b/src/config/aiModels/openai.ts
index bb8f6869c58a9..d408ad77fd5c5 100644
--- a/src/config/aiModels/openai.ts
+++ b/src/config/aiModels/openai.ts
@@ -11,6 +11,7 @@ export const openaiChatModels: AIChatModelCard[] = [
   {
     abilities: {
       functionCall: true,
+      reasoning: true,
     },
     contextWindowTokens: 200_000,
     description:
@@ -27,6 +28,9 @@ export const openaiChatModels: AIChatModelCard[] = [
     type: 'chat',
   },
   {
+    abilities: {
+      reasoning: true,
+    },
     contextWindowTokens: 128_000,
     description:
       'o1-mini是一款针对编程、数学和科学应用场景而设计的快速、经济高效的推理模型。该模型具有128K上下文和2023年10月的知识截止日期。',
@@ -42,6 +46,9 @@ export const openaiChatModels: AIChatModelCard[] = [
     type: 'chat',
   },
   {
+    abilities: {
+      reasoning: true,
+    },
     contextWindowTokens: 200_000,
     description:
       'o1是OpenAI新的推理模型，支持图文输入并输出文本，适用于需要广泛通用知识的复杂任务。该模型具有200K上下文和2023年10月的知识截止日期。',
@@ -57,6 +64,9 @@ export const openaiChatModels: AIChatModelCard[] = [
     type: 'chat',
   },
   {
+    abilities: {
+      reasoning: true,
+    },
     contextWindowTokens: 128_000,
     description:
       'o1是OpenAI新的推理模型，适用于需要广泛通用知识的复杂任务。该模型具有128K上下文和2023年10月的知识截止日期。',
diff --git a/src/config/aiModels/perplexity.ts b/src/config/aiModels/perplexity.ts
index 00e7c5340b783..bbfd1d1d0561d 100644
--- a/src/config/aiModels/perplexity.ts
+++ b/src/config/aiModels/perplexity.ts
@@ -2,6 +2,9 @@ import { AIChatModelCard } from '@/types/aiModel';
 
 const perplexityChatModels: AIChatModelCard[] = [
   {
+    abilities: {
+      reasoning: true,
+    },
     contextWindowTokens: 127_072,
     description:
       '由 DeepSeek 推理模型提供支持的新 API 产品。',
diff --git a/src/config/aiModels/qwen.ts b/src/config/aiModels/qwen.ts
index a398ca8ff64f1..e0eb65c8c5fce 100644
--- a/src/config/aiModels/qwen.ts
+++ b/src/config/aiModels/qwen.ts
@@ -174,6 +174,7 @@ const qwenChatModels: AIChatModelCard[] = [
   },
   {
     abilities: {
+      reasoning: true,
       functionCall: true,
     },
     contextWindowTokens: 32_768,
@@ -191,6 +192,7 @@ const qwenChatModels: AIChatModelCard[] = [
   },
   {
     abilities: {
+      reasoning: true,
       vision: true,
     },
     contextWindowTokens: 32_768,
diff --git a/src/config/aiModels/siliconcloud.ts b/src/config/aiModels/siliconcloud.ts
index 5345dd94a8ba4..2ff53c092b5bf 100644
--- a/src/config/aiModels/siliconcloud.ts
+++ b/src/config/aiModels/siliconcloud.ts
@@ -69,6 +69,7 @@ const siliconcloudChatModels: AIChatModelCard[] = [
   },
   {
     abilities: {
+      reasoning: true,
       vision: true,
     },
     contextWindowTokens: 32_768,
@@ -85,6 +86,9 @@ const siliconcloudChatModels: AIChatModelCard[] = [
     type: 'chat',
   },
   {
+    abilities: {
+      reasoning: true,
+    },
     contextWindowTokens: 32_768,
     description:
       'QwQ-32B-Preview是Qwen 最新的实验性研究模型，专注于提升AI推理能力。通过探索语言混合、递归推理等复杂机制，主要优势包括强大的推理分析能力、数学和编程能力。与此同时，也存在语言切换问题、推理循环、安全性考虑、其他能力方面的差异。',
diff --git a/src/config/aiModels/togetherai.ts b/src/config/aiModels/togetherai.ts
index fa527fde23de8..805d1d4985955 100644
--- a/src/config/aiModels/togetherai.ts
+++ b/src/config/aiModels/togetherai.ts
@@ -1,6 +1,18 @@
 import { AIChatModelCard } from '@/types/aiModel';
 
 const togetheraiChatModels: AIChatModelCard[] = [
+  {
+    abilities: {
+      functionCall: true,
+    },
+    contextWindowTokens: 131_072,
+    description:
+      'Meta Llama 3.3 多语言大语言模型 ( LLM ) 是 70B（文本输入/文本输出）中的预训练和指令调整生成模型。 Llama 3.3 指令调整的纯文本模型针对多语言对话用例进行了优化，并且在常见行业基准上优于许多可用的开源和封闭式聊天模型。',
+    displayName: 'Llama 3.3 70B Instruct Turbo',
+    enabled: true,
+    id: 'meta-llama/Llama-3.3-70B-Instruct-Turbo',
+    type: 'chat',
+  },
   {
     contextWindowTokens: 131_072,
     description:
@@ -245,15 +257,66 @@ const togetheraiChatModels: AIChatModelCard[] = [
     id: 'microsoft/WizardLM-2-8x22B',
     type: 'chat',
   },
+  {
+    abilities: {
+      reasoning: true,
+    },
+    contextWindowTokens: 32_768,
+    description: 'DeepSeek-R1 系列通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆，超越 OpenAI-o1-mini 水平。',
+    displayName: 'DeepSeek-R1',
+    enabled: true,
+    id: 'deepseek-ai/DeepSeek-R1',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+    },
+    contextWindowTokens: 131_072,
+    description: 'DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。',
+    displayName: 'DeepSeek R1 Distill Qwen 1.5B',
+    id: 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+    },
+    contextWindowTokens: 131_072,
+    description: 'DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。',
+    displayName: 'DeepSeek R1 Distill Qwen 14B',
+    id: 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+    },
+    contextWindowTokens: 131_072,
+    description: 'DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。',
+    displayName: 'DeepSeek R1 Distill Llama 70B',
+    id: 'deepseek-ai/DeepSeek-R1-Distill-Llama-70B',
+    type: 'chat',
+  },
+  {
+    contextWindowTokens: 16_384,
+    description: '最新模型 DeepSeek-V3 多项评测成绩超越 Qwen2.5-72B 和 Llama-3.1-405B 等开源模型，性能对齐领军闭源模型 GPT-4o 与 Claude-3.5-Sonnet。',
+    displayName: 'DeepSeek-V3',
+    enabled: true,
+    id: 'deepseek-ai/DeepSeek-V3',
+    type: 'chat',
+  },
   {
     contextWindowTokens: 4096,
     description: 'DeepSeek LLM Chat (67B) 是创新的 AI 模型 提供深度语言理解和互动能力。',
     displayName: 'DeepSeek LLM Chat (67B)',
-    enabled: true,
     id: 'deepseek-ai/deepseek-llm-67b-chat',
     type: 'chat',
   },
   {
+    abilities: {
+      reasoning: true,
+    },
     contextWindowTokens: 32_768,
     description: 'QwQ模型是由 Qwen 团队开发的实验性研究模型，专注于增强 AI 推理能力。',
     displayName: 'QwQ 32B Preview',
diff --git a/src/config/aiModels/zhipu.ts b/src/config/aiModels/zhipu.ts
index 57898d22efaab..71f708aa7f071 100644
--- a/src/config/aiModels/zhipu.ts
+++ b/src/config/aiModels/zhipu.ts
@@ -2,6 +2,9 @@ import { AIChatModelCard } from '@/types/aiModel';
 
 const zhipuChatModels: AIChatModelCard[] = [
   {
+    abilities: {
+      reasoning: true,
+    },
     contextWindowTokens: 16_384,
     description: 'GLM-Zero-Preview具备强大的复杂推理能力，在逻辑推理、数学、编程等领域表现优异。',
     displayName: 'GLM-Zero-Preview',
