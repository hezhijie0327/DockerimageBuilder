diff --git a/.devcontainer/devcontainer.json b/.devcontainer/devcontainer.json
index 9a983d7ac36a3..a9d55f2e279cc 100644
--- a/.devcontainer/devcontainer.json
+++ b/.devcontainer/devcontainer.json
@@ -1,6 +1,6 @@
 {
-  "image": "mcr.microsoft.com/devcontainers/typescript-node",
   "features": {
-    "ghcr.io/devcontainer-community/devcontainer-features/bun.sh:1": {}
-  }
+    // "ghcr.io/devcontainer-community/devcontainer-features/bun.sh:1": {}
+  },
+  "image": "mcr.microsoft.com/devcontainers/typescript-node"
 }
diff --git a/src/config/aiModels/azure.ts b/src/config/aiModels/azure.ts
index c04730f3196ba..ea4b6d805f3e2 100644
--- a/src/config/aiModels/azure.ts
+++ b/src/config/aiModels/azure.ts
@@ -16,6 +16,7 @@ const azureChatModels: AIChatModelCard[] = [
     id: 'o3-mini',
     maxOutput: 100_000,
     pricing: {
+      cachedInput: 0.55,
       input: 1.1,
       output: 4.4,
     },
@@ -37,6 +38,7 @@ const azureChatModels: AIChatModelCard[] = [
     id: 'o1-mini',
     maxOutput: 65_536,
     pricing: {
+      cachedInput: 0.55,
       input: 1.1,
       output: 4.4,
     },
@@ -58,6 +60,7 @@ const azureChatModels: AIChatModelCard[] = [
     id: 'o1',
     maxOutput: 100_000,
     pricing: {
+      cachedInput: 7.5,
       input: 15,
       output: 60,
     },
@@ -98,14 +101,15 @@ const azureChatModels: AIChatModelCard[] = [
     displayName: 'GPT-4o',
     enabled: true,
     id: 'gpt-4o',
+    maxOutput: 4096,
     pricing: {
+      cachedInput: 1.25,
       input: 2.5,
       output: 10,
     },
     releasedAt: '2024-05-13',
     type: 'chat',
   },
-
   {
     abilities: {
       functionCall: true,
@@ -135,6 +139,11 @@ const azureChatModels: AIChatModelCard[] = [
     enabled: true,
     id: 'gpt-4o-mini',
     maxOutput: 4096,
+    pricing: {
+      cachedInput: 0.075,
+      input: 0.15,
+      output: 0.6,
+    },
     type: 'chat',
   },
 ];
diff --git a/src/config/aiModels/azureai.ts b/src/config/aiModels/azureai.ts
index e1f0c9258ebc4..005fac9835e3d 100644
--- a/src/config/aiModels/azureai.ts
+++ b/src/config/aiModels/azureai.ts
@@ -8,7 +8,128 @@ const azureChatModels: AIChatModelCard[] = [
     contextWindowTokens: 128_000,
     displayName: 'DeepSeek R1',
     id: 'DeepSeek-R1',
+    pricing: {
+      input: 1.35,
+      output: 5.4,
+    },
+    type: 'chat',
+  },
+  {
+    abilities: {
+      functionCall: true,
+    },
+    contextWindowTokens: 128_000,
+    displayName: 'DeepSeek V3',
+    id: 'DeepSeek-V3',
+    pricing: {
+      input: 1.14,
+      output: 4.56,
+    },
+    type: 'chat',
+  },
+  {
+    abilities: {
+      functionCall: true,
+    },
+    contextWindowTokens: 128_000,
+    description:
+      'GPT-4.5-preview 是最新的通用模型，具有深厚的世界知识和对用户意图的更好理解，擅长创意任务和代理规划。该模型的知识截止2023年10月。',
+    displayName: 'GPT 4.5 Preview',
+    id: 'gpt-4.5-preview',
+    pricing: {
+      cachedInput: 37.5,
+      input: 75,
+      output: 150,
+    },
+    releasedAt: '2025-02-27',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      functionCall: true,
+      reasoning: true,
+    },
+    contextWindowTokens: 200_000,
+    description:
+      'o3-mini 是我们最新的小型推理模型，在与 o1-mini 相同的成本和延迟目标下提供高智能。',
+    displayName: 'o3-mini',
+    id: 'o3-mini',
+    pricing: {
+      cachedInput: 0.55,
+      input: 1.1,
+      output: 4.4,
+    },
+    releasedAt: '2025-01-31',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+    },
+    contextWindowTokens: 128_000,
+    description:
+      'o1-mini是一款针对编程、数学和科学应用场景而设计的快速、经济高效的推理模型。该模型具有128K上下文和2023年10月的知识截止日期。',
+    displayName: 'o1-mini',
+    id: 'o1-mini',
+    pricing: {
+      cachedInput: 0.55,
+      input: 1.1,
+      output: 4.4,
+    },
+    releasedAt: '2024-09-12',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+    },
+    contextWindowTokens: 200_000,
+    description:
+      'o1是OpenAI新的推理模型，支持图文输入并输出文本，适用于需要广泛通用知识的复杂任务。该模型具有200K上下文和2023年10月的知识截止日期。',
+    displayName: 'o1',
+    id: 'o1',
+    pricing: {
+      cachedInput: 7.5,
+      input: 15,
+      output: 60,
+    },
+    releasedAt: '2024-12-17',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      functionCall: true,
+      vision: true,
+    },
+    contextWindowTokens: 128_000,
+    description:
+      'ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。',
+    displayName: 'GPT-4o',
+    id: 'gpt-4o',
     maxOutput: 4096,
+    pricing: {
+      cachedInput: 1.25,
+      input: 2.5,
+      output: 10,
+    },
+    releasedAt: '2024-05-13',
+    type: 'chat',
+  },
+  {
+    abilities: {
+      functionCall: true,
+      vision: true,
+    },
+    contextWindowTokens: 128_000,
+    description: 'GPT-4o Mini，小型高效模型，具备与GPT-4o相似的卓越性能。',
+    displayName: 'GPT 4o Mini',
+    id: 'gpt-4o-mini',
+    maxOutput: 16_384,
+    pricing: {
+      cachedInput: 0.075,
+      input: 0.15,
+      output: 0.6,
+    },
     type: 'chat',
   },
 ];
diff --git a/src/config/aiModels/google.ts b/src/config/aiModels/google.ts
index 245ae109883cc..7967129905a51 100644
--- a/src/config/aiModels/google.ts
+++ b/src/config/aiModels/google.ts
@@ -16,7 +16,6 @@ const googleChatModels: AIChatModelCard[] = [
     id: 'gemini-2.5-pro-exp-03-25',
     maxOutput: 65_536,
     pricing: {
-      cachedInput: 0,
       input: 0,
       output: 0,
     },
@@ -174,7 +173,6 @@ const googleChatModels: AIChatModelCard[] = [
   },
   {
     abilities: {
-      imageOutput: true,
       vision: true,
     },
     contextWindowTokens: 1_048_576 + 8192,
@@ -297,6 +295,42 @@ const googleChatModels: AIChatModelCard[] = [
     releasedAt: '2024-10-03',
     type: 'chat',
   },
+  {
+    contextWindowTokens: 32_768 + 8192,
+    displayName: 'Gemma 3 1B',
+    id: 'gemma-3-1b-it',
+    maxOutput: 8192,
+    pricing: {
+      cachedInput: 0,
+      input: 0,
+      output: 0,
+    },
+    type: 'chat',
+  },
+  {
+    contextWindowTokens: 32_768 + 8192,
+    displayName: 'Gemma 3 4B',
+    id: 'gemma-3-4b-it',
+    maxOutput: 8192,
+    pricing: {
+      cachedInput: 0,
+      input: 0,
+      output: 0,
+    },
+    type: 'chat',
+  },
+  {
+    contextWindowTokens: 32_768 + 8192,
+    displayName: 'Gemma 3 12B',
+    id: 'gemma-3-12b-it',
+    maxOutput: 8192,
+    pricing: {
+      cachedInput: 0,
+      input: 0,
+      output: 0,
+    },
+    type: 'chat',
+  },
 ];
 
 export const allModels = [...googleChatModels];
diff --git a/src/config/aiModels/groq.ts b/src/config/aiModels/groq.ts
index 2a7c63b00ba7a..5202a4261851c 100644
--- a/src/config/aiModels/groq.ts
+++ b/src/config/aiModels/groq.ts
@@ -4,6 +4,30 @@ import { AIChatModelCard } from '@/types/aiModel';
 // https://console.groq.com/docs/models
 
 const groqChatModels: AIChatModelCard[] = [
+  {
+    contextWindowTokens: 131_072,
+    displayName: 'Llama 4 Scout (17Bx16E)',
+    enabled: true,
+    id: 'meta-llama/llama-4-scout-17b-16e-instruct',
+    maxOutput: 8192,
+    pricing: {
+      input: 0.11,
+      output: 0.34,
+    },
+    type: 'chat',
+  },
+  {
+    contextWindowTokens: 131_072,
+    displayName: 'Llama 4 Maverick (17Bx128E)',
+    enabled: true,
+    id: 'meta-llama/llama-4-maverick-17b-128e-instruct',
+    maxOutput: 8192,
+    pricing: {
+      input: 0.5,
+      output: 0.77,
+    },
+    type: 'chat',
+  },
   {
     abilities: {
       functionCall: true,
@@ -11,6 +35,7 @@ const groqChatModels: AIChatModelCard[] = [
     },
     contextWindowTokens: 131_072,
     displayName: 'Qwen QwQ 32B',
+    enabled: true,
     id: 'qwen-qwq-32b',
     pricing: {
       input: 0.29,
@@ -25,7 +50,6 @@ const groqChatModels: AIChatModelCard[] = [
     },
     contextWindowTokens: 131_072,
     displayName: 'DeepSeek R1 Distill Llama 70B',
-    enabled: true,
     id: 'deepseek-r1-distill-llama-70b',
     pricing: {
       input: 0.75, // 0.75 - 5.00
@@ -51,7 +75,6 @@ const groqChatModels: AIChatModelCard[] = [
     },
     contextWindowTokens: 131_072,
     displayName: 'DeepSeek R1 Distill Qwen 32B',
-    enabled: true,
     id: 'deepseek-r1-distill-qwen-32b',
     maxOutput: 16_384,
     pricing: {
@@ -159,7 +182,6 @@ const groqChatModels: AIChatModelCard[] = [
     contextWindowTokens: 131_072,
     description: 'Meta Llama 3.3 多语言大语言模型 ( LLM ) 是 70B（文本输入/文本输出）中的预训练和指令调整生成模型。 Llama 3.3 指令调整的纯文本模型针对多语言对话用例进行了优化，并且在常见行业基准上优于许多可用的开源和封闭式聊天模型。',
     displayName: 'Llama 3.3 70B Versatile',
-    enabled: true,
     id: 'llama-3.3-70b-versatile',
     maxOutput: 32_768,
     pricing: {
@@ -247,6 +269,12 @@ const groqChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
+  {
+    contextWindowTokens: 4096,
+    displayName: 'ALLaM 2 7B',
+    id: 'allam-2-7b',
+    type: 'chat',
+  },
 ];
 
 export const allModels = [...groqChatModels];
diff --git a/src/config/aiModels/hunyuan.ts b/src/config/aiModels/hunyuan.ts
index 198b8640ba6ce..684421b8c4c6c 100644
--- a/src/config/aiModels/hunyuan.ts
+++ b/src/config/aiModels/hunyuan.ts
@@ -20,7 +20,7 @@ const hunyuanChatModels: AIChatModelCard[] = [
       input: 1,
       output: 4,
     },
-    releasedAt: '2025-03-21',
+    releasedAt: '2025-04-03',
     settings: {
       searchImpl: 'params',
     },
@@ -72,7 +72,6 @@ const hunyuanChatModels: AIChatModelCard[] = [
     description:
       '采用更优的路由策略，同时缓解了负载均衡和专家趋同的问题。长文方面，大海捞针指标达到99.9%。MOE-32K 性价比相对更高，在平衡效果、价格的同时，可对实现对长文本输入的处理。',
     displayName: 'Hunyuan Standard',
-    enabled: true,
     id: 'hunyuan-standard',
     maxOutput: 2000,
     pricing: {
@@ -137,7 +136,6 @@ const hunyuanChatModels: AIChatModelCard[] = [
     description:
       '擅长处理长文任务如文档摘要和文档问答等，同时也具备处理通用文本生成任务的能力。在长文本的分析和生成上表现优异，能有效应对复杂和详尽的长文内容处理需求。',
     displayName: 'Hunyuan Large Longcontext',
-    enabled: true,
     id: 'hunyuan-large-longcontext',
     maxOutput: 6000,
     pricing: {
@@ -160,7 +158,6 @@ const hunyuanChatModels: AIChatModelCard[] = [
     description:
       '通用体验优化，包括NLP理解、文本创作、闲聊、知识问答、翻译、领域等；提升拟人性，优化模型情商；提升意图模糊时模型主动澄清能力；提升字词解析类问题的处理能力；提升创作的质量和可互动性；提升多轮体验。',
     displayName: 'Hunyuan Turbo',
-    enabled: true,
     id: 'hunyuan-turbo-latest',
     maxOutput: 4000,
     pricing: {
@@ -201,19 +198,18 @@ const hunyuanChatModels: AIChatModelCard[] = [
       functionCall: true,
       search: true,
     },
-    contextWindowTokens: 32_000,
+    contextWindowTokens: 134_000,
     description:
-      'hunyuan-TurboS 混元旗舰大模型最新版本，具备更强的思考能力，更优的体验效果。',
-    displayName: 'Hunyuan TurboS',
-    enabled: true,
-    id: 'hunyuan-turbos-latest',
-    maxOutput: 8000,
+      '擅长处理长文任务如文档摘要和文档问答等，同时也具备处理通用文本生成任务的能力。在长文本的分析和生成上表现优异，能有效应对复杂和详尽的长文内容处理需求。',
+    displayName: 'Hunyuan TurboS LongText 128K',
+    id: 'hunyuan-turbos-longtext-128k-20250325',
+    maxOutput: 6000,
     pricing: {
       currency: 'CNY',
-      input: 0.8,
-      output: 2,
+      input: 1.5,
+      output: 6,
     },
-    releasedAt: '2025-03-13',
+    releasedAt: '2025-03-25',
     settings: {
       searchImpl: 'params',
     },
@@ -226,9 +222,10 @@ const hunyuanChatModels: AIChatModelCard[] = [
     },
     contextWindowTokens: 32_000,
     description:
-      '统一数学解题步骤的风格，加强数学多轮问答。文本创作优化回答风格，去除AI味，增加文采。',
-    displayName: 'Hunyuan TurboS 20250313',
-    id: 'hunyuan-turbos-20250313',
+      'hunyuan-TurboS 混元旗舰大模型最新版本，具备更强的思考能力，更优的体验效果。',
+    displayName: 'Hunyuan TurboS',
+    enabled: true,
+    id: 'hunyuan-turbos-latest',
     maxOutput: 8000,
     pricing: {
       currency: 'CNY',
@@ -241,6 +238,29 @@ const hunyuanChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
+  // 重定向模型先行注释，待 latest 更新后再显示
+  // {
+  //   abilities: {
+  //     functionCall: true,
+  //     search: true,
+  //   },
+  //   contextWindowTokens: 32_000,
+  //   description:
+  //     '统一数学解题步骤的风格，加强数学多轮问答。文本创作优化回答风格，去除AI味，增加文采。',
+  //   displayName: 'Hunyuan TurboS 20250313',
+  //   id: 'hunyuan-turbos-20250313',
+  //   maxOutput: 8000,
+  //   pricing: {
+  //     currency: 'CNY',
+  //     input: 0.8,
+  //     output: 2,
+  //   },
+  //   releasedAt: '2025-03-13',
+  //   settings: {
+  //     searchImpl: 'params',
+  //   },
+  //   type: 'chat',
+  // },
   {
     abilities: {
       functionCall: true,
@@ -270,7 +290,6 @@ const hunyuanChatModels: AIChatModelCard[] = [
     contextWindowTokens: 36_000,
     description: '混元最新7B多模态模型，上下文窗口32K，支持中英文场景的多模态对话、图像物体识别、文档表格理解、多模态数学等，在多个维度上评测指标优于7B竞品模型。',
     displayName: 'Hunyuan Lite Vision',
-    enabled: true,
     id: 'hunyuan-lite-vision',
     maxOutput: 4000,
     releasedAt: '2024-12-12',
@@ -296,7 +315,6 @@ const hunyuanChatModels: AIChatModelCard[] = [
     contextWindowTokens: 8000,
     description: '混元新一代视觉语言旗舰大模型，采用全新的混合专家模型（MoE）结构，在图文理解相关的基础识别、内容创作、知识问答、分析推理等能力上相比前一代模型全面提升。',
     displayName: 'Hunyuan Turbo Vision',
-    enabled: true,
     id: 'hunyuan-turbo-vision',
     maxOutput: 2000,
     pricing: {
@@ -307,6 +325,24 @@ const hunyuanChatModels: AIChatModelCard[] = [
     releasedAt: '2024-11-26',
     type: 'chat',
   },
+  {
+    abilities: {
+      vision: true,
+    },
+    contextWindowTokens: 8000,
+    description: '此模型适用于图文理解场景，是基于混元最新 turbos 的新一代视觉语言旗舰大模型，聚焦图文理解相关任务，包括基于图片的实体识别、知识问答、文案创作、拍照解题等方面，相比前一代模型全面提升。',
+    displayName: 'Hunyuan TurboS Vision',
+    enabled: true,
+    id: 'hunyuan-turbos-vision',
+    maxOutput: 2000,
+    pricing: {
+      currency: 'CNY',
+      input: 3,
+      output: 9,
+    },
+    releasedAt: '2025-04-07',
+    type: 'chat',
+  },
   {
     abilities: {
       vision: true,
diff --git a/src/config/aiModels/moonshot.ts b/src/config/aiModels/moonshot.ts
index d9be341bf7da5..d79f2509b8c2f 100644
--- a/src/config/aiModels/moonshot.ts
+++ b/src/config/aiModels/moonshot.ts
@@ -1,5 +1,5 @@
 import { AIChatModelCard } from '@/types/aiModel';
-
+// https://platform.moonshot.cn/docs/pricing/chat
 const moonshotChatModels: AIChatModelCard[] = [
   {
     abilities: {
@@ -16,8 +16,8 @@ const moonshotChatModels: AIChatModelCard[] = [
     pricing: {
       cachedInput: 1,
       currency: 'CNY',
-      input: 60,
-      output: 60,
+      input: 10,
+      output: 30,
     },
     releasedAt: '2025-02-17',
     settings: {
@@ -37,8 +37,8 @@ const moonshotChatModels: AIChatModelCard[] = [
     id: 'moonshot-v1-auto',
     pricing: {
       currency: 'CNY',
-      input: 60,
-      output: 60,
+      input: 10,
+      output: 30,
     },
     settings: {
       searchImpl: 'params',
@@ -57,8 +57,8 @@ const moonshotChatModels: AIChatModelCard[] = [
     id: 'moonshot-v1-8k',
     pricing: {
       currency: 'CNY',
-      input: 12,
-      output: 12,
+      input: 2,
+      output: 10,
     },
     settings: {
       searchImpl: 'params',
@@ -77,8 +77,8 @@ const moonshotChatModels: AIChatModelCard[] = [
     id: 'moonshot-v1-32k',
     pricing: {
       currency: 'CNY',
-      input: 24,
-      output: 24,
+      input: 5,
+      output: 20,
     },
     settings: {
       searchImpl: 'params',
@@ -97,8 +97,8 @@ const moonshotChatModels: AIChatModelCard[] = [
     id: 'moonshot-v1-128k',
     pricing: {
       currency: 'CNY',
-      input: 60,
-      output: 60,
+      input: 10,
+      output: 30,
     },
     settings: {
       searchImpl: 'params',
@@ -118,8 +118,8 @@ const moonshotChatModels: AIChatModelCard[] = [
     id: 'moonshot-v1-8k-vision-preview',
     pricing: {
       currency: 'CNY',
-      input: 12,
-      output: 12,
+      input: 2,
+      output: 10,
     },
     releasedAt: '2025-01-14',
     settings: {
@@ -140,8 +140,8 @@ const moonshotChatModels: AIChatModelCard[] = [
     id: 'moonshot-v1-32k-vision-preview',
     pricing: {
       currency: 'CNY',
-      input: 24,
-      output: 24,
+      input: 5,
+      output: 20,
     },
     releasedAt: '2025-01-14',
     settings: {
@@ -162,8 +162,8 @@ const moonshotChatModels: AIChatModelCard[] = [
     id: 'moonshot-v1-128k-vision-preview',
     pricing: {
       currency: 'CNY',
-      input: 60,
-      output: 60,
+      input: 10,
+      output: 30,
     },
     releasedAt: '2025-01-14',
     settings: {
diff --git a/src/config/aiModels/novita.ts b/src/config/aiModels/novita.ts
index 0ecf28adf6c86..9876ae3fbd49e 100644
--- a/src/config/aiModels/novita.ts
+++ b/src/config/aiModels/novita.ts
@@ -1,26 +1,36 @@
 import { AIChatModelCard } from '@/types/aiModel';
 
 // https://novita.ai/pricing
-
 const novitaChatModels: AIChatModelCard[] = [
   {
     contextWindowTokens: 131_072,
-    displayName: 'Llama 3.3 70B Instruct',
+    displayName: 'Llama 4 Scout 17B Instruct',
     enabled: true,
-    id: 'meta-llama/llama-3.3-70b-instruct',
+    id: 'meta-llama/llama-4-scout-17b-16e-instruct',
     pricing: {
-      input: 0.13,
-      output: 0.39,
+      input: 0.1,
+      output: 0.5,
+    },
+    type: 'chat',
+  },
+  {
+    contextWindowTokens: 1_048_576,
+    displayName: 'Llama 4 Maverick 17B Instruct',
+    enabled: true,
+    id: 'meta-llama/llama-4-maverick-17b-128e-instruct-fp8',
+    pricing: {
+      input: 0.2,
+      output: 0.85,
     },
     type: 'chat',
   },
   {
     contextWindowTokens: 16_384,
-    description: 'Llama 3.1 8B Instruct 是 Meta 推出的最新版本，优化了高质量对话场景，表现优于许多领先的闭源模型。',
+    description: 'Llama 3.1 8B Instruct  优化了高质量对话场景，表现优于许多领先的闭源模型。',
     displayName: 'Llama 3.1 8B Instruct',
     id: 'meta-llama/llama-3.1-8b-instruct',
     pricing: {
-      input: 0.05,
+      input: 0.02,
       output: 0.05,
     },
     type: 'chat',
@@ -73,7 +83,6 @@ const novitaChatModels: AIChatModelCard[] = [
     contextWindowTokens: 32_000,
     description: 'Gemma 3 27B 是谷歌的一款开源语言模型，以其在效率和性能方面设立了新的标准。',
     displayName: 'Gemma 3 27B',
-    enabled: true,
     id: 'google/gemma-3-27b-it',
     pricing: {
       input: 0.2,
@@ -190,7 +199,7 @@ const novitaChatModels: AIChatModelCard[] = [
     enabled: true,
     id: 'deepseek/deepseek-v3-0324',
     pricing: {
-      input: 0.4,
+      input: 0.37,
       output: 1.3,
     },
     type: 'chat',
@@ -318,18 +327,12 @@ const novitaChatModels: AIChatModelCard[] = [
     type: 'chat',
   },
   {
-    contextWindowTokens: 32_768,
-    displayName: 'Qwen 2 VL 72B Instruct',
-    id: 'qwen/qwen-2-vl-72b-instruct',
-    pricing: {
-      input: 0.45,
-      output: 0.45,
+    abilities: {
+      vision: true,
     },
-    type: 'chat',
-  },
-  {
     contextWindowTokens: 96_000,
     displayName: 'Qwen 2.5 VL 72B Instruct',
+    enabled: true,
     id: 'qwen/qwen2.5-vl-72b-instruct',
     pricing: {
       input: 0.8,
@@ -378,7 +381,7 @@ const novitaChatModels: AIChatModelCard[] = [
     type: 'chat',
   },
   {
-    contextWindowTokens: 16_000,
+    contextWindowTokens: 8192,
     displayName: 'L31 70B Euryale v2.2',
     id: 'sao10k/l31-70b-euryale-v2.2',
     pricing: {
@@ -387,22 +390,13 @@ const novitaChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
-  {
-    contextWindowTokens: 32_768,
-    displayName: 'Qwen 2 7B Instruct',
-    id: 'qwen/qwen-2-7b-instruct',
-    pricing: {
-      input: 0.054,
-      output: 0.054,
-    },
-    type: 'chat',
-  },
-  {
+    {
     abilities: {
       reasoning: true,
     },
     contextWindowTokens: 32_768,
     displayName: 'QwQ 32B',
+    enabled: true,
     id: 'qwen/qwq-32b',
     pricing: {
       input: 0.18,
@@ -410,6 +404,7 @@ const novitaChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
+
 ];
 
 export const allModels = [...novitaChatModels];
diff --git a/src/config/aiModels/stepfun.ts b/src/config/aiModels/stepfun.ts
index 4559a4181c30c..9bd0a54724053 100644
--- a/src/config/aiModels/stepfun.ts
+++ b/src/config/aiModels/stepfun.ts
@@ -3,6 +3,27 @@ import { AIChatModelCard } from '@/types/aiModel';
 // https://platform.stepfun.com/docs/pricing/details
 
 const stepfunChatModels: AIChatModelCard[] = [
+  {
+    abilities: {
+      // functionCall: true,
+      reasoning: true,
+      // search: true,
+      vision: true,
+    },
+    contextWindowTokens: 100_000,
+    description: '该模型是拥有强大的图像理解能力的推理大模型，能够处理图像和文字信息，经过深度思考后输出文本生成文本内容。该模型在视觉推理领域表现突出，同时拥有第一梯队的数学、代码、文本推理能力。上下文长度为100k。',
+    displayName: 'Step R1 V Mini',
+    id: 'step-r1-v-mini',
+    pricing: {
+      currency: 'CNY',
+      input: 2.5,
+      output: 8,
+    },
+    // settings: {
+    //   searchImpl: 'params',
+    // },
+    type: 'chat',
+  },
   {
     abilities: {
       functionCall: true,
@@ -11,8 +32,7 @@ const stepfunChatModels: AIChatModelCard[] = [
     contextWindowTokens: 8000,
     description: '高速模型，适合实时对话。',
     displayName: 'Step 1 Flash',
-    enabled: true,
-    id: 'step-1-flash',
+    id: 'step-1-flash', // 将在2025年4月30日下线
     pricing: {
       currency: 'CNY',
       input: 1,
@@ -31,7 +51,6 @@ const stepfunChatModels: AIChatModelCard[] = [
     contextWindowTokens: 8000,
     description: '小型模型，适合轻量级任务。',
     displayName: 'Step 1 8K',
-    enabled: true,
     id: 'step-1-8k',
     pricing: {
       currency: 'CNY',
@@ -51,7 +70,6 @@ const stepfunChatModels: AIChatModelCard[] = [
     contextWindowTokens: 32_000,
     description: '支持中等长度的对话，适用于多种应用场景。',
     displayName: 'Step 1 32K',
-    enabled: true,
     id: 'step-1-32k',
     pricing: {
       currency: 'CNY',
@@ -71,8 +89,7 @@ const stepfunChatModels: AIChatModelCard[] = [
     contextWindowTokens: 128_000,
     description: '平衡性能与成本，适合一般场景。',
     displayName: 'Step 1 128K',
-    enabled: true,
-    id: 'step-1-128k',
+    id: 'step-1-128k', // 将在2025年4月30日下线
     pricing: {
       currency: 'CNY',
       input: 40,
@@ -107,16 +124,18 @@ const stepfunChatModels: AIChatModelCard[] = [
       functionCall: true,
       search: true,
     },
-    contextWindowTokens: 16_000,
-    description: '支持大规模上下文交互，适合复杂对话场景。',
-    displayName: 'Step 2 16K',
+    contextWindowTokens: 8000,
+    description: 
+      '基于新一代自研Attention架构MFA的极速大模型，用极低成本达到和step1类似的效果，同时保持了更高的吞吐和更快响应时延。能够处理通用任务，在代码能力上具备特长。',
+    displayName: 'Step 2 Mini',
     enabled: true,
-    id: 'step-2-16k',
-    pricing: {
+    id: 'step-2-mini',
+      pricing: {
       currency: 'CNY',
-      input: 38,
-      output: 120,
+      input: 1,
+      output: 2,
     },
+    releasedAt: '2025-01-14',
     settings: {
       searchImpl: 'params',
     },
@@ -127,18 +146,15 @@ const stepfunChatModels: AIChatModelCard[] = [
       functionCall: true,
       search: true,
     },
-    contextWindowTokens: 8000,
-    description: 
-      '基于新一代自研Attention架构MFA的极速大模型，用极低成本达到和step1类似的效果，同时保持了更高的吞吐和更快响应时延。能够处理通用任务，在代码能力上具备特长。',
-    displayName: 'Step 2 Mini',
-    enabled: true,
-    id: 'step-2-mini',
-      pricing: {
+    contextWindowTokens: 16_000,
+    description: '支持大规模上下文交互，适合复杂对话场景。',
+    displayName: 'Step 2 16K',
+    id: 'step-2-16k',
+    pricing: {
       currency: 'CNY',
-      input: 1,
-      output: 2,
+      input: 38,
+      output: 120,
     },
-    releasedAt: '2025-01-14',
     settings: {
       searchImpl: 'params',
     },
@@ -153,7 +169,7 @@ const stepfunChatModels: AIChatModelCard[] = [
     description: 'step-2模型的实验版本，包含最新的特性，滚动更新中。不推荐在正式生产环境使用。',
     displayName: 'Step 2 16K Exp',
     enabled: true,
-    id: 'step-2-16k',
+    id: 'step-2-16k-exp',
     pricing: {
       currency: 'CNY',
       input: 38,
@@ -174,7 +190,6 @@ const stepfunChatModels: AIChatModelCard[] = [
     contextWindowTokens: 8000,
     description: '小型视觉模型，适合基本的图文任务。',
     displayName: 'Step 1V 8K',
-    enabled: true,
     id: 'step-1v-8k',
     pricing: {
       currency: 'CNY',
@@ -208,8 +223,6 @@ const stepfunChatModels: AIChatModelCard[] = [
   },
   {
     abilities: {
-      functionCall: true,
-      search: true,
       vision: true,
     },
     contextWindowTokens: 32_000,
@@ -223,9 +236,6 @@ const stepfunChatModels: AIChatModelCard[] = [
       output: 70,
     },
     releasedAt: '2025-01-22',
-    settings: {
-      searchImpl: 'params',
-    },
     type: 'chat',
   },
   {
@@ -235,7 +245,6 @@ const stepfunChatModels: AIChatModelCard[] = [
     contextWindowTokens: 32_000,
     description: '该模型拥有强大的视频理解能力。',
     displayName: 'Step 1.5V Mini',
-    enabled: true,
     id: 'step-1.5v-mini',
     pricing: {
       currency: 'CNY',
diff --git a/src/config/aiModels/tencentcloud.ts b/src/config/aiModels/tencentcloud.ts
index ba13ebb0c7dd0..1b7930f6b3651 100644
--- a/src/config/aiModels/tencentcloud.ts
+++ b/src/config/aiModels/tencentcloud.ts
@@ -1,5 +1,5 @@
 import { AIChatModelCard } from '@/types/aiModel';
-
+// https://cloud.tencent.com/document/product/1772/115969
 const tencentCloudChatModels: AIChatModelCard[] = [
   {
     abilities: {
@@ -7,11 +7,11 @@ const tencentCloudChatModels: AIChatModelCard[] = [
     },
     contextWindowTokens: 65_536,
     description:
-      'DeepSeek-R1 是一款强化学习（RL）驱动的推理模型，解决了模型中的重复性和可读性问题。在 RL 之前，DeepSeek-R1 引入了冷启动数据，进一步优化了推理性能。它在数学、代码和推理任务中与 OpenAI-o1 表现相当，并且通过精心设计的训练方法，提升了整体效果。',
+      'DeepSeek-R1 为671B 模型，使用强化学习训练，推理过程包含大量反思和验证，思维链长度可达数万字。 该系列模型在数学、代码以及各种复杂逻辑推理任务上推理效果优异，并为用户展现了完整的思考过程。',
     displayName: 'DeepSeek R1',
     enabled: true,
     id: 'deepseek-r1',
-    maxOutput: 8192,
+    maxOutput: 16_000,
     pricing: {
       currency: 'CNY',
       input: 4,
@@ -23,9 +23,10 @@ const tencentCloudChatModels: AIChatModelCard[] = [
     contextWindowTokens: 65_536,
     description:
       'DeepSeek-V3-0324 为671B 参数 MoE 模型，在编程与技术能力、上下文理解与长文本处理等方面优势突出。',
-    displayName: 'DeepSeek-V3-0324',
+    displayName: 'DeepSeek V3 0324',
     enabled: true,
     id: 'deepseek-v3-0324',
+    maxOutput: 16_000,
     pricing: {
       currency: 'CNY',
       input: 2,
@@ -36,10 +37,10 @@ const tencentCloudChatModels: AIChatModelCard[] = [
   {
     contextWindowTokens: 65_536,
     description:
-      'DeepSeek-V3 是一款拥有 6710 亿参数的混合专家（MoE）语言模型，采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，结合无辅助损失的负载平衡策略，优化推理和训练效率。通过在 14.8 万亿高质量tokens上预训练，并进行监督微调和强化学习，DeepSeek-V3 在性能上超越其他开源模型，接近领先闭源模型。',
+      'DeepSeek-V3 为671B 参数 MoE 模型，在百科知识、数学推理等多项任务上优势突出。',
     displayName: 'DeepSeek V3',
-    enabled: true,
     id: 'deepseek-v3',
+    maxOutput: 16_000,
     pricing: {
       currency: 'CNY',
       input: 2,
diff --git a/src/config/aiModels/volcengine.ts b/src/config/aiModels/volcengine.ts
index 8c6f77438bd57..e2c9f10f67890 100644
--- a/src/config/aiModels/volcengine.ts
+++ b/src/config/aiModels/volcengine.ts
@@ -149,6 +149,7 @@ const doubaoChatModels: AIChatModelCard[] = [
   },
   {
     abilities: {
+      functionCall: true,
       vision: true,
     },
     config: {
diff --git a/src/config/aiModels/zhipu.ts b/src/config/aiModels/zhipu.ts
index 6b1dc50837a9b..ef06d58315c8c 100644
--- a/src/config/aiModels/zhipu.ts
+++ b/src/config/aiModels/zhipu.ts
@@ -8,7 +8,6 @@ const zhipuChatModels: AIChatModelCard[] = [
     contextWindowTokens: 16_384,
     description: 'GLM-Zero-Preview具备强大的复杂推理能力，在逻辑推理、数学、编程等领域表现优异。',
     displayName: 'GLM-Zero-Preview',
-    enabled: true,
     id: 'glm-zero-preview',
     pricing: {
       currency: 'CNY',
@@ -17,6 +16,67 @@ const zhipuChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
+  {
+    abilities: {
+      reasoning: true,
+      search: true,
+    },
+    contextWindowTokens: 32_000,
+    description: '推理模型: 具备强大推理能力，适用于需要深度推理的任务。',
+    displayName: 'GLM-Z1-Air',
+    id: 'glm-z1-air',
+    maxOutput: 30_000,
+    pricing: {
+      currency: 'CNY',
+      input: 0.5,
+      output: 0.5,
+    },
+    settings: {
+      searchImpl: 'params',
+    },
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+      search: true,
+    },
+    contextWindowTokens: 32_000,
+    description: '极速推理：具有超快的推理速度和强大的推理效果。',
+    displayName: 'GLM-Z1-AirX',
+    id: 'glm-z1-airx',
+    maxOutput: 30_000,
+    pricing: {
+      currency: 'CNY',
+      input: 5,
+      output: 5,
+    },
+    settings: {
+      searchImpl: 'params',
+    },
+    type: 'chat',
+  },
+  {
+    abilities: {
+      reasoning: true,
+      search: true,
+    },
+    contextWindowTokens: 32_000,
+    description: 'GLM-Z1 系列具备强大的复杂推理能力，在逻辑推理、数学、编程等领域表现优异。最大上下文长度为32K。',
+    displayName: 'GLM-Z1-Flash',
+    enabled: true,
+    id: 'glm-z1-flash',
+    maxOutput: 30_000,
+    pricing: {
+      currency: 'CNY',
+      input: 0,
+      output: 0,
+    },
+    settings: {
+      searchImpl: 'params',
+    },
+    type: 'chat',
+  },
   {
     abilities: {
       functionCall: true,
@@ -24,9 +84,10 @@ const zhipuChatModels: AIChatModelCard[] = [
     },
     contextWindowTokens: 128_000,
     description: 'GLM-4-Flash 是处理简单任务的理想选择，速度最快且免费。',
-    displayName: 'GLM-4-Flash',
+    displayName: 'GLM-4-Flash-250414',
     enabled: true,
-    id: 'glm-4-flash',
+    id: 'glm-4-flash-250414',
+    maxOutput: 4000,
     pricing: {
       currency: 'CNY',
       input: 0,
@@ -45,8 +106,8 @@ const zhipuChatModels: AIChatModelCard[] = [
     contextWindowTokens: 128_000,
     description: 'GLM-4-FlashX 是Flash的增强版本，超快推理速度。',
     displayName: 'GLM-4-FlashX',
-    enabled: true,
     id: 'glm-4-flashx',
+    maxOutput: 4000,
     pricing: {
       currency: 'CNY',
       input: 0.1,
@@ -66,6 +127,7 @@ const zhipuChatModels: AIChatModelCard[] = [
     description: 'GLM-4-Long 支持超长文本输入，适合记忆型任务与大规模文档处理。',
     displayName: 'GLM-4-Long',
     id: 'glm-4-long',
+    maxOutput: 4000,
     pricing: {
       currency: 'CNY',
       input: 1,
@@ -81,15 +143,15 @@ const zhipuChatModels: AIChatModelCard[] = [
       functionCall: true,
       search: true,
     },
-    contextWindowTokens: 128_000,
+    contextWindowTokens: 32_000,
     description: 'GLM-4-Air 是性价比高的版本，性能接近GLM-4，提供快速度和实惠的价格。',
-    displayName: 'GLM-4-Air',
-    enabled: true,
-    id: 'glm-4-air',
+    displayName: 'GLM-4-Air-250414',
+    id: 'glm-4-air-250414',
+    maxOutput: 4000,
     pricing: {
       currency: 'CNY',
-      input: 1,
-      output: 1,
+      input: 0.5,
+      output: 0.5,
     },
     settings: {
       searchImpl: 'params',
@@ -104,8 +166,8 @@ const zhipuChatModels: AIChatModelCard[] = [
     contextWindowTokens: 8192,
     description: 'GLM-4-AirX 提供 GLM-4-Air 的高效版本，推理速度可达其2.6倍。',
     displayName: 'GLM-4-AirX',
-    enabled: true,
     id: 'glm-4-airx',
+     maxOutput: 4000,
     pricing: {
       currency: 'CNY',
       input: 10,
@@ -144,8 +206,8 @@ const zhipuChatModels: AIChatModelCard[] = [
     contextWindowTokens: 128_000,
     description: 'GLM-4-Plus 作为高智能旗舰，具备强大的处理长文本和复杂任务的能力，性能全面提升。',
     displayName: 'GLM-4-Plus',
-    enabled: true,
     id: 'glm-4-plus',
+    maxOutput: 4000,
     pricing: {
       currency: 'CNY',
       input: 50,
@@ -164,7 +226,7 @@ const zhipuChatModels: AIChatModelCard[] = [
     contextWindowTokens: 128_000,
     description: 'GLM-4-0520 是最新模型版本，专为高度复杂和多样化任务设计，表现卓越。',
     displayName: 'GLM-4-0520',
-    id: 'glm-4-0520',
+    id: 'glm-4-0520', // 弃用时间 2025年12月30日
     pricing: {
       currency: 'CNY',
       input: 100,
@@ -183,7 +245,7 @@ const zhipuChatModels: AIChatModelCard[] = [
     contextWindowTokens: 128_000,
     description: 'GLM-4 是发布于2024年1月的旧旗舰版本，目前已被更强的 GLM-4-0520 取代。',
     displayName: 'GLM-4',
-    id: 'glm-4',
+    id: 'glm-4', // 弃用时间 2025年6月30日
     pricing: {
       currency: 'CNY',
       input: 100,
@@ -198,7 +260,7 @@ const zhipuChatModels: AIChatModelCard[] = [
     abilities: {
       vision: true,
     },
-    contextWindowTokens: 8192,
+    contextWindowTokens: 4096,
     description:
       'GLM-4V-Flash 专注于高效的单一图像理解，适用于快速图像解析的场景，例如实时图像分析或批量图像处理。',
     displayName: 'GLM-4V-Flash',
@@ -218,13 +280,12 @@ const zhipuChatModels: AIChatModelCard[] = [
     },
     contextWindowTokens: 8192,
     description: 'GLM-4V-Plus 具备对视频内容及多图片的理解能力，适合多模态任务。',
-    displayName: 'GLM-4V-Plus',
-    enabled: true,
-    id: 'glm-4v-plus',
+    displayName: 'GLM-4V-Plus-0111',
+    id: 'glm-4v-plus-0111',
     pricing: {
       currency: 'CNY',
-      input: 10,
-      output: 10,
+      input: 4,
+      output: 4,
     },
     type: 'chat',
   },
@@ -232,7 +293,7 @@ const zhipuChatModels: AIChatModelCard[] = [
     abilities: {
       vision: true,
     },
-    contextWindowTokens: 2048,
+    contextWindowTokens: 4096,
     description: 'GLM-4V 提供强大的图像理解与推理能力，支持多种视觉任务。',
     displayName: 'GLM-4V',
     id: 'glm-4v',
@@ -249,6 +310,7 @@ const zhipuChatModels: AIChatModelCard[] = [
       'CodeGeeX-4 是强大的AI编程助手，支持多种编程语言的智能问答与代码补全，提升开发效率。',
     displayName: 'CodeGeeX-4',
     id: 'codegeex-4',
+    maxOutput: 32_000,
     pricing: {
       currency: 'CNY',
       input: 0.1,
@@ -257,14 +319,15 @@ const zhipuChatModels: AIChatModelCard[] = [
     type: 'chat',
   },
   {
-    contextWindowTokens: 4096,
-    description: 'CharGLM-3 专为角色扮演与情感陪伴设计，支持超长多轮记忆与个性化对话，应用广泛。',
-    displayName: 'CharGLM-3',
-    id: 'charglm-3',
+    contextWindowTokens: 8192,
+    description: 'CharGLM-4 专为角色扮演与情感陪伴设计，支持超长多轮记忆与个性化对话，应用广泛。',
+    displayName: 'CharGLM-4',
+    id: 'charglm-4',
+    maxOutput: 4000,
     pricing: {
       currency: 'CNY',
-      input: 15,
-      output: 15,
+      input: 1,
+      output: 1,
     },
     type: 'chat',
   },
@@ -273,6 +336,7 @@ const zhipuChatModels: AIChatModelCard[] = [
     description: 'Emohaa 是心理模型，具备专业咨询能力，帮助用户理解情感问题。',
     displayName: 'Emohaa',
     id: 'emohaa',
+    maxOutput: 4000,
     pricing: {
       currency: 'CNY',
       input: 15,
diff --git a/src/utils/parseModels.test.ts b/src/utils/parseModels.test.ts
index ae098810bcba5..587e5f44be8e9 100644
--- a/src/utils/parseModels.test.ts
+++ b/src/utils/parseModels.test.ts
@@ -87,7 +87,9 @@ describe('parseModelString', () => {
     });
 
     it('token and image output', () => {
-      const result = parseModelString('gemini-2.0-flash-exp-image-generation=Gemini 2.0 Flash (Image Generation) Experimental<32768:imageOutput>');
+      const result = parseModelString(
+        'gemini-2.0-flash-exp-image-generation=Gemini 2.0 Flash (Image Generation) Experimental<32768:imageOutput>',
+      );
 
       expect(result.add[0]).toEqual({
         displayName: 'Gemini 2.0 Flash (Image Generation) Experimental',
@@ -565,7 +567,12 @@ describe('transformToChatModelCards', () => {
         displayName: 'GPT-4o',
         enabled: true,
         id: 'gpt-4o',
-        pricing: { input: 2.5, output: 10 },
+        maxOutput: 4096,
+        pricing: {
+          cachedInput: 1.25,
+          input: 2.5,
+          output: 10,
+        },
         providerId: 'azure',
         releasedAt: '2024-05-13',
         source: 'builtin',
@@ -582,6 +589,11 @@ describe('transformToChatModelCards', () => {
         enabled: true,
         id: 'gpt-4o-mini',
         maxOutput: 4096,
+        pricing: {
+          cachedInput: 0.075,
+          input: 0.15,
+          output: 0.6,
+        },
         type: 'chat',
       },
       {
@@ -596,7 +608,11 @@ describe('transformToChatModelCards', () => {
         source: 'builtin',
         id: 'o1-mini',
         maxOutput: 65536,
-        pricing: { input: 1.1, output: 4.4 },
+        pricing: {
+          cachedInput: 0.55,
+          input: 1.1,
+          output: 4.4,
+        },
         releasedAt: '2024-09-12',
         type: 'chat',
       },
