From 71474d3cd068916cbe0c1792cef1bd6c00043fa2 Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Mon, 1 Jul 2024 09:52:51 +0800
Subject: [PATCH 01/17] =?UTF-8?q?=E2=9C=A8=20feat:=20Add=20Spark=20model?=
 =?UTF-8?q?=20provider?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 .../settings/llm/ProviderList/providers.tsx   |   7 +
 src/app/api/chat/agentRuntime.ts              |   7 +
 src/components/ModelIcon/index.tsx            |   4 +-
 src/components/ModelProviderIcon/index.tsx    |   5 +
 src/config/llm.ts                             |   6 +
 src/config/modelProviders/index.ts            |   4 +
 src/config/modelProviders/spark.ts            |  53 ++++
 src/const/settings/llm.ts                     |   5 +
 src/libs/agent-runtime/AgentRuntime.ts        |   7 +
 src/libs/agent-runtime/spark/index.test.ts    | 255 ++++++++++++++++++
 src/libs/agent-runtime/spark/index.ts         |  10 +
 src/libs/agent-runtime/types/type.ts          |   1 +
 src/server/globalConfig/index.ts              |   2 +
 src/types/user/settings/keyVaults.ts          |   1 +
 14 files changed, 366 insertions(+), 1 deletion(-)
 create mode 100644 src/config/modelProviders/spark.ts
 create mode 100644 src/libs/agent-runtime/spark/index.test.ts
 create mode 100644 src/libs/agent-runtime/spark/index.ts

diff --git a/src/app/(main)/settings/llm/ProviderList/providers.tsx b/src/app/(main)/settings/llm/ProviderList/providers.tsx
index 39258bb13964..e8a4039b96ee 100644
--- a/src/app/(main)/settings/llm/ProviderList/providers.tsx
+++ b/src/app/(main)/settings/llm/ProviderList/providers.tsx
@@ -10,6 +10,7 @@ import {
   Moonshot,
   OpenRouter,
   Perplexity,
+  Spark,
   Stepfun,
   Together,
   Tongyi,
@@ -33,6 +34,7 @@ import {
   OpenRouterProviderCard,
   PerplexityProviderCard,
   QwenProviderCard,
+  SparkProviderCard,
   StepfunProviderCard,
   TogetherAIProviderCard,
   ZeroOneProviderCard,
@@ -170,6 +172,11 @@ export const useProviderList = (): ProviderItem[] => {
         docUrl: urlJoin(BASE_DOC_URL, 'stepfun'),
         title: <Stepfun.Combine size={20} type={'color'} />,
       },
+      {
+        ...SparkProviderCard,
+        docUrl: urlJoin(BASE_DOC_URL, 'spark'),
+        title: <Spark.Combine size={ 20 } type={ 'color' } />,
+      },
     ],
     [azureProvider, ollamaProvider, ollamaProvider, bedrockProvider],
   );
diff --git a/src/app/api/chat/agentRuntime.ts b/src/app/api/chat/agentRuntime.ts
index 169559804bdc..761826525ca1 100644
--- a/src/app/api/chat/agentRuntime.ts
+++ b/src/app/api/chat/agentRuntime.ts
@@ -170,6 +170,13 @@ const getLlmOptionsFromPayload = (provider: string, payload: JWTPayload) => {
 
       const apiKey = apiKeyManager.pick(payload?.apiKey || STEPFUN_API_KEY);
 
+      return { apiKey };
+    }
+    case ModelProvider.Spark: {
+      const { SPARK_API_KEY } = getLLMConfig();
+
+      const apiKey = apiKeyManager.pick(payload?.apiKey || SPARK_API_KEY);
+
       return { apiKey };
     }
   }
diff --git a/src/components/ModelIcon/index.tsx b/src/components/ModelIcon/index.tsx
index cfac54db16a8..51e109bc3020 100644
--- a/src/components/ModelIcon/index.tsx
+++ b/src/components/ModelIcon/index.tsx
@@ -72,7 +72,9 @@ const ModelIcon = memo<ModelProviderIconProps>(({ model: originModel, size = 12
     return <Baichuan.Avatar background={Baichuan.colorPrimary} size={size} />;
   if (model.includes('rwkv')) return <Rwkv.Avatar size={size} />;
   if (model.includes('ernie')) return <Wenxin.Avatar size={size} />;
-  if (model.includes('spark')) return <Spark.Avatar size={size} />;
+  // ref https://www.xfyun.cn/doc/spark/HTTP%E8%B0%83%E7%94%A8%E6%96%87%E6%A1%A3.html#_3-%E8%AF%B7%E6%B1%82%E8%AF%B4%E6%98%8E
+  if (model.includes('spark') || model.startsWith('generalv'))
+    return <Spark.Avatar size={size} />;
   if (model.includes('hunyuan')) return <Hunyuan.Avatar size={size} />;
   // ref https://github.com/fishaudio/Bert-VITS2/blob/master/train_ms.py#L702
   if (model.startsWith('d_') || model.startsWith('g_') || model.startsWith('wd_'))
diff --git a/src/components/ModelProviderIcon/index.tsx b/src/components/ModelProviderIcon/index.tsx
index a0f2c181e4e4..343eaee6fb35 100644
--- a/src/components/ModelProviderIcon/index.tsx
+++ b/src/components/ModelProviderIcon/index.tsx
@@ -13,6 +13,7 @@ import {
   OpenAI,
   OpenRouter,
   Perplexity,
+  Spark,
   Stepfun,
   Together,
   Tongyi,
@@ -114,6 +115,10 @@ const ModelProviderIcon = memo<ModelProviderIconProps>(({ provider }) => {
       return <Stepfun size={20} />;
     }
 
+    case ModelProvider.Spark: {
+      return <Spark size={20} />;
+    }
+
     default: {
       return null;
     }
diff --git a/src/config/llm.ts b/src/config/llm.ts
index 775f7f61b811..d738d86368b4 100644
--- a/src/config/llm.ts
+++ b/src/config/llm.ts
@@ -82,6 +82,9 @@ export const getLLMConfig = () => {
 
       ENABLED_STEPFUN: z.boolean(),
       STEPFUN_API_KEY: z.string().optional(),
+
+      ENABLED_SPARK: z.boolean(),
+      SPARK_API_KEY: z.string().optional(),
     },
     runtimeEnv: {
       API_KEY_SELECT_MODE: process.env.API_KEY_SELECT_MODE,
@@ -155,6 +158,9 @@ export const getLLMConfig = () => {
 
       ENABLED_STEPFUN: !!process.env.STEPFUN_API_KEY,
       STEPFUN_API_KEY: process.env.STEPFUN_API_KEY,
+
+      ENABLED_SPARK: !!process.env.SPARK_API_KEY,
+      SPARK_API_KEY: process.env.SPARK_API_KEY,
     },
   });
 };
diff --git a/src/config/modelProviders/index.ts b/src/config/modelProviders/index.ts
index 4f61d4b0e0e5..c46e8b2d8a2c 100644
--- a/src/config/modelProviders/index.ts
+++ b/src/config/modelProviders/index.ts
@@ -14,6 +14,7 @@ import OpenAIProvider from './openai';
 import OpenRouterProvider from './openrouter';
 import PerplexityProvider from './perplexity';
 import QwenProvider from './qwen';
+import SparkProvider from './spark';
 import StepfunProvider from './stepfun';
 import TogetherAIProvider from './togetherai';
 import ZeroOneProvider from './zeroone';
@@ -37,6 +38,7 @@ export const LOBE_DEFAULT_MODEL_LIST: ChatModelCard[] = [
   AnthropicProvider.chatModels,
   ZeroOneProvider.chatModels,
   StepfunProvider.chatModels,
+  SparkProvider.chatModels,
 ].flat();
 
 export const DEFAULT_MODEL_PROVIDER_LIST = [
@@ -58,6 +60,7 @@ export const DEFAULT_MODEL_PROVIDER_LIST = [
   ZeroOneProvider,
   ZhiPuProvider,
   StepfunProvider,
+  SparkProvider,
 ];
 
 export const filterEnabledModels = (provider: ModelProviderCard) => {
@@ -78,6 +81,7 @@ export { default as OpenAIProviderCard } from './openai';
 export { default as OpenRouterProviderCard } from './openrouter';
 export { default as PerplexityProviderCard } from './perplexity';
 export { default as QwenProviderCard } from './qwen';
+export { default as SparkProviderCard } from './spark';
 export { default as StepfunProviderCard } from './stepfun';
 export { default as TogetherAIProviderCard } from './togetherai';
 export { default as ZeroOneProviderCard } from './zeroone';
diff --git a/src/config/modelProviders/spark.ts b/src/config/modelProviders/spark.ts
new file mode 100644
index 000000000000..cb60cdfe7513
--- /dev/null
+++ b/src/config/modelProviders/spark.ts
@@ -0,0 +1,53 @@
+import { ModelProviderCard } from '@/types/llm';
+
+// ref https://www.xfyun.cn/doc/spark/HTTP%E8%B0%83%E7%94%A8%E6%96%87%E6%A1%A3.html#_3-%E8%AF%B7%E6%B1%82%E8%AF%B4%E6%98%8E
+// ref https://www.xfyun.cn/doc/spark/Web.html#_1-%E6%8E%A5%E5%8F%A3%E8%AF%B4%E6%98%8E
+const Spark: ModelProviderCard = {
+  chatModels: [
+    {
+      description: '轻量级大语言模型，低延迟，全免费 支持在线联网搜索功能 响应快速、便捷，全面免费开放 适用于低算力推理与模型精调等定制化场景',
+      displayName: 'Spark Lite',
+      enabled: true,
+      functionCall: false,
+      id: 'generalv1.1',
+      maxOutput: 4096,
+    },
+    {
+      displayName: 'Spark v2.0',
+      enabled: true,
+      functionCall: false,
+      id: 'generalv2.1',
+      maxOutput: 4096,
+    },
+    {
+      description: '专业级大语言模型，兼顾模型效果与性能 数学、代码、医疗、教育等场景专项优化 支持联网搜索、天气、日期等多个内置插件 覆盖大部分知识问答、语言理解、文本创作等多个场景',
+      displayName: 'Spark Pro',
+      enabled: true,
+      functionCall: true,
+      id: 'generalv3.1',
+      maxOutput: 8192,
+    },
+    {
+      description: '最全面的星火大模型版本，功能丰富 支持联网搜索、天气、日期等多个内置插件 核心能力全面升级，各场景应用效果普遍提升 支持System角色人设与FunctionCall函数调用',
+      displayName: 'Spark Max',
+      enabled: true,
+      functionCall: true,
+      id: 'generalv3.5',
+      maxOutput: 8192,
+    },
+    {
+      description: '最强大的星火大模型版本，效果极佳 全方位提升效果，引领智能巅峰 优化联网搜索链路，提供精准回答 强化文本总结能力，提升办公生产力',
+      displayName: 'Spark4.0 Ultra',
+      enabled: true,
+      functionCall: false,
+      id: 'generalv4.0',
+      maxOutput: 8192,
+    },
+  ],
+  checkModel: 'generalv1.1',
+  id: 'spark',
+  modelList: { showModelFetcher: true },
+  name: 'Spark',
+};
+
+export default Spark;
diff --git a/src/const/settings/llm.ts b/src/const/settings/llm.ts
index f468b2cb7066..82acc677087b 100644
--- a/src/const/settings/llm.ts
+++ b/src/const/settings/llm.ts
@@ -12,6 +12,7 @@ import {
   OpenRouterProviderCard,
   PerplexityProviderCard,
   QwenProviderCard,
+  SparkProviderCard,
   StepfunProviderCard,
   TogetherAIProviderCard,
   ZeroOneProviderCard,
@@ -78,6 +79,10 @@ export const DEFAULT_LLM_CONFIG: UserModelProviderConfig = {
     enabled: false,
     enabledModels: filterEnabledModels(QwenProviderCard),
   },
+  spark: {
+    enabled: false,
+    enabledModels: filterEnabledModels(SparkProviderCard),
+  },
   stepfun: {
     enabled: false,
     enabledModels: filterEnabledModels(StepfunProviderCard),
diff --git a/src/libs/agent-runtime/AgentRuntime.ts b/src/libs/agent-runtime/AgentRuntime.ts
index 4ee26dbb7db7..6fb5ced6025e 100644
--- a/src/libs/agent-runtime/AgentRuntime.ts
+++ b/src/libs/agent-runtime/AgentRuntime.ts
@@ -17,6 +17,7 @@ import { LobeOpenAI } from './openai';
 import { LobeOpenRouterAI } from './openrouter';
 import { LobePerplexityAI } from './perplexity';
 import { LobeQwenAI } from './qwen';
+import { LobeSparkAI } from './spark';
 import { LobeStepfunAI } from './stepfun';
 import { LobeTogetherAI } from './togetherai';
 import {
@@ -115,6 +116,7 @@ class AgentRuntime {
       openrouter: Partial<ClientOptions>;
       perplexity: Partial<ClientOptions>;
       qwen: Partial<ClientOptions>;
+      spark: Partial<ClientOptions>;
       stepfun: Partial<ClientOptions>;
       togetherai: Partial<ClientOptions>;
       zeroone: Partial<ClientOptions>;
@@ -219,6 +221,11 @@ class AgentRuntime {
         runtimeModel = new LobeStepfunAI(params.stepfun ?? {});
         break;
       }
+
+      case ModelProvider.Spark: {
+        runtimeModel = new LobeSparkAI(params.spark ?? {});
+        break;
+      }
     }
 
     return new AgentRuntime(runtimeModel);
diff --git a/src/libs/agent-runtime/spark/index.test.ts b/src/libs/agent-runtime/spark/index.test.ts
new file mode 100644
index 000000000000..7b6b1a2b1a06
--- /dev/null
+++ b/src/libs/agent-runtime/spark/index.test.ts
@@ -0,0 +1,255 @@
+// @vitest-environment node
+import OpenAI from 'openai';
+import { Mock, afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
+
+import {
+  ChatStreamCallbacks,
+  LobeOpenAICompatibleRuntime,
+  ModelProvider,
+} from '@/libs/agent-runtime';
+
+import * as debugStreamModule from '../utils/debugStream';
+import { LobeSparkAI } from './index';
+
+const provider = ModelProvider.Spark;
+const defaultBaseURL = 'https://spark-api-open.xf-yun.com/v1';
+
+const bizErrorType = 'ProviderBizError';
+const invalidErrorType = 'InvalidProviderAPIKey';
+
+// Mock the console.error to avoid polluting test output
+vi.spyOn(console, 'error').mockImplementation(() => {});
+
+let instance: LobeOpenAICompatibleRuntime;
+
+beforeEach(() => {
+  instance = new LobeSparkAI({ apiKey: 'test' });
+
+  // 使用 vi.spyOn 来模拟 chat.completions.create 方法
+  vi.spyOn(instance['client'].chat.completions, 'create').mockResolvedValue(
+    new ReadableStream() as any,
+  );
+});
+
+afterEach(() => {
+  vi.clearAllMocks();
+});
+
+describe('LobeSparkAI', () => {
+  describe('init', () => {
+    it('should correctly initialize with an API key', async () => {
+      const instance = new LobeSparkAI({ apiKey: 'test_api_key' });
+      expect(instance).toBeInstanceOf(LobeSparkAI);
+      expect(instance.baseURL).toEqual(defaultBaseURL);
+    });
+  });
+
+  describe('chat', () => {
+    describe('Error', () => {
+      it('should return OpenAIBizError with an openai error response when OpenAI.APIError is thrown', async () => {
+        // Arrange
+        const apiError = new OpenAI.APIError(
+          400,
+          {
+            status: 400,
+            error: {
+              message: 'Bad Request',
+            },
+          },
+          'Error message',
+          {},
+        );
+
+        vi.spyOn(instance['client'].chat.completions, 'create').mockRejectedValue(apiError);
+
+        // Act
+        try {
+          await instance.chat({
+            messages: [{ content: 'Hello', role: 'user' }],
+            model: 'general',
+            temperature: 0,
+          });
+        } catch (e) {
+          expect(e).toEqual({
+            endpoint: defaultBaseURL,
+            error: {
+              error: { message: 'Bad Request' },
+              status: 400,
+            },
+            errorType: bizErrorType,
+            provider,
+          });
+        }
+      });
+
+      it('should throw AgentRuntimeError with NoOpenAIAPIKey if no apiKey is provided', async () => {
+        try {
+          new LobeSparkAI({});
+        } catch (e) {
+          expect(e).toEqual({ errorType: invalidErrorType });
+        }
+      });
+
+      it('should return OpenAIBizError with the cause when OpenAI.APIError is thrown with cause', async () => {
+        // Arrange
+        const errorInfo = {
+          stack: 'abc',
+          cause: {
+            message: 'api is undefined',
+          },
+        };
+        const apiError = new OpenAI.APIError(400, errorInfo, 'module error', {});
+
+        vi.spyOn(instance['client'].chat.completions, 'create').mockRejectedValue(apiError);
+
+        // Act
+        try {
+          await instance.chat({
+            messages: [{ content: 'Hello', role: 'user' }],
+            model: 'general',
+            temperature: 0,
+          });
+        } catch (e) {
+          expect(e).toEqual({
+            endpoint: defaultBaseURL,
+            error: {
+              cause: { message: 'api is undefined' },
+              stack: 'abc',
+            },
+            errorType: bizErrorType,
+            provider,
+          });
+        }
+      });
+
+      it('should return OpenAIBizError with an cause response with desensitize Url', async () => {
+        // Arrange
+        const errorInfo = {
+          stack: 'abc',
+          cause: { message: 'api is undefined' },
+        };
+        const apiError = new OpenAI.APIError(400, errorInfo, 'module error', {});
+
+        instance = new LobeSparkAI({
+          apiKey: 'test',
+
+          baseURL: 'https://api.abc.com/v1',
+        });
+
+        vi.spyOn(instance['client'].chat.completions, 'create').mockRejectedValue(apiError);
+
+        // Act
+        try {
+          await instance.chat({
+            messages: [{ content: 'Hello', role: 'user' }],
+            model: 'general',
+            temperature: 0,
+          });
+        } catch (e) {
+          expect(e).toEqual({
+            endpoint: 'https://api.***.com/v1',
+            error: {
+              cause: { message: 'api is undefined' },
+              stack: 'abc',
+            },
+            errorType: bizErrorType,
+            provider,
+          });
+        }
+      });
+
+      it('should throw an InvalidSparkAPIKey error type on 401 status code', async () => {
+        // Mock the API call to simulate a 401 error
+        const error = new Error('Unauthorized') as any;
+        error.status = 401;
+        vi.mocked(instance['client'].chat.completions.create).mockRejectedValue(error);
+
+        try {
+          await instance.chat({
+            messages: [{ content: 'Hello', role: 'user' }],
+            model: 'general',
+            temperature: 0,
+          });
+        } catch (e) {
+          // Expect the chat method to throw an error with InvalidSparkAPIKey
+          expect(e).toEqual({
+            endpoint: defaultBaseURL,
+            error: new Error('Unauthorized'),
+            errorType: invalidErrorType,
+            provider,
+          });
+        }
+      });
+
+      it('should return AgentRuntimeError for non-OpenAI errors', async () => {
+        // Arrange
+        const genericError = new Error('Generic Error');
+
+        vi.spyOn(instance['client'].chat.completions, 'create').mockRejectedValue(genericError);
+
+        // Act
+        try {
+          await instance.chat({
+            messages: [{ content: 'Hello', role: 'user' }],
+            model: 'general',
+            temperature: 0,
+          });
+        } catch (e) {
+          expect(e).toEqual({
+            endpoint: defaultBaseURL,
+            errorType: 'AgentRuntimeError',
+            provider,
+            error: {
+              name: genericError.name,
+              cause: genericError.cause,
+              message: genericError.message,
+              stack: genericError.stack,
+            },
+          });
+        }
+      });
+    });
+
+    describe('DEBUG', () => {
+      it('should call debugStream and return StreamingTextResponse when DEBUG_SPARK_CHAT_COMPLETION is 1', async () => {
+        // Arrange
+        const mockProdStream = new ReadableStream() as any; // 模拟的 prod 流
+        const mockDebugStream = new ReadableStream({
+          start(controller) {
+            controller.enqueue('Debug stream content');
+            controller.close();
+          },
+        }) as any;
+        mockDebugStream.toReadableStream = () => mockDebugStream; // 添加 toReadableStream 方法
+
+        // 模拟 chat.completions.create 返回值，包括模拟的 tee 方法
+        (instance['client'].chat.completions.create as Mock).mockResolvedValue({
+          tee: () => [mockProdStream, { toReadableStream: () => mockDebugStream }],
+        });
+
+        // 保存原始环境变量值
+        const originalDebugValue = process.env.DEBUG_SPARK_CHAT_COMPLETION;
+
+        // 模拟环境变量
+        process.env.DEBUG_SPARK_CHAT_COMPLETION = '1';
+        vi.spyOn(debugStreamModule, 'debugStream').mockImplementation(() => Promise.resolve());
+
+        // 执行测试
+        // 运行你的测试函数，确保它会在条件满足时调用 debugStream
+        // 假设的测试函数调用，你可能需要根据实际情况调整
+        await instance.chat({
+          messages: [{ content: 'Hello', role: 'user' }],
+          model: 'general',
+          stream: true,
+          temperature: 0,
+        });
+
+        // 验证 debugStream 被调用
+        expect(debugStreamModule.debugStream).toHaveBeenCalled();
+
+        // 恢复原始环境变量值
+        process.env.DEBUG_SPARK_CHAT_COMPLETION = originalDebugValue;
+      });
+    });
+  });
+});
diff --git a/src/libs/agent-runtime/spark/index.ts b/src/libs/agent-runtime/spark/index.ts
new file mode 100644
index 000000000000..1646970a04e3
--- /dev/null
+++ b/src/libs/agent-runtime/spark/index.ts
@@ -0,0 +1,10 @@
+import { ModelProvider } from '../types';
+import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
+
+export const LobeSparkAI = LobeOpenAICompatibleFactory({
+  baseURL: 'https://spark-api-open.xf-yun.com/v1',
+  debug: {
+    chatCompletion: () => process.env.DEBUG_SPARK_CHAT_COMPLETION === '1',
+  },
+  provider: ModelProvider.Spark,
+});
diff --git a/src/libs/agent-runtime/types/type.ts b/src/libs/agent-runtime/types/type.ts
index bd5feef94b88..22e11d0e04b1 100644
--- a/src/libs/agent-runtime/types/type.ts
+++ b/src/libs/agent-runtime/types/type.ts
@@ -36,6 +36,7 @@ export enum ModelProvider {
   OpenRouter = 'openrouter',
   Perplexity = 'perplexity',
   Qwen = 'qwen',
+  Spark = 'spark',
   Stepfun = 'stepfun',
   TogetherAI = 'togetherai',
   ZeroOne = 'zeroone',
diff --git a/src/server/globalConfig/index.ts b/src/server/globalConfig/index.ts
index 614e5083cc34..265ff2b5ef26 100644
--- a/src/server/globalConfig/index.ts
+++ b/src/server/globalConfig/index.ts
@@ -34,6 +34,7 @@ export const getServerGlobalConfig = () => {
     ENABLED_MISTRAL,
     ENABLED_QWEN,
     ENABLED_STEPFUN,
+    ENABLED_SPARK,
 
     ENABLED_AZURE_OPENAI,
     AZURE_MODEL_LIST,
@@ -105,6 +106,7 @@ export const getServerGlobalConfig = () => {
       perplexity: { enabled: ENABLED_PERPLEXITY },
       qwen: { enabled: ENABLED_QWEN },
 
+      spark: { enabled: ENABLED_SPARK },
       stepfun: { enabled: ENABLED_STEPFUN },
 
       togetherai: {
diff --git a/src/types/user/settings/keyVaults.ts b/src/types/user/settings/keyVaults.ts
index 8fb1428d41e5..d5c9d3e11b51 100644
--- a/src/types/user/settings/keyVaults.ts
+++ b/src/types/user/settings/keyVaults.ts
@@ -32,6 +32,7 @@ export interface UserKeyVaults {
   password?: string;
   perplexity?: OpenAICompatibleKeyVault;
   qwen?: OpenAICompatibleKeyVault;
+  spark?: OpenAICompatibleKeyVault;
   stepfun?: OpenAICompatibleKeyVault;
   togetherai?: OpenAICompatibleKeyVault;
   zeroone?: OpenAICompatibleKeyVault;

From 0f1a9c70d3efd5a4cc634fb80803c0d3421a4448 Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Mon, 1 Jul 2024 15:47:12 +0800
Subject: [PATCH 02/17] =?UTF-8?q?=F0=9F=94=A8=20chore:=20split=20Spark=20A?=
 =?UTF-8?q?PI=20Key=20&=20Spark=20Secret?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 .../settings/llm/ProviderList/Spark/index.tsx | 58 +++++++++++++++++++
 .../settings/llm/ProviderList/providers.tsx   | 11 ++--
 src/app/api/chat/agentRuntime.ts              |  6 +-
 src/config/llm.ts                             |  4 +-
 src/const/auth.ts                             |  3 +
 src/locales/default/modelProvider.ts          | 12 ++++
 src/services/_auth.ts                         |  9 +++
 src/services/chat.ts                          |  7 +++
 .../slices/modelList/selectors/keyVaults.ts   |  2 +
 .../slices/modelList/selectors/modelConfig.ts |  3 +
 src/types/user/settings/keyVaults.ts          |  7 ++-
 11 files changed, 112 insertions(+), 10 deletions(-)
 create mode 100644 src/app/(main)/settings/llm/ProviderList/Spark/index.tsx

diff --git a/src/app/(main)/settings/llm/ProviderList/Spark/index.tsx b/src/app/(main)/settings/llm/ProviderList/Spark/index.tsx
new file mode 100644
index 000000000000..0ca65b714f26
--- /dev/null
+++ b/src/app/(main)/settings/llm/ProviderList/Spark/index.tsx
@@ -0,0 +1,58 @@
+'use client';
+
+import { Spark } from '@lobehub/icons';
+import { useTheme } from 'antd-style';
+
+import { Input } from 'antd';
+import { useTranslation } from 'react-i18next';
+
+import { SparkProviderCard } from '@/config/modelProviders';
+import { GlobalLLMProviderKey } from '@/types/user/settings';
+
+import { KeyVaultsConfigKey } from '../../const';
+import { ProviderItem } from '../../type';
+
+const providerKey: GlobalLLMProviderKey = 'spark';
+
+const SparkBrand = () => {
+  const theme = useTheme();
+  return (
+    <Spark.Combine
+      color={theme.isDarkMode ? theme.colorText : Spark.colorPrimary}
+      size={22}
+    />
+  );
+};
+
+export const useSparkProvider = (): ProviderItem => {
+  const { t } = useTranslation('modelProvider');
+
+  return {
+    ...SparkProviderCard,
+    apiKeyItems: [
+      {
+        children: (
+          <Input.Password
+            autoComplete={'new-password'}
+            placeholder={t('spark.sparkApiKey.placeholder')}
+          />
+        ),
+        desc: t('spark.sparkApiKey.desc'),
+        label: t('spark.sparkApiKey.title'),
+        name: [KeyVaultsConfigKey, providerKey, 'sparkApiKey'],
+      },
+      {
+        children: (
+          <Input.Password
+            autoComplete={'new-password'}
+            placeholder={t('spark.sparkApiSecret.placeholder')}
+          />
+        ),
+        desc: t('spark.sparkApiSecret.desc'),
+        label: t('spark.sparkApiSecret.title'),
+        name: [KeyVaultsConfigKey, providerKey, 'sparkApiSecret'],
+      },
+    ],
+    title: <SparkBrand />,
+  };
+};
diff --git a/src/app/(main)/settings/llm/ProviderList/providers.tsx b/src/app/(main)/settings/llm/ProviderList/providers.tsx
index e8a4039b96ee..5d960b659800 100644
--- a/src/app/(main)/settings/llm/ProviderList/providers.tsx
+++ b/src/app/(main)/settings/llm/ProviderList/providers.tsx
@@ -10,7 +10,6 @@ import {
   Moonshot,
   OpenRouter,
   Perplexity,
-  Spark,
   Stepfun,
   Together,
   Tongyi,
@@ -34,7 +33,6 @@ import {
   OpenRouterProviderCard,
   PerplexityProviderCard,
   QwenProviderCard,
-  SparkProviderCard,
   StepfunProviderCard,
   TogetherAIProviderCard,
   ZeroOneProviderCard,
@@ -46,6 +44,7 @@ import { useAzureProvider } from './Azure';
 import { useBedrockProvider } from './Bedrock';
 import { useOllamaProvider } from './Ollama';
 import { useOpenAIProvider } from './OpenAI';
+import { useSparkProvider } from './Spark';
 
 const BASE_DOC_URL = 'https://lobehub.com/docs/usage/providers';
 
@@ -83,6 +82,7 @@ export const useProviderList = (): ProviderItem[] => {
   const ollamaProvider = useOllamaProvider();
   const openAIProvider = useOpenAIProvider();
   const bedrockProvider = useBedrockProvider();
+  const sparkProvider = useSparkProvider();
 
   return useMemo(
     () => [
@@ -173,11 +173,10 @@ export const useProviderList = (): ProviderItem[] => {
         title: <Stepfun.Combine size={20} type={'color'} />,
       },
       {
-        ...SparkProviderCard,
-        docUrl: urlJoin(BASE_DOC_URL, 'spark'),
-        title: <Spark.Combine size={ 20 } type={ 'color' } />,
+        ...sparkProvider,
+        docUrl: urlJoin(BASE_DOC_URL, 'spark')
       },
     ],
-    [azureProvider, ollamaProvider, ollamaProvider, bedrockProvider],
+    [azureProvider, ollamaProvider, ollamaProvider, bedrockProvider, sparkProvider],
   );
 };
diff --git a/src/app/api/chat/agentRuntime.ts b/src/app/api/chat/agentRuntime.ts
index 761826525ca1..12eff153c0b3 100644
--- a/src/app/api/chat/agentRuntime.ts
+++ b/src/app/api/chat/agentRuntime.ts
@@ -173,10 +173,12 @@ const getLlmOptionsFromPayload = (provider: string, payload: JWTPayload) => {
       return { apiKey };
     }
     case ModelProvider.Spark: {
-      const { SPARK_API_KEY } = getLLMConfig();
+      const { SPARK_API_KEY, SPARK_API_SECRET } = getLLMConfig();
 
-      const apiKey = apiKeyManager.pick(payload?.apiKey || SPARK_API_KEY);
+      const sparkApiKey = payload?.sparkApiKey || SPARK_API_KEY;
+      const sparkApiSecret = payload?.sparkApiSecret || SPARK_API_SECRET;
 
+      const apiKey = sparkApiKey + ':' + sparkApiSecret;
       return { apiKey };
     }
   }
diff --git a/src/config/llm.ts b/src/config/llm.ts
index d738d86368b4..01bea17795ce 100644
--- a/src/config/llm.ts
+++ b/src/config/llm.ts
@@ -85,6 +85,7 @@ export const getLLMConfig = () => {
 
       ENABLED_SPARK: z.boolean(),
       SPARK_API_KEY: z.string().optional(),
+      SPARK_API_SECRET: z.string().optional(),
     },
     runtimeEnv: {
       API_KEY_SELECT_MODE: process.env.API_KEY_SELECT_MODE,
@@ -159,8 +160,9 @@ export const getLLMConfig = () => {
       ENABLED_STEPFUN: !!process.env.STEPFUN_API_KEY,
       STEPFUN_API_KEY: process.env.STEPFUN_API_KEY,
 
-      ENABLED_SPARK: !!process.env.SPARK_API_KEY,
+      ENABLED_SPARK: !!process.env.SPARK_API_KEY && !!process.env.SPARK_API_SECRET,
       SPARK_API_KEY: process.env.SPARK_API_KEY,
+      SPARK_API_SECRET: process.env.SPARK_API_SECRET,
     },
   });
 };
diff --git a/src/const/auth.ts b/src/const/auth.ts
index 1c0fd878dd35..949d345eb833 100644
--- a/src/const/auth.ts
+++ b/src/const/auth.ts
@@ -41,5 +41,8 @@ export interface JWTPayload {
    * in server db mode it's a user id
    */
   userId?: string;
+
+  sparkApiKey?: string;
+  sparkApiSecret?: string;
 }
 /* eslint-enable */
diff --git a/src/locales/default/modelProvider.ts b/src/locales/default/modelProvider.ts
index 89a222c462f7..61404c8dda4c 100644
--- a/src/locales/default/modelProvider.ts
+++ b/src/locales/default/modelProvider.ts
@@ -102,6 +102,18 @@ export default {
       title: '下载指定的 Ollama 模型',
     },
   },
+  spark: {
+    sparkApiKey: {
+      desc: '填入 Spark API Key',
+      placeholder: 'Spark API Key',
+      title: 'Spark API Key',
+    },
+    sparkApiSecret: {
+      desc: '填入 Spark API Secret',
+      placeholder: 'Spark API Secret',
+      title: 'Spark API Secret',
+    },
+  },
   zeroone: {
     title: '01.AI 零一万物',
   },
diff --git a/src/services/_auth.ts b/src/services/_auth.ts
index 6e8c98b04d9f..f8f157098ee2 100644
--- a/src/services/_auth.ts
+++ b/src/services/_auth.ts
@@ -36,6 +36,15 @@ export const getProviderAuthPayload = (provider: string) => {
       return { endpoint: config?.baseURL };
     }
 
+    case ModelProvider.Spark: {
+      const config = keyVaultsConfigSelectors.sparkConfig(useUserStore.getState());
+
+      return { 
+        sparkApiKey: config?.sparkApiKey, 
+        sparkApiSecret: config?.sparkApiSecret, 
+      };
+    }
+
     default: {
       const config = keyVaultsConfigSelectors.getVaultByProvider(provider as GlobalLLMProviderKey)(
         useUserStore.getState(),
diff --git a/src/services/chat.ts b/src/services/chat.ts
index f68f7344a28e..25a53638cbbb 100644
--- a/src/services/chat.ts
+++ b/src/services/chat.ts
@@ -158,6 +158,13 @@ export function initializeWithClientStore(provider: string, payload: any) {
     case ModelProvider.ZeroOne: {
       break;
     }
+    case ModelProvider.Spark: {
+      providerOptions = {
+        sparkApiKey: providerAuthPayload?.sparkApiKey,
+        sparkApiSecret: providerAuthPayload?.sparkApiSecret,
+      };
+      break;
+    }
   }
 
   /**
diff --git a/src/store/user/slices/modelList/selectors/keyVaults.ts b/src/store/user/slices/modelList/selectors/keyVaults.ts
index 0a9bbb265b65..9baea979c20a 100644
--- a/src/store/user/slices/modelList/selectors/keyVaults.ts
+++ b/src/store/user/slices/modelList/selectors/keyVaults.ts
@@ -16,6 +16,7 @@ const openAIConfig = (s: UserStore) => keyVaultsSettings(s).openai || {};
 const bedrockConfig = (s: UserStore) => keyVaultsSettings(s).bedrock || {};
 const ollamaConfig = (s: UserStore) => keyVaultsSettings(s).ollama || {};
 const azureConfig = (s: UserStore) => keyVaultsSettings(s).azure || {};
+const sparkConfig = (s: UserStore) => keyVaultsSettings(s).spark || {};
 const getVaultByProvider = (provider: GlobalLLMProviderKey) => (s: UserStore) =>
   (keyVaultsSettings(s)[provider] || {}) as OpenAICompatibleKeyVault &
     AzureOpenAIKeyVault &
@@ -42,4 +43,5 @@ export const keyVaultsConfigSelectors = {
   ollamaConfig,
   openAIConfig,
   password,
+  sparkConfig,
 };
diff --git a/src/store/user/slices/modelList/selectors/modelConfig.ts b/src/store/user/slices/modelList/selectors/modelConfig.ts
index d6e6fdf50215..31a01c767c57 100644
--- a/src/store/user/slices/modelList/selectors/modelConfig.ts
+++ b/src/store/user/slices/modelList/selectors/modelConfig.ts
@@ -65,6 +65,7 @@ const openAIConfig = (s: UserStore) => currentLLMSettings(s).openai;
 const bedrockConfig = (s: UserStore) => currentLLMSettings(s).bedrock;
 const ollamaConfig = (s: UserStore) => currentLLMSettings(s).ollama;
 const azureConfig = (s: UserStore) => currentLLMSettings(s).azure;
+const sparkConfig = (s: UserStore) => currentLLMSettings(s).spark;
 
 const isAzureEnabled = (s: UserStore) => currentLLMSettings(s).azure.enabled;
 
@@ -82,4 +83,6 @@ export const modelConfigSelectors = {
 
   ollamaConfig,
   openAIConfig,
+
+  sparkConfig,
 };
diff --git a/src/types/user/settings/keyVaults.ts b/src/types/user/settings/keyVaults.ts
index d5c9d3e11b51..db13adad62b9 100644
--- a/src/types/user/settings/keyVaults.ts
+++ b/src/types/user/settings/keyVaults.ts
@@ -15,6 +15,11 @@ export interface AWSBedrockKeyVault {
   secretAccessKey?: string;
 }
 
+export interface SparkKeyVault {
+  sparkApiKey?: string;
+  sparkApiSecret?: string;
+}
+
 export interface UserKeyVaults {
   anthropic?: OpenAICompatibleKeyVault;
   azure?: AzureOpenAIKeyVault;
@@ -32,7 +37,7 @@ export interface UserKeyVaults {
   password?: string;
   perplexity?: OpenAICompatibleKeyVault;
   qwen?: OpenAICompatibleKeyVault;
-  spark?: OpenAICompatibleKeyVault;
+  spark?: SparkKeyVault;
   stepfun?: OpenAICompatibleKeyVault;
   togetherai?: OpenAICompatibleKeyVault;
   zeroone?: OpenAICompatibleKeyVault;

From 4ef282382a8fd3680372242677abc645cb96135f Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Mon, 1 Jul 2024 16:17:52 +0800
Subject: [PATCH 03/17] =?UTF-8?q?=F0=9F=92=84=20style:=20update=20Spark=20?=
 =?UTF-8?q?icon?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 .../settings/llm/ProviderList/Spark/index.tsx       | 13 +++----------
 1 file changed, 3 insertions(+), 10 deletions(-)

diff --git a/src/app/(main)/settings/llm/ProviderList/Spark/index.tsx b/src/app/(main)/settings/llm/ProviderList/Spark/index.tsx
index 0ca65b714f26..36757425c2ab 100644
--- a/src/app/(main)/settings/llm/ProviderList/Spark/index.tsx
+++ b/src/app/(main)/settings/llm/ProviderList/Spark/index.tsx
@@ -1,7 +1,6 @@
 'use client';
 
 import { Spark } from '@lobehub/icons';
-import { useTheme } from 'antd-style';
 
 import { Input } from 'antd';
 import { useTranslation } from 'react-i18next';
@@ -14,15 +13,9 @@ import { ProviderItem } from '../../type';
 
 const providerKey: GlobalLLMProviderKey = 'spark';
 
-const SparkBrand = () => {
-  const theme = useTheme();
-  return (
-    <Spark.Combine
-      color={theme.isDarkMode ? theme.colorText : Spark.colorPrimary}
-      size={22}
-    />
-  );
-};
+const SparkBrand = () => (
+  <Spark.Combine size={ 20 } type={ 'color' } />
+);
 
 export const useSparkProvider = (): ProviderItem => {
   const { t } = useTranslation('modelProvider');

From 179bb0c60c107bd1f9abc72eeb683c51c813d871 Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Mon, 1 Jul 2024 16:32:59 +0800
Subject: [PATCH 04/17] =?UTF-8?q?=F0=9F=92=84=20style:=20update=20Spark=20?=
 =?UTF-8?q?icon=20size?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 src/app/(main)/settings/llm/ProviderList/Spark/index.tsx | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/src/app/(main)/settings/llm/ProviderList/Spark/index.tsx b/src/app/(main)/settings/llm/ProviderList/Spark/index.tsx
index 36757425c2ab..dda6e48aaad8 100644
--- a/src/app/(main)/settings/llm/ProviderList/Spark/index.tsx
+++ b/src/app/(main)/settings/llm/ProviderList/Spark/index.tsx
@@ -14,7 +14,7 @@ import { ProviderItem } from '../../type';
 const providerKey: GlobalLLMProviderKey = 'spark';
 
 const SparkBrand = () => (
-  <Spark.Combine size={ 20 } type={ 'color' } />
+  <Spark.Combine size={ 22 } type={ 'color' } />
 );
 
 export const useSparkProvider = (): ProviderItem => {

From 3c6f392f7d4dfc098e70fcbd653b2a688e40b598 Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Mon, 1 Jul 2024 19:02:57 +0800
Subject: [PATCH 05/17] =?UTF-8?q?=F0=9F=92=84=20style:=20update=20Spark=20?=
 =?UTF-8?q?icon=20in=20ProviderAvatar?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 .../Conversation/Error/APIKeyForm/ProviderAvatar.tsx         | 5 +++++
 1 file changed, 5 insertions(+)

diff --git a/src/features/Conversation/Error/APIKeyForm/ProviderAvatar.tsx b/src/features/Conversation/Error/APIKeyForm/ProviderAvatar.tsx
index e937422d2989..2903c3307a42 100644
--- a/src/features/Conversation/Error/APIKeyForm/ProviderAvatar.tsx
+++ b/src/features/Conversation/Error/APIKeyForm/ProviderAvatar.tsx
@@ -9,6 +9,7 @@ import {
   OpenAI,
   OpenRouter,
   Perplexity,
+  Spark,
   Together,
   Tongyi,
   ZeroOne,
@@ -71,6 +72,10 @@ const ProviderAvatar = memo<ProviderAvatarProps>(({ provider }) => {
       return <Tongyi color={Tongyi.colorPrimary} size={56} />;
     }
 
+    case ModelProvider.Spark: {
+      return <Spark color={Spark.colorPrimary} size={56} />;
+    }
+
     case ModelProvider.TogetherAI: {
       return <Together color={Together.colorPrimary} size={56} />;
     }

From bbced9396b136440e951f45a8e64fd6bbab8dfb3 Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Mon, 1 Jul 2024 23:17:30 +0800
Subject: [PATCH 06/17] =?UTF-8?q?=F0=9F=94=A8=20chore:=20update=20Spark=20?=
 =?UTF-8?q?models?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 src/components/ModelIcon/index.tsx |  2 +-
 src/config/modelProviders/spark.ts | 14 +++++++-------
 2 files changed, 8 insertions(+), 8 deletions(-)

diff --git a/src/components/ModelIcon/index.tsx b/src/components/ModelIcon/index.tsx
index 51e109bc3020..ec3802a28ac7 100644
--- a/src/components/ModelIcon/index.tsx
+++ b/src/components/ModelIcon/index.tsx
@@ -73,7 +73,7 @@ const ModelIcon = memo<ModelProviderIconProps>(({ model: originModel, size = 12
   if (model.includes('rwkv')) return <Rwkv.Avatar size={size} />;
   if (model.includes('ernie')) return <Wenxin.Avatar size={size} />;
   // ref https://www.xfyun.cn/doc/spark/HTTP%E8%B0%83%E7%94%A8%E6%96%87%E6%A1%A3.html#_3-%E8%AF%B7%E6%B1%82%E8%AF%B4%E6%98%8E
-  if (model.includes('spark') || model.startsWith('generalv'))
+  if (model.includes('spark') || model.startsWith('general') || model.startsWith('4.0Ultra'))
     return <Spark.Avatar size={size} />;
   if (model.includes('hunyuan')) return <Hunyuan.Avatar size={size} />;
   // ref https://github.com/fishaudio/Bert-VITS2/blob/master/train_ms.py#L702
diff --git a/src/config/modelProviders/spark.ts b/src/config/modelProviders/spark.ts
index cb60cdfe7513..eacce6d4fbde 100644
--- a/src/config/modelProviders/spark.ts
+++ b/src/config/modelProviders/spark.ts
@@ -7,16 +7,16 @@ const Spark: ModelProviderCard = {
     {
       description: '轻量级大语言模型，低延迟，全免费 支持在线联网搜索功能 响应快速、便捷，全面免费开放 适用于低算力推理与模型精调等定制化场景',
       displayName: 'Spark Lite',
-      enabled: true,
+      enabled: false,
       functionCall: false,
-      id: 'generalv1.1',
+      id: 'general',
       maxOutput: 4096,
     },
     {
       displayName: 'Spark v2.0',
-      enabled: true,
+      enabled: false,
       functionCall: false,
-      id: 'generalv2.1',
+      id: 'generalv2',
       maxOutput: 4096,
     },
     {
@@ -24,7 +24,7 @@ const Spark: ModelProviderCard = {
       displayName: 'Spark Pro',
       enabled: true,
       functionCall: true,
-      id: 'generalv3.1',
+      id: 'generalv3',
       maxOutput: 8192,
     },
     {
@@ -40,11 +40,11 @@ const Spark: ModelProviderCard = {
       displayName: 'Spark4.0 Ultra',
       enabled: true,
       functionCall: false,
-      id: 'generalv4.0',
+      id: '4.0Ultra',
       maxOutput: 8192,
     },
   ],
-  checkModel: 'generalv1.1',
+  checkModel: 'generalv3',
   id: 'spark',
   modelList: { showModelFetcher: true },
   name: 'Spark',

From 0bd2c334063ad645d0306efad1c8316738527958 Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Mon, 1 Jul 2024 23:56:43 +0800
Subject: [PATCH 07/17] =?UTF-8?q?=F0=9F=94=A8=20chore:=20update=20Spark=20?=
 =?UTF-8?q?models?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 src/config/modelProviders/spark.ts | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/src/config/modelProviders/spark.ts b/src/config/modelProviders/spark.ts
index eacce6d4fbde..cc878fd1696b 100644
--- a/src/config/modelProviders/spark.ts
+++ b/src/config/modelProviders/spark.ts
@@ -39,7 +39,7 @@ const Spark: ModelProviderCard = {
       description: '最强大的星火大模型版本，效果极佳 全方位提升效果，引领智能巅峰 优化联网搜索链路，提供精准回答 强化文本总结能力，提升办公生产力',
       displayName: 'Spark4.0 Ultra',
       enabled: true,
-      functionCall: false,
+      functionCall: true,
       id: '4.0Ultra',
       maxOutput: 8192,
     },

From df1c498dc7bcb056870d031b28bb6ababf2fd402 Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Tue, 2 Jul 2024 09:36:20 +0800
Subject: [PATCH 08/17] =?UTF-8?q?=F0=9F=92=84=20style:=20fixed=20Spark=204?=
 =?UTF-8?q?.0=20Ultra=20model=20icon=20display?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 src/components/ModelIcon/index.tsx | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/src/components/ModelIcon/index.tsx b/src/components/ModelIcon/index.tsx
index ec3802a28ac7..d2c7e998bf5e 100644
--- a/src/components/ModelIcon/index.tsx
+++ b/src/components/ModelIcon/index.tsx
@@ -73,7 +73,7 @@ const ModelIcon = memo<ModelProviderIconProps>(({ model: originModel, size = 12
   if (model.includes('rwkv')) return <Rwkv.Avatar size={size} />;
   if (model.includes('ernie')) return <Wenxin.Avatar size={size} />;
   // ref https://www.xfyun.cn/doc/spark/HTTP%E8%B0%83%E7%94%A8%E6%96%87%E6%A1%A3.html#_3-%E8%AF%B7%E6%B1%82%E8%AF%B4%E6%98%8E
-  if (model.includes('spark') || model.startsWith('general') || model.startsWith('4.0Ultra'))
+  if (model.includes('spark') || model.startsWith('general') || model.startsWith('4.0ultra'))
     return <Spark.Avatar size={size} />;
   if (model.includes('hunyuan')) return <Hunyuan.Avatar size={size} />;
   // ref https://github.com/fishaudio/Bert-VITS2/blob/master/train_ms.py#L702

From 24dcc2b1abeb4b4539105e9998ad1ee95cdd8715 Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Tue, 2 Jul 2024 10:20:26 +0800
Subject: [PATCH 09/17] =?UTF-8?q?=F0=9F=94=A8=20chore:=20update=20Spark=20?=
 =?UTF-8?q?models=20info?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 src/config/modelProviders/spark.ts | 6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/src/config/modelProviders/spark.ts b/src/config/modelProviders/spark.ts
index cc878fd1696b..026310e9f210 100644
--- a/src/config/modelProviders/spark.ts
+++ b/src/config/modelProviders/spark.ts
@@ -23,7 +23,7 @@ const Spark: ModelProviderCard = {
       description: '专业级大语言模型，兼顾模型效果与性能 数学、代码、医疗、教育等场景专项优化 支持联网搜索、天气、日期等多个内置插件 覆盖大部分知识问答、语言理解、文本创作等多个场景',
       displayName: 'Spark Pro',
       enabled: true,
-      functionCall: true,
+      functionCall: false,
       id: 'generalv3',
       maxOutput: 8192,
     },
@@ -31,7 +31,7 @@ const Spark: ModelProviderCard = {
       description: '最全面的星火大模型版本，功能丰富 支持联网搜索、天气、日期等多个内置插件 核心能力全面升级，各场景应用效果普遍提升 支持System角色人设与FunctionCall函数调用',
       displayName: 'Spark Max',
       enabled: true,
-      functionCall: true,
+      functionCall: false,
       id: 'generalv3.5',
       maxOutput: 8192,
     },
@@ -39,7 +39,7 @@ const Spark: ModelProviderCard = {
       description: '最强大的星火大模型版本，效果极佳 全方位提升效果，引领智能巅峰 优化联网搜索链路，提供精准回答 强化文本总结能力，提升办公生产力',
       displayName: 'Spark4.0 Ultra',
       enabled: true,
-      functionCall: true,
+      functionCall: false,
       id: '4.0Ultra',
       maxOutput: 8192,
     },

From b782a9497a34cf8138aa20cd35d1fb162fa965ba Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Tue, 2 Jul 2024 15:25:40 +0800
Subject: [PATCH 10/17] =?UTF-8?q?=F0=9F=94=A8=20chore:=20update=20Spark=20?=
 =?UTF-8?q?models=20tokens=20info?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 src/config/modelProviders/spark.ts | 5 +++++
 1 file changed, 5 insertions(+)

diff --git a/src/config/modelProviders/spark.ts b/src/config/modelProviders/spark.ts
index 026310e9f210..616d9ca2faf6 100644
--- a/src/config/modelProviders/spark.ts
+++ b/src/config/modelProviders/spark.ts
@@ -11,6 +11,7 @@ const Spark: ModelProviderCard = {
       functionCall: false,
       id: 'general',
       maxOutput: 4096,
+      tokens: 8192,
     },
     {
       displayName: 'Spark v2.0',
@@ -18,6 +19,7 @@ const Spark: ModelProviderCard = {
       functionCall: false,
       id: 'generalv2',
       maxOutput: 4096,
+      tokens: 8192,
     },
     {
       description: '专业级大语言模型，兼顾模型效果与性能 数学、代码、医疗、教育等场景专项优化 支持联网搜索、天气、日期等多个内置插件 覆盖大部分知识问答、语言理解、文本创作等多个场景',
@@ -26,6 +28,7 @@ const Spark: ModelProviderCard = {
       functionCall: false,
       id: 'generalv3',
       maxOutput: 8192,
+      tokens: 8192,
     },
     {
       description: '最全面的星火大模型版本，功能丰富 支持联网搜索、天气、日期等多个内置插件 核心能力全面升级，各场景应用效果普遍提升 支持System角色人设与FunctionCall函数调用',
@@ -34,6 +37,7 @@ const Spark: ModelProviderCard = {
       functionCall: false,
       id: 'generalv3.5',
       maxOutput: 8192,
+      tokens: 8192,
     },
     {
       description: '最强大的星火大模型版本，效果极佳 全方位提升效果，引领智能巅峰 优化联网搜索链路，提供精准回答 强化文本总结能力，提升办公生产力',
@@ -42,6 +46,7 @@ const Spark: ModelProviderCard = {
       functionCall: false,
       id: '4.0Ultra',
       maxOutput: 8192,
+      tokens: 8192,
     },
   ],
   checkModel: 'generalv3',

From 4a8fa3ff9fd8ac6ed0b7fe7ea9e0b8b6f162c567 Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Wed, 3 Jul 2024 14:58:42 +0800
Subject: [PATCH 11/17] =?UTF-8?q?=F0=9F=94=A8=20chore:=20update=20Spark=20?=
 =?UTF-8?q?models=20info?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 src/config/modelProviders/spark.ts | 10 +---------
 1 file changed, 1 insertion(+), 9 deletions(-)

diff --git a/src/config/modelProviders/spark.ts b/src/config/modelProviders/spark.ts
index 616d9ca2faf6..9a8fd801e12b 100644
--- a/src/config/modelProviders/spark.ts
+++ b/src/config/modelProviders/spark.ts
@@ -7,20 +7,12 @@ const Spark: ModelProviderCard = {
     {
       description: '轻量级大语言模型，低延迟，全免费 支持在线联网搜索功能 响应快速、便捷，全面免费开放 适用于低算力推理与模型精调等定制化场景',
       displayName: 'Spark Lite',
-      enabled: false,
+      enabled: true,
       functionCall: false,
       id: 'general',
       maxOutput: 4096,
       tokens: 8192,
     },
-    {
-      displayName: 'Spark v2.0',
-      enabled: false,
-      functionCall: false,
-      id: 'generalv2',
-      maxOutput: 4096,
-      tokens: 8192,
-    },
     {
       description: '专业级大语言模型，兼顾模型效果与性能 数学、代码、医疗、教育等场景专项优化 支持联网搜索、天气、日期等多个内置插件 覆盖大部分知识问答、语言理解、文本创作等多个场景',
       displayName: 'Spark Pro',

From 140c2c7835b733d30971bf2a0c0aca896e956397 Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Fri, 5 Jul 2024 18:44:47 +0800
Subject: [PATCH 12/17] =?UTF-8?q?=F0=9F=90=9B=20fix:=20fixed=20"'$.header.?=
 =?UTF-8?q?uid'=20length=20must=20be=20less=20or=20equal=20than=2032"=20wi?=
 =?UTF-8?q?th=20Spark=20Lite?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 src/libs/agent-runtime/spark/index.ts                       | 3 +++
 .../agent-runtime/utils/openaiCompatibleFactory/index.ts    | 6 +++++-
 2 files changed, 8 insertions(+), 1 deletion(-)

diff --git a/src/libs/agent-runtime/spark/index.ts b/src/libs/agent-runtime/spark/index.ts
index 1646970a04e3..8cc8dfe1e28e 100644
--- a/src/libs/agent-runtime/spark/index.ts
+++ b/src/libs/agent-runtime/spark/index.ts
@@ -3,6 +3,9 @@ import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
 
 export const LobeSparkAI = LobeOpenAICompatibleFactory({
   baseURL: 'https://spark-api-open.xf-yun.com/v1',
+  chatCompletion: {
+    noUserId: true,
+  },
   debug: {
     chatCompletion: () => process.env.DEBUG_SPARK_CHAT_COMPLETION === '1',
   },
diff --git a/src/libs/agent-runtime/utils/openaiCompatibleFactory/index.ts b/src/libs/agent-runtime/utils/openaiCompatibleFactory/index.ts
index da5e94349b01..1fcb8bd62e68 100644
--- a/src/libs/agent-runtime/utils/openaiCompatibleFactory/index.ts
+++ b/src/libs/agent-runtime/utils/openaiCompatibleFactory/index.ts
@@ -32,6 +32,7 @@ interface OpenAICompatibleFactoryOptions {
   chatCompletion?: {
     handleError?: (error: any) => Omit<ChatCompletionErrorPayload, 'provider'> | undefined;
     handlePayload?: (payload: ChatStreamPayload) => OpenAI.ChatCompletionCreateParamsStreaming;
+    noUserId?: boolean;
   };
   constructorOptions?: ClientOptions;
   debug?: {
@@ -85,7 +86,10 @@ export const LobeOpenAICompatibleFactory = ({
             } as OpenAI.ChatCompletionCreateParamsStreaming);
 
         const response = await this.client.chat.completions.create(
-          { ...postPayload, user: options?.user },
+          {
+            ...postPayload,
+            ...(chatCompletion?.noUserId ? {} : { user: options?.user }) 
+          },
           {
             // https://github.com/lobehub/lobe-chat/pull/318
             headers: { Accept: '*/*' },

From 7881cf12caa9a014c03c51a5d400ccf5b356cf6d Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Sun, 7 Jul 2024 17:16:59 +0800
Subject: [PATCH 13/17] =?UTF-8?q?=F0=9F=92=84=20style:=20fix=20model=20tag?=
 =?UTF-8?q?=20icon=20missing?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 src/components/ModelTag/ModelIcon.tsx | 13 ++++++++++---
 1 file changed, 10 insertions(+), 3 deletions(-)

diff --git a/src/components/ModelTag/ModelIcon.tsx b/src/components/ModelTag/ModelIcon.tsx
index 5f90067926c6..a350db70229b 100644
--- a/src/components/ModelTag/ModelIcon.tsx
+++ b/src/components/ModelTag/ModelIcon.tsx
@@ -26,6 +26,7 @@ import {
   Rwkv,
   Spark,
   Stability,
+  Stepfun,
   Tongyi,
   Wenxin,
   Yi,
@@ -37,8 +38,11 @@ interface ModelIconProps {
   size?: number;
 }
 
-const ModelIcon = memo<ModelIconProps>(({ model, size = 12 }) => {
-  if (!model) return;
+const ModelIcon = memo<ModelIconProps>(({ originModel, size = 12 }) => {
+  if (!originModel) return;
+
+  // lower case the origin model so to better match more model id case
+  const model = originModel.toLowerCase();
 
   // currently supported models, maybe not in its own provider
   if (model.startsWith('gpt')) return <OpenAI size={size} />;
@@ -61,12 +65,15 @@ const ModelIcon = memo<ModelIconProps>(({ model, size = 12 }) => {
   if (model.startsWith('openchat')) return <OpenChat size={size} />;
   if (model.includes('command')) return <Cohere size={size} />;
   if (model.includes('dbrx')) return <Dbrx size={size} />;
+  if (model.includes('step')) return <Stepfun size={size} />;
 
   // below: To be supported in providers, move up if supported
   if (model.includes('baichuan')) return <Baichuan size={size} />;
   if (model.includes('rwkv')) return <Rwkv size={size} />;
   if (model.includes('ernie')) return <Wenxin size={size} />;
-  if (model.includes('spark')) return <Spark size={size} />;
+  // ref https://www.xfyun.cn/doc/spark/HTTP%E8%B0%83%E7%94%A8%E6%96%87%E6%A1%A3.html#_3-%E8%AF%B7%E6%B1%82%E8%AF%B4%E6%98%8E
+  if (model.includes('spark') || model.startsWith('general') || model.startsWith('4.0ultra'))
+    return <Spark size={size} />;
   if (model.includes('hunyuan')) return <Hunyuan size={size} />;
   // ref https://github.com/fishaudio/Bert-VITS2/blob/master/train_ms.py#L702
   if (model.startsWith('d_') || model.startsWith('g_') || model.startsWith('wd_'))

From c32f83f007f81be6544061e8ce8745248718ba86 Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Sun, 7 Jul 2024 17:28:44 +0800
Subject: [PATCH 14/17] =?UTF-8?q?=F0=9F=90=9B=20fix:=20fix=20typo=20in=20M?=
 =?UTF-8?q?odelIcon?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 src/components/ModelTag/ModelIcon.tsx | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/src/components/ModelTag/ModelIcon.tsx b/src/components/ModelTag/ModelIcon.tsx
index a350db70229b..9e1377530c85 100644
--- a/src/components/ModelTag/ModelIcon.tsx
+++ b/src/components/ModelTag/ModelIcon.tsx
@@ -38,7 +38,7 @@ interface ModelIconProps {
   size?: number;
 }
 
-const ModelIcon = memo<ModelIconProps>(({ originModel, size = 12 }) => {
+const ModelIcon = memo<ModelIconProps>(({ model: originModel, size = 12 }) => {
   if (!originModel) return;
 
   // lower case the origin model so to better match more model id case

From f53cb85d9362354365ef1a739d51f569c10e513b Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Sun, 7 Jul 2024 18:30:55 +0800
Subject: [PATCH 15/17] =?UTF-8?q?=F0=9F=94=A8=20chore:=20add=20unit=20test?=
 =?UTF-8?q?=20for=20noUserId?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 .../openaiCompatibleFactory/index.test.ts     | 86 +++++++++++++++++++
 1 file changed, 86 insertions(+)

diff --git a/src/libs/agent-runtime/utils/openaiCompatibleFactory/index.test.ts b/src/libs/agent-runtime/utils/openaiCompatibleFactory/index.test.ts
index 8c55a3c797d0..a662f132afcb 100644
--- a/src/libs/agent-runtime/utils/openaiCompatibleFactory/index.test.ts
+++ b/src/libs/agent-runtime/utils/openaiCompatibleFactory/index.test.ts
@@ -409,6 +409,92 @@ describe('LobeOpenAICompatibleFactory', () => {
       });
     });
 
+    describe('noUserId option', () => {
+      it('should not add user to payload when noUserId is true', async () => {
+        const LobeMockProvider = LobeOpenAICompatibleFactory({
+          baseURL: 'https://spark-api-open.xf-yun.com/v1',
+          chatCompletion: {
+            noUserId: true,
+          },
+          provider: ModelProvider.Spark,
+        });
+    
+        const instance = new LobeMockProvider({ apiKey: 'test' });
+        const mockCreateMethod = vi.spyOn(instance['client'].chat.completions, 'create').mockResolvedValue(new ReadableStream() as any);
+    
+        await instance.chat(
+          {
+            messages: [{ content: 'Hello', role: 'user' }],
+            model: 'general',
+            temperature: 0,
+          },
+          { user: 'testUser' }
+        );
+    
+        expect(mockCreateMethod).toHaveBeenCalledWith(
+          expect.not.objectContaining({
+            user: 'testUser',
+          }),
+          expect.anything()
+        );
+      });
+    
+      it('should add user to payload when noUserId is false', async () => {
+        const LobeMockProvider = LobeOpenAICompatibleFactory({
+          baseURL: 'https://spark-api-open.xf-yun.com/v1',
+          chatCompletion: {
+            noUserId: false,
+          },
+          provider: ModelProvider.Spark,
+        });
+    
+        const instance = new LobeMockProvider({ apiKey: 'test' });
+        const mockCreateMethod = vi.spyOn(instance['client'].chat.completions, 'create').mockResolvedValue(new ReadableStream() as any);
+    
+        await instance.chat(
+          {
+            messages: [{ content: 'Hello', role: 'user' }],
+            model: 'general',
+            temperature: 0,
+          },
+          { user: 'testUser' }
+        );
+    
+        expect(mockCreateMethod).toHaveBeenCalledWith(
+          expect.objectContaining({
+            user: 'testUser',
+          }),
+          expect.anything()
+        );
+      });
+    
+      it('should add user to payload when noUserId is not set in chatCompletion', async () => {
+        const LobeMockProvider = LobeOpenAICompatibleFactory({
+          baseURL: 'https://spark-api-open.xf-yun.com/v1',
+          provider: ModelProvider.Spark,
+        });
+    
+        const instance = new LobeMockProvider({ apiKey: 'test' });
+        const mockCreateMethod = vi.spyOn(instance['client'].chat.completions, 'create').mockResolvedValue(new ReadableStream() as any);
+    
+        await instance.chat(
+          {
+            messages: [{ content: 'Hello', role: 'user' }],
+            model: 'general',
+            temperature: 0,
+          },
+          { user: 'testUser' }
+        );
+    
+        expect(mockCreateMethod).toHaveBeenCalledWith(
+          expect.objectContaining({
+            user: 'testUser',
+          }),
+          expect.anything()
+        );
+      });
+    });
+
     describe('cancel request', () => {
       it('should cancel ongoing request correctly', async () => {
         const controller = new AbortController();

From 302e01d181a8f949053e04df85d23f69d2149039 Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Tue, 9 Jul 2024 12:16:45 +0800
Subject: [PATCH 16/17] =?UTF-8?q?=F0=9F=94=A8=20chore:=20disable=20stream?=
 =?UTF-8?q?=20mode?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 src/libs/agent-runtime/spark/index.test.ts | 43 ----------------------
 src/libs/agent-runtime/spark/index.ts      |  8 ++++
 2 files changed, 8 insertions(+), 43 deletions(-)

diff --git a/src/libs/agent-runtime/spark/index.test.ts b/src/libs/agent-runtime/spark/index.test.ts
index 7b6b1a2b1a06..db3b9eeff26d 100644
--- a/src/libs/agent-runtime/spark/index.test.ts
+++ b/src/libs/agent-runtime/spark/index.test.ts
@@ -8,7 +8,6 @@ import {
   ModelProvider,
 } from '@/libs/agent-runtime';
 
-import * as debugStreamModule from '../utils/debugStream';
 import { LobeSparkAI } from './index';
 
 const provider = ModelProvider.Spark;
@@ -209,47 +208,5 @@ describe('LobeSparkAI', () => {
         }
       });
     });
-
-    describe('DEBUG', () => {
-      it('should call debugStream and return StreamingTextResponse when DEBUG_SPARK_CHAT_COMPLETION is 1', async () => {
-        // Arrange
-        const mockProdStream = new ReadableStream() as any; // 模拟的 prod 流
-        const mockDebugStream = new ReadableStream({
-          start(controller) {
-            controller.enqueue('Debug stream content');
-            controller.close();
-          },
-        }) as any;
-        mockDebugStream.toReadableStream = () => mockDebugStream; // 添加 toReadableStream 方法
-
-        // 模拟 chat.completions.create 返回值，包括模拟的 tee 方法
-        (instance['client'].chat.completions.create as Mock).mockResolvedValue({
-          tee: () => [mockProdStream, { toReadableStream: () => mockDebugStream }],
-        });
-
-        // 保存原始环境变量值
-        const originalDebugValue = process.env.DEBUG_SPARK_CHAT_COMPLETION;
-
-        // 模拟环境变量
-        process.env.DEBUG_SPARK_CHAT_COMPLETION = '1';
-        vi.spyOn(debugStreamModule, 'debugStream').mockImplementation(() => Promise.resolve());
-
-        // 执行测试
-        // 运行你的测试函数，确保它会在条件满足时调用 debugStream
-        // 假设的测试函数调用，你可能需要根据实际情况调整
-        await instance.chat({
-          messages: [{ content: 'Hello', role: 'user' }],
-          model: 'general',
-          stream: true,
-          temperature: 0,
-        });
-
-        // 验证 debugStream 被调用
-        expect(debugStreamModule.debugStream).toHaveBeenCalled();
-
-        // 恢复原始环境变量值
-        process.env.DEBUG_SPARK_CHAT_COMPLETION = originalDebugValue;
-      });
-    });
   });
 });
diff --git a/src/libs/agent-runtime/spark/index.ts b/src/libs/agent-runtime/spark/index.ts
index 8cc8dfe1e28e..bdc59f8f4bcc 100644
--- a/src/libs/agent-runtime/spark/index.ts
+++ b/src/libs/agent-runtime/spark/index.ts
@@ -1,9 +1,17 @@
+import OpenAI from 'openai';
+
 import { ModelProvider } from '../types';
 import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
 
 export const LobeSparkAI = LobeOpenAICompatibleFactory({
   baseURL: 'https://spark-api-open.xf-yun.com/v1',
   chatCompletion: {
+    handlePayload: (payload) => {
+      return {
+        ...payload,
+        stream: false,
+      } as unknown as OpenAI.ChatCompletionCreateParamsStreaming;
+    },
     noUserId: true,
   },
   debug: {

From 931571a15c6e39ef07e98cafbf622849f2f1dadd Mon Sep 17 00:00:00 2001
From: Zhijie He <hezhijie0327@hotmail.com>
Date: Tue, 9 Jul 2024 16:15:24 +0800
Subject: [PATCH 17/17] =?UTF-8?q?Revert=20"=F0=9F=94=A8=20chore:=20disable?=
 =?UTF-8?q?=20stream=20mode"=20(#25)?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

This reverts commit 302e01d181a8f949053e04df85d23f69d2149039.
---
 src/libs/agent-runtime/spark/index.test.ts | 43 ++++++++++++++++++++++
 src/libs/agent-runtime/spark/index.ts      |  8 ----
 2 files changed, 43 insertions(+), 8 deletions(-)

diff --git a/src/libs/agent-runtime/spark/index.test.ts b/src/libs/agent-runtime/spark/index.test.ts
index db3b9eeff26d..7b6b1a2b1a06 100644
--- a/src/libs/agent-runtime/spark/index.test.ts
+++ b/src/libs/agent-runtime/spark/index.test.ts
@@ -8,6 +8,7 @@ import {
   ModelProvider,
 } from '@/libs/agent-runtime';
 
+import * as debugStreamModule from '../utils/debugStream';
 import { LobeSparkAI } from './index';
 
 const provider = ModelProvider.Spark;
@@ -208,5 +209,47 @@ describe('LobeSparkAI', () => {
         }
       });
     });
+
+    describe('DEBUG', () => {
+      it('should call debugStream and return StreamingTextResponse when DEBUG_SPARK_CHAT_COMPLETION is 1', async () => {
+        // Arrange
+        const mockProdStream = new ReadableStream() as any; // 模拟的 prod 流
+        const mockDebugStream = new ReadableStream({
+          start(controller) {
+            controller.enqueue('Debug stream content');
+            controller.close();
+          },
+        }) as any;
+        mockDebugStream.toReadableStream = () => mockDebugStream; // 添加 toReadableStream 方法
+
+        // 模拟 chat.completions.create 返回值，包括模拟的 tee 方法
+        (instance['client'].chat.completions.create as Mock).mockResolvedValue({
+          tee: () => [mockProdStream, { toReadableStream: () => mockDebugStream }],
+        });
+
+        // 保存原始环境变量值
+        const originalDebugValue = process.env.DEBUG_SPARK_CHAT_COMPLETION;
+
+        // 模拟环境变量
+        process.env.DEBUG_SPARK_CHAT_COMPLETION = '1';
+        vi.spyOn(debugStreamModule, 'debugStream').mockImplementation(() => Promise.resolve());
+
+        // 执行测试
+        // 运行你的测试函数，确保它会在条件满足时调用 debugStream
+        // 假设的测试函数调用，你可能需要根据实际情况调整
+        await instance.chat({
+          messages: [{ content: 'Hello', role: 'user' }],
+          model: 'general',
+          stream: true,
+          temperature: 0,
+        });
+
+        // 验证 debugStream 被调用
+        expect(debugStreamModule.debugStream).toHaveBeenCalled();
+
+        // 恢复原始环境变量值
+        process.env.DEBUG_SPARK_CHAT_COMPLETION = originalDebugValue;
+      });
+    });
   });
 });
diff --git a/src/libs/agent-runtime/spark/index.ts b/src/libs/agent-runtime/spark/index.ts
index bdc59f8f4bcc..8cc8dfe1e28e 100644
--- a/src/libs/agent-runtime/spark/index.ts
+++ b/src/libs/agent-runtime/spark/index.ts
@@ -1,17 +1,9 @@
-import OpenAI from 'openai';
-
 import { ModelProvider } from '../types';
 import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
 
 export const LobeSparkAI = LobeOpenAICompatibleFactory({
   baseURL: 'https://spark-api-open.xf-yun.com/v1',
   chatCompletion: {
-    handlePayload: (payload) => {
-      return {
-        ...payload,
-        stream: false,
-      } as unknown as OpenAI.ChatCompletionCreateParamsStreaming;
-    },
     noUserId: true,
   },
   debug: {
