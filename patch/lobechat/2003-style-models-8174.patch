diff --git a/locales/ar/chat.json b/locales/ar/chat.json
index 43a3d2c44ff95..77ac818caa943 100644
--- a/locales/ar/chat.json
+++ b/locales/ar/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "شدة الاستدلال"
     },
+    "thinking": {
+      "title": "مفتاح التفكير العميق"
+    },
     "title": "وظائف توسيع النموذج"
   },
   "history": {
diff --git a/locales/ar/models.json b/locales/ar/models.json
index d987a01464e14..86377fae2b766 100644
--- a/locales/ar/models.json
+++ b/locales/ar/models.json
@@ -726,7 +726,7 @@
     "description": "Compound-beta-mini هو نظام ذكاء اصطناعي مركب، مدعوم بنماذج مفتوحة متاحة في GroqCloud، يمكنه استخدام الأدوات بشكل ذكي وانتقائي للإجابة على استفسارات المستخدمين."
   },
   "computer-use-preview": {
-    "description": "نموذج computer-use-preview هو نموذج مخصص مصمم خصيصًا لـ \"أدوات استخدام الكمبيوتر\"، تم تدريبه لفهم وتنفيذ المهام المتعلقة بالكمبيوتر."
+    "description": "نموذج computer-use-preview هو نموذج مخصص لأدوات \"استخدام الحاسوب\"، تم تدريبه لفهم وتنفيذ المهام المتعلقة بالحاسوب."
   },
   "dall-e-2": {
     "description": "النموذج الثاني من DALL·E، يدعم توليد صور أكثر واقعية ودقة، بدقة تعادل أربعة أضعاف الجيل الأول."
@@ -918,13 +918,13 @@
     "description": "Doubao-1.5-vision-lite هو نموذج كبير متعدد الوسائط تم ترقيته حديثًا، يدعم التعرف على الصور بدقة غير محدودة ونسب عرض إلى ارتفاع متطرفة، ويعزز قدرات الاستدلال البصري، التعرف على الوثائق، فهم المعلومات التفصيلية، واتباع التعليمات. يدعم نافذة سياق 128k، وطول الإخراج يدعم حتى 16k توكن."
   },
   "doubao-seed-1.6": {
-    "description": "نموذج Doubao-Seed-1.6 متعدد الوسائط للتفكير العميق، يدعم ثلاثة أوضاع تفكير: تلقائي/تفكير/عدم تفكير. في وضع عدم التفكير، يتحسن أداء النموذج بشكل كبير مقارنة بـ Doubao-1.5-pro/250115. يدعم نافذة سياق تصل إلى 256k وطول إخراج يصل إلى 16k رمز."
+    "description": "نموذج Doubao-Seed-1.6 متعدد الوسائط للتفكير العميق، يدعم ثلاثة أوضاع تفكير: تلقائي/تفكير/عدم تفكير. في وضع عدم التفكير، يتحسن أداء النموذج بشكل كبير مقارنة بـ Doubao-1.5-pro/250115. يدعم نافذة سياق بحجم 256k وطول إخراج يصل إلى 16k رمز."
   },
   "doubao-seed-1.6-flash": {
-    "description": "نموذج Doubao-Seed-1.6-flash هو نموذج متعدد الوسائط للتفكير العميق بسرعات استدلال فائقة، حيث يحتاج TPOT فقط إلى 10 مللي ثانية؛ يدعم فهم النصوص والرؤية، وتفوق قدرات فهم النصوص على الجيل السابق lite، وفهم الرؤية يضاهي نماذج pro المنافسة. يدعم نافذة سياق تصل إلى 256k وطول إخراج يصل إلى 16k رمز."
+    "description": "نموذج Doubao-Seed-1.6-flash للتفكير العميق متعدد الوسائط مع سرعة استدلال فائقة، حيث يحتاج TPOT فقط إلى 10 مللي ثانية؛ يدعم فهم النصوص والرؤية، وتفوق قدرات فهم النصوص على الجيل السابق lite، وفهم الرؤية يضاهي نماذج pro المنافسة. يدعم نافذة سياق بحجم 256k وطول إخراج يصل إلى 16k رمز."
   },
   "doubao-seed-1.6-thinking": {
-    "description": "نموذج Doubao-Seed-1.6-thinking يعزز قدرات التفكير بشكل كبير، مقارنة بـ Doubao-1.5-thinking-pro، مع تحسينات إضافية في القدرات الأساسية مثل البرمجة والرياضيات والاستدلال المنطقي، ويدعم الفهم البصري. يدعم نافذة سياق تصل إلى 256k وطول إخراج يصل إلى 16k رمز."
+    "description": "نموذج Doubao-Seed-1.6-thinking يعزز قدرات التفكير بشكل كبير، مقارنة بـ Doubao-1.5-thinking-pro، مع تحسينات إضافية في القدرات الأساسية مثل البرمجة والرياضيات والاستدلال المنطقي، ويدعم الفهم البصري. يدعم نافذة سياق بحجم 256k وطول إخراج يصل إلى 16k رمز."
   },
   "emohaa": {
     "description": "Emohaa هو نموذج نفسي، يتمتع بقدرات استشارية متخصصة، يساعد المستخدمين في فهم القضايا العاطفية."
@@ -1869,7 +1869,7 @@
     "description": "o1 هو نموذج استدلال جديد من OpenAI، مناسب للمهام المعقدة التي تتطلب معرفة عامة واسعة. يحتوي هذا النموذج على 128K من السياق وتاريخ انتهاء المعرفة في أكتوبر 2023."
   },
   "o1-pro": {
-    "description": "سلسلة نماذج o1 مدربة بالتعلم المعزز، قادرة على التفكير قبل الإجابة وتنفيذ مهام استدلال معقدة. يستخدم نموذج o1-pro موارد حسابية أكبر للتفكير بشكل أعمق، مما يضمن تقديم إجابات ذات جودة أعلى باستمرار."
+    "description": "نماذج سلسلة o1 مدربة بالتعلم المعزز، قادرة على التفكير قبل الإجابة وتنفيذ مهام استدلال معقدة. يستخدم نموذج o1-pro موارد حسابية أكبر للتفكير الأعمق، مما يضمن تقديم إجابات ذات جودة أعلى باستمرار."
   },
   "o3": {
     "description": "o3 هو نموذج قوي شامل، يظهر أداءً ممتازًا في مجالات متعددة. يضع معايير جديدة في المهام الرياضية، العلمية، البرمجية، واستدلال الرؤية. كما أنه بارع في الكتابة التقنية واتباع التعليمات. يمكن للمستخدمين استخدامه لتحليل النصوص، الأكواد، والصور، وحل المشكلات المعقدة متعددة الخطوات."
@@ -1881,7 +1881,7 @@
     "description": "o3-mini هو أحدث نموذج استدلال صغير لدينا، يقدم ذكاءً عالياً تحت نفس تكاليف التأخير والأداء مثل o1-mini."
   },
   "o3-pro": {
-    "description": "نموذج o3-pro يستخدم المزيد من الحسابات للتفكير بشكل أعمق وتقديم إجابات أفضل دائمًا، ويدعم فقط الاستخدام ضمن Responses API."
+    "description": "نموذج o3-pro يستخدم موارد حسابية أكبر للتفكير الأعمق وتقديم إجابات أفضل باستمرار، ويدعم الاستخدام فقط عبر واجهة برمجة التطبيقات Responses API."
   },
   "o4-mini": {
     "description": "o4-mini هو أحدث نموذج صغير من سلسلة o. تم تحسينه للاستدلال السريع والفعال، ويظهر كفاءة وأداء عاليين في المهام البرمجية والرؤية."
diff --git a/locales/bg-BG/chat.json b/locales/bg-BG/chat.json
index 8dc0a0bbe4cf9..144dc93477992 100644
--- a/locales/bg-BG/chat.json
+++ b/locales/bg-BG/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "Интензитет на разсъждение"
     },
+    "thinking": {
+      "title": "Превключвател за дълбоко мислене"
+    },
     "title": "Разширени функции на модела"
   },
   "history": {
diff --git a/locales/bg-BG/models.json b/locales/bg-BG/models.json
index 55b4963df0540..3a09d006335e9 100644
--- a/locales/bg-BG/models.json
+++ b/locales/bg-BG/models.json
@@ -726,7 +726,7 @@
     "description": "Compound-beta-mini е композитна AI система, подкрепена от публично достъпни модели в GroqCloud, която интелигентно и селективно използва инструменти за отговор на запитвания на потребителите."
   },
   "computer-use-preview": {
-    "description": "Моделът computer-use-preview е специално създаден за „инструменти за използване на компютър“, обучен да разбира и изпълнява задачи, свързани с компютри."
+    "description": "Моделът computer-use-preview е специално разработен за „инструменти за използване на компютър“, обучен да разбира и изпълнява задачи, свързани с компютри."
   },
   "dall-e-2": {
     "description": "Второ поколение модел DALL·E, поддържащ по-реалистично и точно генериране на изображения, с резолюция 4 пъти по-висока от първото поколение."
@@ -918,13 +918,13 @@
     "description": "Doubao-1.5-vision-lite е ново обновление на мултимодалния модел, поддържащ разпознаване на изображения с произволна резолюция и екстремни съотношения на дължина и ширина, подобряващ способностите за визуални разсъждения, разпознаване на документи, разбиране на детайлна информация и следване на инструкции. Поддържа контекстуален прозорец от 128k, с максимална дължина на изхода от 16k токена."
   },
   "doubao-seed-1.6": {
-    "description": "Doubao-Seed-1.6 е нов мултимодален модел за дълбоко мислене, който поддържа три режима на мислене: auto, thinking и non-thinking. В non-thinking режим моделът значително превъзхожда Doubao-1.5-pro/250115. Поддържа контекстен прозорец от 256k и максимална дължина на изхода до 16k токена."
+    "description": "Doubao-Seed-1.6 е нов много модален модел за дълбоко мислене, който поддържа три режима на мислене: auto, thinking и non-thinking. В non-thinking режим моделът значително превъзхожда Doubao-1.5-pro/250115. Поддържа контекстен прозорец от 256k и максимална дължина на изхода до 16k токена."
   },
   "doubao-seed-1.6-flash": {
-    "description": "Doubao-Seed-1.6-flash е мултимодален модел за дълбоко мислене с изключително бързо изчисление, TPOT отнема само 10ms; поддържа както текстово, така и визуално разбиране, като текстовите му възможности надминават предишното поколение lite, а визуалното разбиране е на нивото на професионалните модели на конкурентите. Поддържа контекстен прозорец от 256k и максимална дължина на изхода до 16k токена."
+    "description": "Doubao-Seed-1.6-flash е изключително бърз много модален модел за дълбоко мислене с TPOT само 10ms; поддържа както текстово, така и визуално разбиране, като текстовите му възможности надминават предишното поколение lite, а визуалното разбиране е на нивото на професионалните модели на конкурентите. Поддържа контекстен прозорец от 256k и максимална дължина на изхода до 16k токена."
   },
   "doubao-seed-1.6-thinking": {
-    "description": "Doubao-Seed-1.6-thinking моделът значително подобрява способностите за мислене в сравнение с Doubao-1.5-thinking-pro, с допълнителни подобрения в кодиране, математика и логическо разсъждение, като поддържа визуално разбиране. Поддържа контекстен прозорец от 256k и максимална дължина на изхода до 16k токена."
+    "description": "Doubao-Seed-1.6-thinking моделът значително подобрява способностите за мислене в сравнение с Doubao-1.5-thinking-pro, с допълнителни подобрения в кодиране, математика и логическо разсъждение, като поддържа и визуално разбиране. Поддържа контекстен прозорец от 256k и максимална дължина на изхода до 16k токена."
   },
   "emohaa": {
     "description": "Emohaa е психологически модел с професионални консултантски способности, помагащ на потребителите да разберат емоционалните проблеми."
@@ -1305,7 +1305,7 @@
     "description": "GPT-4o mini е най-новият модел на OpenAI, след GPT-4 Omni, който поддържа текстово и визуално въвеждане и генерира текст. Като най-напредналият им малък модел, той е значително по-евтин от другите нови модели и е с над 60% по-евтин от GPT-3.5 Turbo. Запазва най-съвременната интелигентност, като същевременно предлага значителна стойност за парите. GPT-4o mini получи 82% на теста MMLU и в момента е с по-висок рейтинг от GPT-4 по предпочитания за чат."
   },
   "gpt-4o-mini-audio-preview": {
-    "description": "GPT-4o mini Audio модел, поддържа вход и изход на аудио."
+    "description": "GPT-4o mini аудио модел, поддържа вход и изход на аудио."
   },
   "gpt-4o-mini-realtime-preview": {
     "description": "Реален вариант на GPT-4o-mini, поддържащ вход и изход на аудио и текст в реално време."
diff --git a/locales/de-DE/chat.json b/locales/de-DE/chat.json
index 62f63e34a673e..dad3fc9a2f7f7 100644
--- a/locales/de-DE/chat.json
+++ b/locales/de-DE/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "Argumentationsstärke"
     },
+    "thinking": {
+      "title": "Tiefdenk-Schalter"
+    },
     "title": "Modell Erweiterungsfunktionen"
   },
   "history": {
diff --git a/locales/de-DE/models.json b/locales/de-DE/models.json
index 895cbb827fa09..023f21c59f209 100644
--- a/locales/de-DE/models.json
+++ b/locales/de-DE/models.json
@@ -918,10 +918,10 @@
     "description": "Doubao-1.5-vision-lite ist ein neu verbessertes multimodales großes Modell, das beliebige Auflösungen und extreme Seitenverhältnisse bei der Bilderkennung unterstützt und die Fähigkeiten in visueller Schlussfolgerung, Dokumentenerkennung, Detailverständnis und Befolgung von Anweisungen verbessert. Es unterstützt ein Kontextfenster von 128k und eine maximale Ausgabelänge von 16k Tokens."
   },
   "doubao-seed-1.6": {
-    "description": "Doubao-Seed-1.6 ist ein neues multimodales Modell für tiefgehendes Denken, das drei Denkmodi unterstützt: auto, thinking und non-thinking. Im non-thinking-Modus ist die Leistung im Vergleich zu Doubao-1.5-pro/250115 deutlich verbessert. Unterstützt ein Kontextfenster von 256k und eine maximale Ausgabelänge von 16k Tokens."
+    "description": "Doubao-Seed-1.6 ist ein neues multimodales Modell für tiefgehendes Denken, das drei Denkmodi unterstützt: auto, thinking und non-thinking. Im non-thinking-Modus ist die Modellleistung im Vergleich zu Doubao-1.5-pro/250115 deutlich verbessert. Unterstützt ein Kontextfenster von 256k und eine maximale Ausgabelänge von 16k Tokens."
   },
   "doubao-seed-1.6-flash": {
-    "description": "Doubao-Seed-1.6-flash ist ein multimodales Modell für tiefgehendes Denken mit extrem schneller Inferenzgeschwindigkeit, TPOT benötigt nur 10 ms; unterstützt sowohl Text- als auch visuelle Verarbeitung, die Textverständnisfähigkeit übertrifft die vorherige Lite-Generation, das visuelle Verständnis ist vergleichbar mit den Pro-Modellen der Konkurrenz. Unterstützt ein Kontextfenster von 256k und eine maximale Ausgabelänge von 16k Tokens."
+    "description": "Doubao-Seed-1.6-flash ist ein multimodales Modell für tiefgehendes Denken mit extrem schneller Inferenzgeschwindigkeit, TPOT benötigt nur 10 ms; unterstützt sowohl Text- als auch visuelles Verständnis, die Textverständnisfähigkeit übertrifft die vorherige Lite-Generation, das visuelle Verständnis ist vergleichbar mit den Pro-Modellen der Konkurrenz. Unterstützt ein Kontextfenster von 256k und eine maximale Ausgabelänge von 16k Tokens."
   },
   "doubao-seed-1.6-thinking": {
     "description": "Das Doubao-Seed-1.6-thinking Modell verfügt über stark verbesserte Denkfähigkeiten. Im Vergleich zu Doubao-1.5-thinking-pro wurden die Grundfähigkeiten in Coding, Mathematik und logischem Denken weiter verbessert und unterstützt visuelles Verständnis. Unterstützt ein Kontextfenster von 256k und eine maximale Ausgabelänge von 16k Tokens."
@@ -1869,7 +1869,7 @@
     "description": "o1 ist OpenAIs neues Inferenzmodell, das für komplexe Aufgaben geeignet ist, die umfangreiches Allgemeinwissen erfordern. Das Modell hat einen Kontext von 128K und einen Wissensstand bis Oktober 2023."
   },
   "o1-pro": {
-    "description": "Die o1-Modellreihe wurde durch verstärkendes Lernen trainiert, um vor der Antwort nachzudenken und komplexe logische Aufgaben auszuführen. Das o1-pro Modell nutzt mehr Rechenressourcen für tiefere Überlegungen und liefert dadurch kontinuierlich qualitativ hochwertigere Antworten."
+    "description": "Die o1-Serie wurde durch verstärkendes Lernen trainiert, um vor der Antwort nachzudenken und komplexe Schlussfolgerungen zu ziehen. Das o1-pro Modell nutzt mehr Rechenressourcen für tiefere Überlegungen und liefert dadurch kontinuierlich qualitativ hochwertigere Antworten."
   },
   "o3": {
     "description": "o3 ist ein vielseitiges und leistungsstarkes Modell, das in mehreren Bereichen hervorragende Leistungen zeigt. Es setzt neue Maßstäbe für mathematische, wissenschaftliche, programmiertechnische und visuelle Schlussfolgerungsaufgaben. Es ist auch versiert in technischer Schreibweise und der Befolgung von Anweisungen. Benutzer können es nutzen, um Texte, Code und Bilder zu analysieren und komplexe Probleme mit mehreren Schritten zu lösen."
diff --git a/locales/en-US/chat.json b/locales/en-US/chat.json
index e8350b4e11dd8..f5a0a62ad8e26 100644
--- a/locales/en-US/chat.json
+++ b/locales/en-US/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "Reasoning Intensity"
     },
+    "thinking": {
+      "title": "Deep Thinking Switch"
+    },
     "title": "Model Extension Features"
   },
   "history": {
diff --git a/locales/en-US/models.json b/locales/en-US/models.json
index 9f0b6c97e50f4..86dd6b0cbd8b6 100644
--- a/locales/en-US/models.json
+++ b/locales/en-US/models.json
@@ -921,10 +921,10 @@
     "description": "Doubao-Seed-1.6 is a brand-new multimodal deep thinking model supporting auto, thinking, and non-thinking modes. In non-thinking mode, its performance significantly surpasses Doubao-1.5-pro/250115. It supports a 256k context window and output lengths up to 16k tokens."
   },
   "doubao-seed-1.6-flash": {
-    "description": "Doubao-Seed-1.6-flash is an ultra-fast multimodal deep thinking model with inference speed as low as 10ms on TPOT; it supports both text and visual understanding. Its text comprehension exceeds the previous lite generation, and its visual understanding rivals competitor pro series models. It supports a 256k context window and output lengths up to 16k tokens."
+    "description": "Doubao-Seed-1.6-flash is an ultra-fast multimodal deep thinking model with TPOT inference speed as low as 10ms; it supports both text and visual understanding. Its text comprehension exceeds the previous lite generation, and its visual understanding rivals competitor pro series models. It supports a 256k context window and output lengths up to 16k tokens."
   },
   "doubao-seed-1.6-thinking": {
-    "description": "Doubao-Seed-1.6-thinking significantly enhances thinking capabilities compared to Doubao-1.5-thinking-pro, with further improvements in coding, math, and logical reasoning skills. It supports visual understanding and a 256k context window, with output lengths up to 16k tokens."
+    "description": "Doubao-Seed-1.6-thinking features greatly enhanced thinking capabilities. Compared to Doubao-1.5-thinking-pro, it further improves foundational skills such as coding, math, and logical reasoning, and supports visual understanding. It supports a 256k context window and output lengths up to 16k tokens."
   },
   "emohaa": {
     "description": "Emohaa is a psychological model with professional counseling capabilities, helping users understand emotional issues."
@@ -1881,7 +1881,7 @@
     "description": "o3-mini is our latest small inference model that delivers high intelligence while maintaining the same cost and latency targets as o1-mini."
   },
   "o3-pro": {
-    "description": "The o3-pro model employs increased computation for deeper thinking and consistently better answers. It is only available for use under the Responses API."
+    "description": "The o3-pro model employs greater computational power for deeper thinking and consistently provides better answers. It is only supported under the Responses API."
   },
   "o4-mini": {
     "description": "o4-mini is our latest small model in the o series. It is optimized for fast and efficient inference, demonstrating high efficiency and performance in coding and visual tasks."
diff --git a/locales/es-ES/chat.json b/locales/es-ES/chat.json
index c1ef975d04c04..b61056c42a165 100644
--- a/locales/es-ES/chat.json
+++ b/locales/es-ES/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "Intensidad de razonamiento"
     },
+    "thinking": {
+      "title": "Interruptor de pensamiento profundo"
+    },
     "title": "Funcionalidad de extensión del modelo"
   },
   "history": {
diff --git a/locales/es-ES/models.json b/locales/es-ES/models.json
index c2af7cec69f62..c69a7503a60fd 100644
--- a/locales/es-ES/models.json
+++ b/locales/es-ES/models.json
@@ -921,10 +921,10 @@
     "description": "Doubao-Seed-1.6 es un nuevo modelo multimodal de pensamiento profundo que soporta tres modos de pensamiento: automático, reflexivo y no reflexivo. En modo no reflexivo, el rendimiento del modelo mejora significativamente en comparación con Doubao-1.5-pro/250115. Soporta una ventana de contexto de 256k y una longitud máxima de salida de 16k tokens."
   },
   "doubao-seed-1.6-flash": {
-    "description": "Doubao-Seed-1.6-flash es un modelo multimodal de pensamiento profundo con velocidad de inferencia extrema, TPOT de solo 10 ms; soporta comprensión tanto textual como visual, con capacidad de comprensión textual superior a la generación lite anterior y comprensión visual comparable a la serie pro de competidores. Soporta una ventana de contexto de 256k y una longitud máxima de salida de 16k tokens."
+    "description": "Doubao-Seed-1.6-flash es un modelo multimodal de pensamiento profundo con velocidad de inferencia extrema, TPOT de solo 10 ms; soporta comprensión tanto textual como visual, con capacidad de comprensión textual superior a la generación lite anterior y comprensión visual comparable a los modelos pro de la competencia. Soporta una ventana de contexto de 256k y una longitud máxima de salida de 16k tokens."
   },
   "doubao-seed-1.6-thinking": {
-    "description": "El modelo Doubao-Seed-1.6-thinking tiene una capacidad de pensamiento significativamente mejorada. En comparación con Doubao-1.5-thinking-pro, mejora aún más en habilidades básicas como programación, matemáticas y razonamiento lógico, además de soportar comprensión visual. Soporta una ventana de contexto de 256k y una longitud máxima de salida de 16k tokens."
+    "description": "El modelo Doubao-Seed-1.6-thinking tiene una capacidad de pensamiento significativamente mejorada. En comparación con Doubao-1.5-thinking-pro, mejora aún más en habilidades básicas como programación, matemáticas y razonamiento lógico, y soporta comprensión visual. Soporta una ventana de contexto de 256k y una longitud máxima de salida de 16k tokens."
   },
   "emohaa": {
     "description": "Emohaa es un modelo psicológico con capacidades de consulta profesional, ayudando a los usuarios a comprender problemas emocionales."
@@ -1869,7 +1869,7 @@
     "description": "o1 es el nuevo modelo de inferencia de OpenAI, adecuado para tareas complejas que requieren un amplio conocimiento general. Este modelo tiene un contexto de 128K y una fecha de corte de conocimiento en octubre de 2023."
   },
   "o1-pro": {
-    "description": "La serie o1 ha sido entrenada mediante aprendizaje reforzado para pensar antes de responder y ejecutar tareas de razonamiento complejas. El modelo o1-pro utiliza más recursos computacionales para un pensamiento más profundo, proporcionando respuestas de calidad superior de manera continua."
+    "description": "La serie o1 ha sido entrenada mediante aprendizaje reforzado para pensar antes de responder y ejecutar tareas de razonamiento complejas. El modelo o1-pro utiliza más recursos computacionales para un pensamiento más profundo, proporcionando respuestas de calidad superior de manera constante."
   },
   "o3": {
     "description": "o3 es un modelo versátil y potente, que destaca en múltiples campos. Establece un nuevo estándar para tareas de matemáticas, ciencia, programación y razonamiento visual. También es hábil en redacción técnica y seguimiento de instrucciones. Los usuarios pueden utilizarlo para analizar texto, código e imágenes, resolviendo problemas complejos de múltiples pasos."
@@ -1881,7 +1881,7 @@
     "description": "o3-mini es nuestro último modelo de inferencia de tamaño pequeño, que ofrece alta inteligencia con los mismos objetivos de costo y latencia que o1-mini."
   },
   "o3-pro": {
-    "description": "El modelo o3-pro utiliza más capacidad computacional para pensar más profundamente y siempre ofrecer mejores respuestas, soportado únicamente bajo la API de Responses."
+    "description": "El modelo o3-pro utiliza más capacidad computacional para pensar más profundamente y siempre ofrecer mejores respuestas, y solo está disponible para uso bajo la API de Responses."
   },
   "o4-mini": {
     "description": "o4-mini es nuestro último modelo de la serie o en formato pequeño. Está optimizado para una inferencia rápida y efectiva, mostrando una alta eficiencia y rendimiento en tareas de codificación y visuales."
diff --git a/locales/fa-IR/chat.json b/locales/fa-IR/chat.json
index e622b15569d48..83bd4be41c299 100644
--- a/locales/fa-IR/chat.json
+++ b/locales/fa-IR/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "شدت استدلال"
     },
+    "thinking": {
+      "title": "کلید تفکر عمیق"
+    },
     "title": "ویژگی‌های گسترش مدل"
   },
   "history": {
diff --git a/locales/fa-IR/models.json b/locales/fa-IR/models.json
index 26be25cfdb84d..279320cfc3bc5 100644
--- a/locales/fa-IR/models.json
+++ b/locales/fa-IR/models.json
@@ -918,13 +918,13 @@
     "description": "Doubao-1.5-vision-lite مدل بزرگ چندرسانه‌ای به‌روز شده است که از شناسایی تصاویر با هر وضوح و نسبت ابعاد بسیار طولانی پشتیبانی می‌کند و توانایی‌های استدلال بصری، شناسایی مستندات، درک اطلاعات جزئی و پیروی از دستورات را تقویت می‌کند. از پنجره متن 128k و حداکثر طول خروجی 16k توکن پشتیبانی می‌کند."
   },
   "doubao-seed-1.6": {
-    "description": "مدل تفکر عمیق چندرسانه‌ای جدید Doubao-Seed-1.6 که از سه حالت تفکر auto/thinking/non-thinking پشتیبانی می‌کند. در حالت non-thinking، عملکرد مدل نسبت به Doubao-1.5-pro/250115 به‌طور قابل توجهی بهبود یافته است. از پنجره متنی ۲۵۶ هزار توکنی پشتیبانی می‌کند و طول خروجی تا ۱۶ هزار توکن قابل افزایش است."
+    "description": "مدل تفکر عمیق چندرسانه‌ای جدید Doubao-Seed-1.6 که از سه حالت تفکر auto/thinking/non-thinking پشتیبانی می‌کند. در حالت non-thinking، عملکرد مدل نسبت به Doubao-1.5-pro/250115 به‌طور قابل توجهی بهبود یافته است. از پنجره متنی ۲۵۶ هزار توکنی پشتیبانی می‌کند و طول خروجی تا ۱۶ هزار توکن را امکان‌پذیر می‌سازد."
   },
   "doubao-seed-1.6-flash": {
-    "description": "مدل تفکر عمیق چندرسانه‌ای Doubao-Seed-1.6-flash با سرعت استنتاج بسیار بالا، TPOT تنها ۱۰ میلی‌ثانیه است؛ همچنین از درک متن و تصویر پشتیبانی می‌کند، توانایی درک متنی آن از نسل قبلی lite بهتر است و درک تصویری آن با مدل‌های pro رقبا برابری می‌کند. از پنجره متنی ۲۵۶ هزار توکنی و طول خروجی تا ۱۶ هزار توکن پشتیبانی می‌کند."
+    "description": "مدل تفکر عمیق چندرسانه‌ای Doubao-Seed-1.6-flash با سرعت استنتاج بسیار بالا، TPOT تنها ۱۰ میلی‌ثانیه است؛ همچنین از درک متن و تصویر پشتیبانی می‌کند، توانایی درک متنی آن از نسل قبلی lite بهتر است و درک تصویری آن با مدل‌های pro رقبا برابری می‌کند. از پنجره متنی ۲۵۶ هزار توکنی پشتیبانی می‌کند و طول خروجی تا ۱۶ هزار توکن را امکان‌پذیر می‌سازد."
   },
   "doubao-seed-1.6-thinking": {
-    "description": "مدل Doubao-Seed-1.6-thinking با توانایی تفکر به‌طور قابل توجهی تقویت شده است، نسبت به Doubao-1.5-thinking-pro در مهارت‌های پایه‌ای مانند برنامه‌نویسی، ریاضیات و استدلال منطقی پیشرفت داشته و از درک تصویری پشتیبانی می‌کند. از پنجره متنی ۲۵۶ هزار توکنی و طول خروجی تا ۱۶ هزار توکن پشتیبانی می‌کند."
+    "description": "مدل Doubao-Seed-1.6-thinking با توانایی تفکر به‌طور قابل توجهی تقویت شده است، نسبت به Doubao-1.5-thinking-pro در مهارت‌های پایه‌ای مانند برنامه‌نویسی، ریاضیات و استدلال منطقی پیشرفت داشته و از درک تصویری پشتیبانی می‌کند. از پنجره متنی ۲۵۶ هزار توکنی پشتیبانی می‌کند و طول خروجی تا ۱۶ هزار توکن را امکان‌پذیر می‌سازد."
   },
   "emohaa": {
     "description": "Emohaa یک مدل روان‌شناختی است که دارای توانایی مشاوره حرفه‌ای بوده و به کاربران در درک مسائل احساسی کمک می‌کند."
@@ -1869,7 +1869,7 @@
     "description": "تمرکز بر استدلال پیشرفته و حل مسائل پیچیده، از جمله وظایف ریاضی و علمی. بسیار مناسب برای برنامه‌هایی که نیاز به درک عمیق از زمینه و جریان کاری خودمختار دارند."
   },
   "o1-pro": {
-    "description": "مدل‌های سری o1 با آموزش تقویتی قادر به تفکر پیش از پاسخ‌دهی و انجام وظایف استدلالی پیچیده هستند. مدل o1-pro از منابع محاسباتی بیشتری استفاده می‌کند تا تفکر عمیق‌تری داشته باشد و پاسخ‌های با کیفیت‌تری ارائه دهد."
+    "description": "مدل‌های سری o1 با آموزش تقویت یادگیری قادرند پیش از پاسخ‌دهی تفکر کنند و وظایف استدلال پیچیده را انجام دهند. مدل o1-pro از منابع محاسباتی بیشتری استفاده می‌کند تا تفکر عمیق‌تری داشته باشد و پاسخ‌های با کیفیت‌تری ارائه دهد."
   },
   "o3": {
     "description": "o3 یک مدل همه‌کاره و قدرتمند است که در چندین حوزه عملکرد عالی دارد. این مدل استاندارد جدیدی برای وظایف ریاضی، علمی، برنامه‌نویسی و استدلال بصری تعیین کرده است. همچنین در نوشتن فنی و پیروی از دستورات نیز مهارت دارد. کاربران می‌توانند از آن برای تحلیل متن، کد و تصاویر و حل مسائل پیچیده چند مرحله‌ای استفاده کنند."
diff --git a/locales/fr-FR/chat.json b/locales/fr-FR/chat.json
index 07ab2a181be3f..fa1e6a9f841e9 100644
--- a/locales/fr-FR/chat.json
+++ b/locales/fr-FR/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "Intensité du raisonnement"
     },
+    "thinking": {
+      "title": "Interrupteur de réflexion approfondie"
+    },
     "title": "Fonctionnalités d'extension du modèle"
   },
   "history": {
diff --git a/locales/fr-FR/models.json b/locales/fr-FR/models.json
index 012a7e51d6348..5031e7827105e 100644
--- a/locales/fr-FR/models.json
+++ b/locales/fr-FR/models.json
@@ -924,7 +924,7 @@
     "description": "Doubao-Seed-1.6-flash est un modèle multimodal de réflexion profonde à vitesse d'inférence extrême, avec un TPOT de seulement 10 ms ; il supporte à la fois la compréhension textuelle et visuelle, avec une capacité de compréhension textuelle supérieure à la génération lite précédente, et une compréhension visuelle comparable aux modèles pro des concurrents. Il prend en charge une fenêtre contextuelle de 256k et une longueur de sortie maximale de 16k tokens."
   },
   "doubao-seed-1.6-thinking": {
-    "description": "Le modèle Doubao-Seed-1.6-thinking a une capacité de réflexion considérablement renforcée. Par rapport à Doubao-1.5-thinking-pro, il améliore davantage les compétences de base telles que le codage, les mathématiques et le raisonnement logique, tout en supportant la compréhension visuelle. Il prend en charge une fenêtre contextuelle de 256k et une longueur de sortie maximale de 16k tokens."
+    "description": "Le modèle Doubao-Seed-1.6-thinking a une capacité de réflexion considérablement renforcée. Par rapport à Doubao-1.5-thinking-pro, il améliore davantage les compétences fondamentales telles que le codage, les mathématiques et le raisonnement logique, tout en supportant la compréhension visuelle. Il prend en charge une fenêtre contextuelle de 256k et une longueur de sortie maximale de 16k tokens."
   },
   "emohaa": {
     "description": "Emohaa est un modèle psychologique, doté de compétences de conseil professionnel, aidant les utilisateurs à comprendre les problèmes émotionnels."
diff --git a/locales/it-IT/chat.json b/locales/it-IT/chat.json
index 6d2873a17aaaf..98a657196462a 100644
--- a/locales/it-IT/chat.json
+++ b/locales/it-IT/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "Intensità del ragionamento"
     },
+    "thinking": {
+      "title": "Interruttore di pensiero profondo"
+    },
     "title": "Funzionalità di estensione del modello"
   },
   "history": {
diff --git a/locales/it-IT/models.json b/locales/it-IT/models.json
index 760167acb2579..cbfb036d56891 100644
--- a/locales/it-IT/models.json
+++ b/locales/it-IT/models.json
@@ -1869,7 +1869,7 @@
     "description": "o1 è il nuovo modello di inferenza di OpenAI, adatto a compiti complessi che richiedono una vasta conoscenza generale. Questo modello ha un contesto di 128K e una data di cutoff della conoscenza di ottobre 2023."
   },
   "o1-pro": {
-    "description": "La serie di modelli o1 è stata addestrata con apprendimento rinforzato, in grado di riflettere prima di rispondere ed eseguire compiti di ragionamento complessi. Il modello o1-pro utilizza più risorse computazionali per un pensiero più approfondito, offrendo risposte di qualità superiore in modo costante."
+    "description": "La serie di modelli o1 è stata addestrata con apprendimento rinforzato, in grado di riflettere prima di rispondere ed eseguire compiti di ragionamento complessi. Il modello o1-pro utilizza più risorse computazionali per un pensiero più approfondito, offrendo risposte di qualità superiore in modo continuo."
   },
   "o3": {
     "description": "o3 è un modello versatile e potente, che si distingue in vari campi. Stabilisce nuovi standard per compiti di matematica, scienza, programmazione e ragionamento visivo. È anche abile nella scrittura tecnica e nel seguire istruzioni. Gli utenti possono utilizzarlo per analizzare testi, codici e immagini, risolvendo problemi complessi in più passaggi."
diff --git a/locales/ja-JP/chat.json b/locales/ja-JP/chat.json
index cfd3e5785049a..01eecb92bdcd1 100644
--- a/locales/ja-JP/chat.json
+++ b/locales/ja-JP/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "推論の強度"
     },
+    "thinking": {
+      "title": "深い思考のスイッチ"
+    },
     "title": "モデル拡張機能"
   },
   "history": {
diff --git a/locales/ja-JP/models.json b/locales/ja-JP/models.json
index 2ad21273d8932..cd05881fb1d39 100644
--- a/locales/ja-JP/models.json
+++ b/locales/ja-JP/models.json
@@ -918,13 +918,13 @@
     "description": "Doubao-1.5-vision-liteは新たにアップグレードされた多モーダル大モデルで、任意の解像度と極端なアスペクト比の画像認識をサポートし、視覚推論、文書認識、詳細情報の理解、指示の遵守能力を強化しています。128kのコンテキストウィンドウをサポートし、出力長は最大16kトークンをサポートします。"
   },
   "doubao-seed-1.6": {
-    "description": "Doubao-Seed-1.6 は新しいマルチモーダル深層思考モデルで、auto/thinking/non-thinking の3つの思考モードをサポートします。non-thinking モードでは、Doubao-1.5-pro/250115 と比較して大幅に性能が向上しています。256k のコンテキストウィンドウをサポートし、最大16kトークンの出力長に対応しています。"
+    "description": "Doubao-Seed-1.6 は新しいマルチモーダル深層思考モデルで、auto/thinking/non-thinking の三つの思考モードをサポートします。non-thinking モードでは、Doubao-1.5-pro/250115 と比較して大幅に性能が向上しています。256k のコンテキストウィンドウをサポートし、最大 16k トークンの出力長に対応しています。"
   },
   "doubao-seed-1.6-flash": {
-    "description": "Doubao-Seed-1.6-flash は推論速度に極限を追求したマルチモーダル深層思考モデルで、TPOT はわずか10msです。テキストと視覚の理解を同時にサポートし、テキスト理解能力は前世代の lite を超え、視覚理解は競合の pro シリーズモデルに匹敵します。256k のコンテキストウィンドウをサポートし、最大16kトークンの出力長に対応しています。"
+    "description": "Doubao-Seed-1.6-flash は推論速度に優れたマルチモーダル深層思考モデルで、TPOT はわずか 10ms です。テキストと視覚の理解を同時にサポートし、テキスト理解能力は前世代の lite を超え、視覚理解は競合他社の pro シリーズモデルに匹敵します。256k のコンテキストウィンドウをサポートし、最大 16k トークンの出力長に対応しています。"
   },
   "doubao-seed-1.6-thinking": {
-    "description": "Doubao-Seed-1.6-thinking モデルは思考能力が大幅に強化されており、Doubao-1.5-thinking-pro と比較して、コーディング、数学、論理推論などの基礎能力がさらに向上しています。視覚理解もサポートしています。256k のコンテキストウィンドウをサポートし、最大16kトークンの出力長に対応しています。"
+    "description": "Doubao-Seed-1.6-thinking モデルは思考能力が大幅に強化されており、Doubao-1.5-thinking-pro と比較して、コーディング、数学、論理推論などの基礎能力がさらに向上しています。視覚理解もサポートしています。256k のコンテキストウィンドウをサポートし、最大 16k トークンの出力長に対応しています。"
   },
   "emohaa": {
     "description": "Emohaaは心理モデルで、専門的な相談能力を持ち、ユーザーが感情問題を理解するのを助けます。"
@@ -1305,7 +1305,7 @@
     "description": "GPT-4o miniは、OpenAIがGPT-4 Omniの後に発表した最新のモデルで、画像とテキストの入力をサポートし、テキストを出力します。最先端の小型モデルとして、最近の他の先進モデルよりもはるかに安価で、GPT-3.5 Turboよりも60%以上安価です。最先端の知能を維持しつつ、コストパフォーマンスが大幅に向上しています。GPT-4o miniはMMLUテストで82%のスコアを獲得し、現在チャットの好みではGPT-4よりも高い評価を得ています。"
   },
   "gpt-4o-mini-audio-preview": {
-    "description": "GPT-4o mini Audio モデルは音声の入力と出力に対応しています。"
+    "description": "GPT-4o mini Audio モデルは音声の入力と出力をサポートします。"
   },
   "gpt-4o-mini-realtime-preview": {
     "description": "GPT-4o-miniリアルタイムバージョン、音声とテキストのリアルタイム入力と出力をサポート"
@@ -1869,7 +1869,7 @@
     "description": "o1はOpenAIの新しい推論モデルで、広範な一般知識を必要とする複雑なタスクに適しています。このモデルは128Kのコンテキストを持ち、2023年10月の知識のカットオフがあります。"
   },
   "o1-pro": {
-    "description": "o1 シリーズモデルは強化学習で訓練されており、回答前に思考を行い、複雑な推論タスクを実行できます。o1-pro モデルはより多くの計算資源を使用してより深い思考を行い、継続的に高品質な回答を提供します。"
+    "description": "o1 シリーズモデルは強化学習により訓練されており、回答前に思考を行い、複雑な推論タスクを実行できます。o1-pro モデルはより多くの計算資源を使用してより深い思考を行い、継続的に高品質な回答を提供します。"
   },
   "o3": {
     "description": "o3は全能で強力なモデルで、複数の分野で優れたパフォーマンスを発揮します。数学、科学、プログラミング、視覚推論タスクの新たな基準を設定しました。また、技術的な執筆や指示の遵守にも優れています。ユーザーはこれを利用して、テキスト、コード、画像を分析し、複雑な多段階の問題を解決できます。"
diff --git a/locales/ko-KR/chat.json b/locales/ko-KR/chat.json
index f7b08820e3e41..921db3f371808 100644
--- a/locales/ko-KR/chat.json
+++ b/locales/ko-KR/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "추론 강도"
     },
+    "thinking": {
+      "title": "심층 사고 스위치"
+    },
     "title": "모델 확장 기능"
   },
   "history": {
diff --git a/locales/ko-KR/models.json b/locales/ko-KR/models.json
index 7158a77a319be..62175337523ed 100644
--- a/locales/ko-KR/models.json
+++ b/locales/ko-KR/models.json
@@ -918,13 +918,13 @@
     "description": "Doubao-1.5-vision-lite는 새롭게 업그레이드된 다중 모드 대모델로, 임의의 해상도와 극단적인 가로 세로 비율의 이미지 인식을 지원하며, 시각적 추론, 문서 인식, 세부 정보 이해 및 지시 준수 능력을 강화합니다. 128k 문맥 창을 지원하며, 최대 16k 토큰의 출력 길이를 지원합니다."
   },
   "doubao-seed-1.6": {
-    "description": "Doubao-Seed-1.6은 완전히 새로워진 다중 모달 심층 사고 모델로, auto/thinking/non-thinking 세 가지 사고 모드를 모두 지원합니다. non-thinking 모드에서 모델 성능은 Doubao-1.5-pro/250115에 비해 크게 향상되었습니다. 256k 컨텍스트 윈도우를 지원하며, 출력 길이는 최대 16k 토큰까지 가능합니다."
+    "description": "Doubao-Seed-1.6은 완전히 새로워진 다중 모달 심층 사고 모델로, auto/thinking/non-thinking 세 가지 사고 모드를 모두 지원합니다. non-thinking 모드에서는 Doubao-1.5-pro/250115에 비해 모델 성능이 크게 향상되었습니다. 256k 컨텍스트 창을 지원하며, 출력 길이는 최대 16k 토큰까지 가능합니다."
   },
   "doubao-seed-1.6-flash": {
-    "description": "Doubao-Seed-1.6-flash는 추론 속도가 극대화된 다중 모달 심층 사고 모델로, TPOT가 단 10ms에 불과합니다. 텍스트와 시각 이해를 모두 지원하며, 텍스트 이해 능력은 이전 세대 lite를 능가하고, 시각 이해는 경쟁사 pro 시리즈 모델과 견줄 만합니다. 256k 컨텍스트 윈도우를 지원하며, 출력 길이는 최대 16k 토큰까지 가능합니다."
+    "description": "Doubao-Seed-1.6-flash는 추론 속도가 극대화된 다중 모달 심층 사고 모델로, TPOT가 단 10ms에 불과합니다. 텍스트와 시각 이해를 모두 지원하며, 텍스트 이해 능력은 이전 세대 lite를 능가하고, 시각 이해는 경쟁사 pro 시리즈 모델과 견줄 만합니다. 256k 컨텍스트 창을 지원하며, 출력 길이는 최대 16k 토큰까지 가능합니다."
   },
   "doubao-seed-1.6-thinking": {
-    "description": "Doubao-Seed-1.6-thinking 모델은 사고 능력이 크게 강화되어 Doubao-1.5-thinking-pro에 비해 코딩, 수학, 논리 추론 등 기본 능력이 더욱 향상되었으며, 시각 이해를 지원합니다. 256k 컨텍스트 윈도우를 지원하며, 출력 길이는 최대 16k 토큰까지 가능합니다."
+    "description": "Doubao-Seed-1.6-thinking 모델은 사고 능력이 크게 강화되어 Doubao-1.5-thinking-pro에 비해 코딩, 수학, 논리 추론 등 기본 능력이 더욱 향상되었으며, 시각 이해도 지원합니다. 256k 컨텍스트 창을 지원하며, 출력 길이는 최대 16k 토큰까지 가능합니다."
   },
   "emohaa": {
     "description": "Emohaa는 심리 모델로, 전문 상담 능력을 갖추고 있어 사용자가 감정 문제를 이해하는 데 도움을 줍니다."
@@ -1869,7 +1869,7 @@
     "description": "o1은 OpenAI의 새로운 추론 모델로, 광범위한 일반 지식이 필요한 복잡한 작업에 적합합니다. 이 모델은 128K의 컨텍스트와 2023년 10월의 지식 기준일을 가지고 있습니다."
   },
   "o1-pro": {
-    "description": "o1 시리즈 모델은 강화 학습을 통해 훈련되어 답변 전에 사고를 수행하고 복잡한 추론 작업을 실행할 수 있습니다. o1-pro 모델은 더 많은 계산 자원을 사용하여 더 깊이 사고함으로써 지속적으로 더 우수한 답변을 제공합니다."
+    "description": "o1 시리즈 모델은 강화 학습을 통해 훈련되어 답변 전에 사고를 진행하고 복잡한 추론 작업을 수행할 수 있습니다. o1-pro 모델은 더 많은 계산 자원을 사용하여 더 깊이 사고함으로써 지속적으로 더 우수한 답변을 제공합니다."
   },
   "o3": {
     "description": "o3는 다재다능한 강력한 모델로, 여러 분야에서 뛰어난 성능을 발휘합니다. 수학, 과학, 프로그래밍 및 시각적 추론 작업에서 새로운 기준을 세웠습니다. 기술 작문 및 지시 준수에도 능숙합니다. 사용자는 이를 통해 텍스트, 코드 및 이미지를 분석하고, 다단계 복잡한 문제를 해결할 수 있습니다."
@@ -1881,7 +1881,7 @@
     "description": "o3-mini는 최신 소형 추론 모델로, o1-mini와 동일한 비용과 지연 목표에서 높은 지능을 제공합니다."
   },
   "o3-pro": {
-    "description": "o3-pro 모델은 더 많은 계산을 사용하여 더 깊이 사고하고 항상 더 나은 답변을 제공하며, Responses API에서만 사용할 수 있습니다."
+    "description": "o3-pro 모델은 더 많은 계산을 사용하여 더 깊이 사고하고 항상 더 나은 답변을 제공하며, Responses API에서만 사용 가능합니다."
   },
   "o4-mini": {
     "description": "o4-mini는 최신 소형 o 시리즈 모델로, 빠르고 효율적인 추론을 위해 최적화되어 있으며, 코딩 및 시각적 작업에서 매우 높은 효율성과 성능을 자랑합니다."
diff --git a/locales/nl-NL/chat.json b/locales/nl-NL/chat.json
index 1793f6d078a3f..4da1e5c2ddad0 100644
--- a/locales/nl-NL/chat.json
+++ b/locales/nl-NL/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "Redeneringsinspanning"
     },
+    "thinking": {
+      "title": "Diepdenkschakelaar"
+    },
     "title": "Modeluitbreidingsfunctie"
   },
   "history": {
diff --git a/locales/nl-NL/models.json b/locales/nl-NL/models.json
index e6df20e975126..31b1a5808b65c 100644
--- a/locales/nl-NL/models.json
+++ b/locales/nl-NL/models.json
@@ -666,7 +666,7 @@
     "description": "Codestral is een geavanceerd generatief model dat zich richt op codegeneratie, geoptimaliseerd voor tussentijdse invulling en code-aanvultaken."
   },
   "codex-mini-latest": {
-    "description": "codex-mini-latest is een verfijnde versie van o4-mini, speciaal ontworpen voor Codex CLI. Voor direct gebruik via de API raden we aan te beginnen met gpt-4.1."
+    "description": "codex-mini-latest is een fijn afgestemde versie van o4-mini, speciaal ontworpen voor Codex CLI. Voor direct gebruik via de API raden we aan te beginnen met gpt-4.1."
   },
   "cognitivecomputations/dolphin-mixtral-8x22b": {
     "description": "Dolphin Mixtral 8x22B is een model ontworpen voor instructievolging, gesprekken en programmeren."
@@ -924,7 +924,7 @@
     "description": "Doubao-Seed-1.6-flash is een multimodaal diepdenkend model met extreem snelle inferentiesnelheid, TPOT slechts 10ms; ondersteunt zowel tekst- als visueel begrip, met tekstbegrip dat beter is dan de vorige lite-generatie en visueel begrip dat vergelijkbaar is met concurrerende pro-serie modellen. Ondersteunt een contextvenster van 256k en een maximale uitvoerlengte van 16k tokens."
   },
   "doubao-seed-1.6-thinking": {
-    "description": "Doubao-Seed-1.6-thinking model heeft sterk verbeterde denkvermogens. Vergeleken met Doubao-1.5-thinking-pro zijn de basisvaardigheden in coderen, wiskunde en logisch redeneren verder verbeterd, met ondersteuning voor visueel begrip. Ondersteunt een contextvenster van 256k en een maximale uitvoerlengte van 16k tokens."
+    "description": "Doubao-Seed-1.6-thinking model heeft sterk verbeterde denkvermogens, met verdere verbeteringen in basisvaardigheden zoals coderen, wiskunde en logisch redeneren ten opzichte van Doubao-1.5-thinking-pro, en ondersteunt visueel begrip. Ondersteunt een contextvenster van 256k en een maximale uitvoerlengte van 16k tokens."
   },
   "emohaa": {
     "description": "Emohaa is een psychologisch model met professionele adviescapaciteiten, dat gebruikers helpt emotionele problemen te begrijpen."
@@ -1881,7 +1881,7 @@
     "description": "o3-mini is ons nieuwste kleine inferentiemodel dat hoge intelligentie biedt met dezelfde kosten- en vertragingdoelen als o1-mini."
   },
   "o3-pro": {
-    "description": "Het o3-pro model gebruikt meer rekenkracht om dieper na te denken en altijd betere antwoorden te bieden, alleen ondersteund onder de Responses API."
+    "description": "Het o3-pro model gebruikt meer rekenkracht om dieper na te denken en altijd betere antwoorden te bieden, alleen te gebruiken onder de Responses API."
   },
   "o4-mini": {
     "description": "o4-mini is ons nieuwste compacte model uit de o-serie. Het is geoptimaliseerd voor snelle en efficiënte inferentie, met een hoge efficiëntie en prestaties in codering en visuele taken."
diff --git a/locales/pl-PL/chat.json b/locales/pl-PL/chat.json
index a315a23da0c90..a6db575968a7c 100644
--- a/locales/pl-PL/chat.json
+++ b/locales/pl-PL/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "Intensywność rozumowania"
     },
+    "thinking": {
+      "title": "Przełącznik głębokiego myślenia"
+    },
     "title": "Funkcje rozszerzenia modelu"
   },
   "history": {
diff --git a/locales/pl-PL/models.json b/locales/pl-PL/models.json
index 8449e9e9d4a8e..03cc1f709965f 100644
--- a/locales/pl-PL/models.json
+++ b/locales/pl-PL/models.json
@@ -918,13 +918,13 @@
     "description": "Doubao-1.5-vision-lite to nowo zaktualizowany model multimodalny, który obsługuje rozpoznawanie obrazów o dowolnej rozdzielczości i ekstremalnych proporcjach, wzmacniając zdolności wnioskowania wizualnego, rozpoznawania dokumentów, rozumienia szczegółowych informacji i przestrzegania instrukcji. Obsługuje okno kontekstowe 128k, maksymalna długość wyjścia to 16k tokenów."
   },
   "doubao-seed-1.6": {
-    "description": "Doubao-Seed-1.6 to nowy, multimodalny model głębokiego myślenia, obsługujący trzy tryby myślenia: auto, thinking i non-thinking. W trybie non-thinking model osiąga znacznie lepsze wyniki w porównaniu z Doubao-1.5-pro/250115. Obsługuje kontekst do 256k oraz maksymalną długość wyjścia do 16k tokenów."
+    "description": "Doubao-Seed-1.6 to nowy, wielomodalny model głębokiego myślenia, obsługujący trzy tryby myślenia: auto, thinking i non-thinking. W trybie non-thinking model osiąga znacznie lepsze wyniki w porównaniu do Doubao-1.5-pro/250115. Obsługuje kontekst do 256k oraz maksymalną długość wyjścia do 16k tokenów."
   },
   "doubao-seed-1.6-flash": {
-    "description": "Doubao-Seed-1.6-flash to ultraszybki multimodalny model głębokiego myślenia, z czasem TPOT wynoszącym zaledwie 10 ms; obsługuje zarówno rozumienie tekstu, jak i obrazu, z lepszymi zdolnościami tekstowymi niż poprzednia generacja lite oraz wizualnymi porównywalnymi do modeli pro konkurencji. Obsługuje kontekst do 256k oraz maksymalną długość wyjścia do 16k tokenów."
+    "description": "Doubao-Seed-1.6-flash to ultraszybki model wielomodalnego głębokiego myślenia, z czasem TPOT zaledwie 10 ms; obsługuje zarówno rozumienie tekstu, jak i obrazu, z lepszymi zdolnościami tekstowymi niż poprzednia generacja lite oraz wizualnymi porównywalnymi do modeli pro konkurencji. Obsługuje kontekst do 256k oraz maksymalną długość wyjścia do 16k tokenów."
   },
   "doubao-seed-1.6-thinking": {
-    "description": "Model Doubao-Seed-1.6-thinking ma znacznie wzmocnione zdolności myślenia, w porównaniu z Doubao-1.5-thinking-pro osiąga dalsze ulepszenia w podstawowych umiejętnościach takich jak kodowanie, matematyka i rozumowanie logiczne, wspiera również rozumienie wizualne. Obsługuje kontekst do 256k oraz maksymalną długość wyjścia do 16k tokenów."
+    "description": "Model Doubao-Seed-1.6-thinking ma znacznie wzmocnione zdolności myślenia, w porównaniu do Doubao-1.5-thinking-pro osiąga dalsze ulepszenia w podstawowych umiejętnościach takich jak kodowanie, matematyka i rozumowanie logiczne, wspiera również rozumienie wizualne. Obsługuje kontekst do 256k oraz maksymalną długość wyjścia do 16k tokenów."
   },
   "emohaa": {
     "description": "Emohaa to model psychologiczny, posiadający profesjonalne umiejętności doradcze, pomagający użytkownikom zrozumieć problemy emocjonalne."
@@ -1869,7 +1869,7 @@
     "description": "o1 to nowy model wnioskowania OpenAI, odpowiedni do złożonych zadań wymagających szerokiej wiedzy ogólnej. Model ten ma kontekst 128K i datę graniczną wiedzy z października 2023 roku."
   },
   "o1-pro": {
-    "description": "Modele serii o1 są trenowane z wykorzystaniem uczenia ze wzmocnieniem, potrafią myśleć przed udzieleniem odpowiedzi i wykonywać złożone zadania rozumowania. Model o1-pro wykorzystuje więcej zasobów obliczeniowych do głębszego myślenia, co pozwala na ciągłe dostarczanie lepszych odpowiedzi."
+    "description": "Modele z serii o1 są trenowane z wykorzystaniem uczenia ze wzmocnieniem, potrafią myśleć przed udzieleniem odpowiedzi i wykonywać złożone zadania rozumowania. Model o1-pro wykorzystuje więcej zasobów obliczeniowych, aby prowadzić głębsze rozważania i stale dostarczać lepsze odpowiedzi."
   },
   "o3": {
     "description": "o3 to wszechstronny i potężny model, który doskonale sprawdza się w wielu dziedzinach. Ustanawia nowe standardy w zadaniach matematycznych, naukowych, programistycznych i wizualnych. Jest również biegły w pisaniu technicznym i przestrzeganiu instrukcji. Użytkownicy mogą go wykorzystać do analizy tekstów, kodów i obrazów, rozwiązując złożone problemy wieloetapowe."
@@ -1881,7 +1881,7 @@
     "description": "o3-mini to nasz najnowszy mały model wnioskowania, który oferuje wysoką inteligencję przy tych samych kosztach i celach opóźnienia co o1-mini."
   },
   "o3-pro": {
-    "description": "Model o3-pro wykorzystuje większą moc obliczeniową do głębszego myślenia i zawsze dostarcza lepsze odpowiedzi, jest dostępny wyłącznie przez API Responses."
+    "description": "Model o3-pro wykorzystuje większą moc obliczeniową do głębszego myślenia i zawsze dostarcza lepsze odpowiedzi, dostępny wyłącznie przez API Responses."
   },
   "o4-mini": {
     "description": "o4-mini to nasz najnowszy mały model z serii o. Został zoptymalizowany do szybkiego i efektywnego wnioskowania, osiągając wysoką wydajność i efektywność w zadaniach kodowania i wizualnych."
diff --git a/locales/pt-BR/chat.json b/locales/pt-BR/chat.json
index 69f88e4d68355..b25a6a16b1fcb 100644
--- a/locales/pt-BR/chat.json
+++ b/locales/pt-BR/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "Intensidade de Raciocínio"
     },
+    "thinking": {
+      "title": "Interruptor de Pensamento Profundo"
+    },
     "title": "Funcionalidade de Extensão do Modelo"
   },
   "history": {
diff --git a/locales/pt-BR/models.json b/locales/pt-BR/models.json
index 3bbcc47dfe785..2c2850aadf8c1 100644
--- a/locales/pt-BR/models.json
+++ b/locales/pt-BR/models.json
@@ -665,9 +665,6 @@
   "codestral-latest": {
     "description": "Codestral é um modelo gerador de ponta focado em geração de código, otimizado para preenchimento intermediário e tarefas de conclusão de código."
   },
-  "codex-mini-latest": {
-    "description": "codex-mini-latest é uma versão ajustada do o4-mini, especialmente para o Codex CLI. Para uso direto via API, recomendamos começar com o gpt-4.1."
-  },
   "cognitivecomputations/dolphin-mixtral-8x22b": {
     "description": "Dolphin Mixtral 8x22B é um modelo projetado para seguir instruções, diálogos e programação."
   },
@@ -917,15 +914,6 @@
   "doubao-1.5-vision-lite": {
     "description": "Doubao-1.5-vision-lite é um modelo multimodal atualizado, suportando reconhecimento de imagens de qualquer resolução e proporções extremas, melhorando a capacidade de raciocínio visual, reconhecimento de documentos, compreensão de informações detalhadas e seguimento de instruções. Suporta uma janela de contexto de 128k, com comprimento de saída de até 16k tokens."
   },
-  "doubao-seed-1.6": {
-    "description": "Doubao-Seed-1.6 é um novo modelo multimodal de pensamento profundo, suportando três modos de pensamento: auto, thinking e non-thinking. No modo non-thinking, o desempenho do modelo melhora significativamente em comparação com Doubao-1.5-pro/250115. Suporta janela de contexto de 256k e comprimento máximo de saída de 16k tokens."
-  },
-  "doubao-seed-1.6-flash": {
-    "description": "Doubao-Seed-1.6-flash é um modelo multimodal de pensamento profundo com velocidade de inferência extrema, TPOT de apenas 10ms; suporta compreensão de texto e visual, com capacidade de compreensão textual superior à geração lite anterior e compreensão visual comparável aos modelos pro da concorrência. Suporta janela de contexto de 256k e comprimento máximo de saída de 16k tokens."
-  },
-  "doubao-seed-1.6-thinking": {
-    "description": "O modelo Doubao-Seed-1.6-thinking tem capacidade de pensamento significativamente reforçada, melhorando ainda mais as habilidades básicas em Coding, Matemática e raciocínio lógico em comparação com Doubao-1.5-thinking-pro, além de suportar compreensão visual. Suporta janela de contexto de 256k e comprimento máximo de saída de 16k tokens."
-  },
   "emohaa": {
     "description": "O Emohaa é um modelo psicológico com capacidade de consultoria profissional, ajudando os usuários a entender questões emocionais."
   },
@@ -1868,9 +1856,6 @@
   "o1-preview": {
     "description": "o1 é o novo modelo de raciocínio da OpenAI, adequado para tarefas complexas que exigem amplo conhecimento geral. Este modelo possui um contexto de 128K e uma data limite de conhecimento em outubro de 2023."
   },
-  "o1-pro": {
-    "description": "A série de modelos o1 é treinada com aprendizado por reforço, capaz de pensar antes de responder e executar tarefas complexas de raciocínio. O modelo o1-pro utiliza mais recursos computacionais para um pensamento mais profundo, oferecendo respostas de qualidade superior de forma contínua."
-  },
   "o3": {
     "description": "o3 é um modelo versátil e poderoso, com excelente desempenho em várias áreas. Ele estabelece novos padrões para tarefas de matemática, ciência, programação e raciocínio visual. Também é bom em redação técnica e seguimento de instruções. Os usuários podem utilizá-lo para analisar textos, códigos e imagens, resolvendo problemas complexos em múltiplas etapas."
   },
@@ -1880,9 +1865,6 @@
   "o3-mini": {
     "description": "o3-mini é nosso mais recente modelo de inferência em miniatura, oferecendo alta inteligência com os mesmos custos e metas de latência que o o1-mini."
   },
-  "o3-pro": {
-    "description": "O modelo o3-pro utiliza mais computação para pensar mais profundamente e sempre fornecer melhores respostas, suportado apenas para uso via Responses API."
-  },
   "o4-mini": {
     "description": "o4-mini é nosso mais recente modelo compacto da série o. Ele é otimizado para inferência rápida e eficaz, apresentando alta eficiência e desempenho em tarefas de codificação e visuais."
   },
diff --git a/locales/ru-RU/chat.json b/locales/ru-RU/chat.json
index 8c5d6896b8f2e..cfc2fcfea5e55 100644
--- a/locales/ru-RU/chat.json
+++ b/locales/ru-RU/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "Интенсивность рассуждений"
     },
+    "thinking": {
+      "title": "Переключатель глубокого мышления"
+    },
     "title": "Расширенные функции модели"
   },
   "history": {
diff --git a/locales/ru-RU/models.json b/locales/ru-RU/models.json
index 37c396f7b9b07..23ccc43733608 100644
--- a/locales/ru-RU/models.json
+++ b/locales/ru-RU/models.json
@@ -918,13 +918,13 @@
     "description": "Doubao-1.5-vision-lite — это новая усовершенствованная мультимодальная модель, поддерживающая распознавание изображений с любым разрешением и экстремальным соотношением сторон, улучшая способности к визуальному выводу, распознаванию документов, пониманию детальной информации и соблюдению инструкций. Поддерживает контекстное окно 128k, максимальная длина вывода составляет 16k токенов."
   },
   "doubao-seed-1.6": {
-    "description": "Doubao-Seed-1.6 — новая мультимодальная модель глубокого мышления, поддерживающая три режима мышления: auto, thinking и non-thinking. В режиме non-thinking производительность модели значительно выше по сравнению с Doubao-1.5-pro/250115. Поддерживает контекстное окно до 256k и максимальную длину вывода до 16k токенов."
+    "description": "Doubao-Seed-1.6 — новая мультимодальная модель глубокого мышления, поддерживающая три режима мышления: auto, thinking и non-thinking. В режиме non-thinking производительность модели значительно выше по сравнению с Doubao-1.5-pro/250115. Поддерживает контекстное окно размером 256k и максимальную длину вывода до 16k токенов."
   },
   "doubao-seed-1.6-flash": {
-    "description": "Doubao-Seed-1.6-flash — мультимодальная модель глубокого мышления с предельной скоростью вывода, TPOT занимает всего 10 мс; поддерживает понимание текста и визуальных данных, текстовое понимание превосходит предыдущую lite-версию, визуальное понимание сопоставимо с pro-серией конкурентов. Поддерживает контекстное окно до 256k и максимальную длину вывода до 16k токенов."
+    "description": "Doubao-Seed-1.6-flash — мультимодальная модель глубокого мышления с экстремально высокой скоростью вывода, TPOT занимает всего 10 мс; поддерживает понимание текста и визуальных данных, текстовое понимание превосходит предыдущую lite-версию, визуальное понимание сопоставимо с pro-серией конкурентов. Поддерживает контекстное окно 256k и максимальную длину вывода до 16k токенов."
   },
   "doubao-seed-1.6-thinking": {
-    "description": "Модель Doubao-Seed-1.6-thinking значительно усилена в способности к мышлению, по сравнению с Doubao-1.5-thinking-pro улучшены базовые навыки в программировании, математике и логическом рассуждении, поддерживает визуальное понимание. Поддерживает контекстное окно до 256k и максимальную длину вывода до 16k токенов."
+    "description": "Модель Doubao-Seed-1.6-thinking значительно улучшена в плане мышления, по сравнению с Doubao-1.5-thinking-pro дополнительно повышены базовые способности в программировании, математике и логическом рассуждении, поддерживается визуальное понимание. Поддерживает контекстное окно 256k и максимальную длину вывода до 16k токенов."
   },
   "emohaa": {
     "description": "Emohaa — это психологическая модель, обладающая профессиональными консультационными способностями, помогающая пользователям понимать эмоциональные проблемы."
diff --git a/locales/tr-TR/chat.json b/locales/tr-TR/chat.json
index da1ece7658699..a9b96e1648216 100644
--- a/locales/tr-TR/chat.json
+++ b/locales/tr-TR/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "Akıl Yürütme Gücü"
     },
+    "thinking": {
+      "title": "Derin Düşünme Anahtarı"
+    },
     "title": "Model Genişletme Özellikleri"
   },
   "history": {
diff --git a/locales/tr-TR/models.json b/locales/tr-TR/models.json
index 5c1a10662d4fd..235c31ddeb1e4 100644
--- a/locales/tr-TR/models.json
+++ b/locales/tr-TR/models.json
@@ -666,7 +666,7 @@
     "description": "Codestral, kod üretimine odaklanan son teknoloji bir üretim modelidir, ara doldurma ve kod tamamlama görevlerini optimize etmiştir."
   },
   "codex-mini-latest": {
-    "description": "codex-mini-latest, Codex CLI için özel olarak tasarlanmış o4-mini'nin ince ayar versiyonudur. API üzerinden doğrudan kullanım için, gpt-4.1'den başlamanızı öneririz."
+    "description": "codex-mini-latest, Codex CLI için özel olarak ince ayarlanmış o4-mini versiyonudur. API üzerinden doğrudan kullanım için, gpt-4.1'den başlamanızı öneririz."
   },
   "cognitivecomputations/dolphin-mixtral-8x22b": {
     "description": "Dolphin Mixtral 8x22B, talimat takibi, diyalog ve programlama için tasarlanmış bir modeldir."
@@ -726,7 +726,7 @@
     "description": "Compound-beta-mini, GroqCloud'da desteklenen açık kullanılabilir modellerden güç alan bir bileşik AI sistemidir, kullanıcı sorgularını yanıtlamak için araçları akıllıca ve seçici bir şekilde kullanabilir."
   },
   "computer-use-preview": {
-    "description": "computer-use-preview modeli, \"Bilgisayar Kullanım Araçları\" için özel olarak tasarlanmış bir modeldir ve bilgisayarla ilgili görevleri anlama ve yerine getirme konusunda eğitilmiştir."
+    "description": "computer-use-preview modeli, \"Bilgisayar Kullanım Araçları\" için özel olarak tasarlanmış ve bilgisayarla ilgili görevleri anlama ve yerine getirme konusunda eğitilmiş özel bir modeldir."
   },
   "dall-e-2": {
     "description": "İkinci nesil DALL·E modeli, daha gerçekçi ve doğru görüntü üretimi destekler, çözünürlüğü birinci neslin 4 katıdır."
@@ -924,7 +924,7 @@
     "description": "Doubao-Seed-1.6-flash, TPOT sadece 10ms olan son derece hızlı çok modlu derin düşünme modelidir; hem metin hem de görsel anlayışı destekler, metin anlama yeteneği önceki lite neslini aşar, görsel anlama ise rakiplerin pro serisi modelleriyle eşdeğerdir. 256k bağlam penceresini destekler ve çıktı uzunluğu maksimum 16k token olabilir."
   },
   "doubao-seed-1.6-thinking": {
-    "description": "Doubao-Seed-1.6-thinking modeli düşünme yeteneğinde büyük gelişme göstermiştir; Doubao-1.5-thinking-pro ile karşılaştırıldığında Kodlama, Matematik ve mantıksal akıl yürütme gibi temel yeteneklerde daha da iyileşmiştir ve görsel anlayışı destekler. 256k bağlam penceresini destekler ve çıktı uzunluğu maksimum 16k token olabilir."
+    "description": "Doubao-Seed-1.6-thinking modeli düşünme yeteneğinde büyük gelişme göstermiştir, Doubao-1.5-thinking-pro ile karşılaştırıldığında Kodlama, Matematik ve mantıksal akıl yürütme gibi temel yeteneklerde daha da iyileşmiştir, görsel anlayışı destekler. 256k bağlam penceresini destekler ve çıktı uzunluğu maksimum 16k token olabilir."
   },
   "emohaa": {
     "description": "Emohaa, duygusal sorunları anlamalarına yardımcı olmak için profesyonel danışmanlık yeteneklerine sahip bir psikolojik modeldir."
@@ -1305,7 +1305,7 @@
     "description": "GPT-4o mini, OpenAI'nin GPT-4 Omni'den sonra tanıttığı en yeni modeldir. Görsel ve metin girişi destekler ve metin çıktısı verir. En gelişmiş küçük model olarak, diğer son zamanlardaki öncü modellere göre çok daha ucuzdur ve GPT-3.5 Turbo'dan %60'tan fazla daha ucuzdur. En son teknolojiyi korurken, önemli bir maliyet etkinliği sunar. GPT-4o mini, MMLU testinde %82 puan almış olup, şu anda sohbet tercihleri açısından GPT-4'ün üzerinde yer almaktadır."
   },
   "gpt-4o-mini-audio-preview": {
-    "description": "GPT-4o mini Ses modeli, ses giriş ve çıkışını destekler."
+    "description": "GPT-4o mini Ses modeli, sesli giriş ve çıkışı destekler."
   },
   "gpt-4o-mini-realtime-preview": {
     "description": "GPT-4o-mini gerçek zamanlı versiyonu, ses ve metin için gerçek zamanlı giriş ve çıkış desteği sunar."
@@ -1869,7 +1869,7 @@
     "description": "o1, OpenAI'nin geniş genel bilgiye ihtiyaç duyan karmaşık görevler için uygun yeni bir akıl yürütme modelidir. Bu model, 128K bağlam ve Ekim 2023 bilgi kesim tarihi ile donatılmıştır."
   },
   "o1-pro": {
-    "description": "o1 serisi modeller, güçlendirilmiş öğrenme ile eğitilmiş olup, yanıtlamadan önce düşünme yapabilir ve karmaşık akıl yürütme görevlerini yerine getirebilir. o1-pro modeli, daha derin düşünme için daha fazla hesaplama kaynağı kullanır ve böylece sürekli olarak daha kaliteli yanıtlar sunar."
+    "description": "o1 serisi modeller, yanıtlamadan önce düşünme yapabilen ve karmaşık akıl yürütme görevlerini yerine getirebilen pekiştirmeli öğrenme ile eğitilmiştir. o1-pro modeli, daha derin düşünme için daha fazla hesaplama kaynağı kullanır ve böylece sürekli olarak daha kaliteli yanıtlar sunar."
   },
   "o3": {
     "description": "o3, çok çeşitli alanlarda mükemmel performans gösteren çok yönlü güçlü bir modeldir. Matematik, bilim, programlama ve görsel çıkarım görevlerinde yeni standartlar belirler. Ayrıca teknik yazım ve talimat takibi konusunda da uzmandır. Kullanıcılar, metin, kod ve görüntüleri analiz ederek çok adımlı karmaşık sorunları çözebilir."
@@ -1881,7 +1881,7 @@
     "description": "o3-mini, aynı maliyet ve gecikme hedefleriyle yüksek zeka sunan en yeni küçük ölçekli çıkarım modelimizdir."
   },
   "o3-pro": {
-    "description": "o3-pro modeli, daha derin düşünmek ve her zaman daha iyi yanıtlar sunmak için daha fazla hesaplama kullanır; yalnızca Responses API altında kullanılabilir."
+    "description": "o3-pro modeli, daha derin düşünmek ve her zaman daha iyi yanıtlar sunmak için daha fazla hesaplama kullanır, yalnızca Responses API altında kullanılabilir."
   },
   "o4-mini": {
     "description": "o4-mini, en yeni küçük o serisi modelimizdir. Hızlı ve etkili çıkarım için optimize edilmiştir ve kodlama ile görsel görevlerde son derece yüksek verimlilik ve performans sergiler."
diff --git a/locales/vi-VN/chat.json b/locales/vi-VN/chat.json
index 6f44b5b2c8e1f..7cfef2e460b1c 100644
--- a/locales/vi-VN/chat.json
+++ b/locales/vi-VN/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "Cường độ suy luận"
     },
+    "thinking": {
+      "title": "Công tắc suy nghĩ sâu"
+    },
     "title": "Chức năng mở rộng mô hình"
   },
   "history": {
diff --git a/locales/vi-VN/models.json b/locales/vi-VN/models.json
index 9db7e3ac85625..8659297d161c2 100644
--- a/locales/vi-VN/models.json
+++ b/locales/vi-VN/models.json
@@ -726,7 +726,7 @@
     "description": "Compound-beta-mini là một hệ thống AI phức hợp, được hỗ trợ bởi các mô hình có sẵn công khai trong GroqCloud, có khả năng thông minh và chọn lọc sử dụng công cụ để trả lời các truy vấn của người dùng."
   },
   "computer-use-preview": {
-    "description": "Mô hình computer-use-preview được thiết kế chuyên biệt cho \"công cụ sử dụng máy tính\", được huấn luyện để hiểu và thực hiện các nhiệm vụ liên quan đến máy tính."
+    "description": "Mô hình computer-use-preview được thiết kế chuyên biệt cho “công cụ sử dụng máy tính”, được huấn luyện để hiểu và thực hiện các nhiệm vụ liên quan đến máy tính."
   },
   "dall-e-2": {
     "description": "Mô hình DALL·E thế hệ thứ hai, hỗ trợ tạo hình ảnh chân thực và chính xác hơn, với độ phân giải gấp 4 lần thế hệ đầu tiên."
@@ -924,7 +924,7 @@
     "description": "Doubao-Seed-1.6-flash là mô hình suy nghĩ sâu đa phương thức với tốc độ suy luận tối ưu, TPOT chỉ cần 10ms; đồng thời hỗ trợ hiểu văn bản và hình ảnh, khả năng hiểu văn bản vượt trội so với thế hệ lite trước, khả năng hiểu hình ảnh sánh ngang với các mô hình pro của đối thủ. Hỗ trợ cửa sổ ngữ cảnh 256k, độ dài đầu ra tối đa 16k tokens."
   },
   "doubao-seed-1.6-thinking": {
-    "description": "Mô hình Doubao-Seed-1.6-thinking có khả năng suy nghĩ được tăng cường đáng kể, so với Doubao-1.5-thinking-pro, nâng cao hơn nữa các năng lực cơ bản như Lập trình, Toán học, Lý luận logic, đồng thời hỗ trợ hiểu hình ảnh. Hỗ trợ cửa sổ ngữ cảnh 256k, độ dài đầu ra tối đa 16k tokens."
+    "description": "Mô hình Doubao-Seed-1.6-thinking có khả năng suy nghĩ được tăng cường đáng kể, so với Doubao-1.5-thinking-pro, nâng cao hơn nữa các năng lực cơ bản như lập trình, toán học, suy luận logic, đồng thời hỗ trợ hiểu hình ảnh. Hỗ trợ cửa sổ ngữ cảnh 256k, độ dài đầu ra tối đa 16k tokens."
   },
   "emohaa": {
     "description": "Emohaa là mô hình tâm lý, có khả năng tư vấn chuyên nghiệp, giúp người dùng hiểu các vấn đề cảm xúc."
@@ -1881,7 +1881,7 @@
     "description": "o3-mini là mô hình suy diễn nhỏ gọn mới nhất của chúng tôi, cung cấp trí thông minh cao với chi phí và độ trễ tương tự như o1-mini."
   },
   "o3-pro": {
-    "description": "Mô hình o3-pro sử dụng nhiều tài nguyên tính toán hơn để suy nghĩ sâu hơn và luôn cung cấp câu trả lời tốt hơn, chỉ hỗ trợ sử dụng dưới API Responses."
+    "description": "Mô hình o3-pro sử dụng nhiều tài nguyên tính toán hơn để suy nghĩ sâu sắc hơn và luôn cung cấp câu trả lời tốt hơn, chỉ hỗ trợ sử dụng dưới API Responses."
   },
   "o4-mini": {
     "description": "o4-mini là mô hình nhỏ gọn mới nhất trong dòng o của chúng tôi. Nó được tối ưu hóa cho suy luận nhanh chóng và hiệu quả, thể hiện hiệu suất và hiệu quả cao trong các nhiệm vụ mã hóa và hình ảnh."
diff --git a/locales/zh-CN/chat.json b/locales/zh-CN/chat.json
index 462162b9de8af..fb009afd8dd35 100644
--- a/locales/zh-CN/chat.json
+++ b/locales/zh-CN/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "推理强度"
     },
+    "thinking": {
+      "title": "深度思考开关"
+    },
     "title": "模型扩展功能"
   },
   "history": {
diff --git a/locales/zh-TW/chat.json b/locales/zh-TW/chat.json
index 399f2628ff7bc..31555f0ca7322 100644
--- a/locales/zh-TW/chat.json
+++ b/locales/zh-TW/chat.json
@@ -46,6 +46,9 @@
     "reasoningEffort": {
       "title": "推理強度"
     },
+    "thinking": {
+      "title": "深度思考開關"
+    },
     "title": "模型擴展功能"
   },
   "history": {
diff --git a/src/config/aiModels/google.ts b/src/config/aiModels/google.ts
index 6a7398ede31db..7d086396463f5 100644
--- a/src/config/aiModels/google.ts
+++ b/src/config/aiModels/google.ts
@@ -40,6 +40,7 @@ const googleChatModels: AIChatModelCard[] = [
     id: 'gemini-2.5-pro-preview-06-05',
     maxOutput: 65_536,
     pricing: {
+      cachedInput: 0.31, // prompts <= 200k tokens
       input: 1.25, // prompts <= 200k tokens
       output: 10, // prompts <= 200k tokens
     },
@@ -65,6 +66,7 @@ const googleChatModels: AIChatModelCard[] = [
     id: 'gemini-2.5-pro-preview-05-06',
     maxOutput: 65_536,
     pricing: {
+      cachedInput: 0.31, // prompts <= 200k tokens
       input: 1.25, // prompts <= 200k tokens
       output: 10, // prompts <= 200k tokens
     },
@@ -138,6 +140,7 @@ const googleChatModels: AIChatModelCard[] = [
     id: 'gemini-2.5-flash-preview-05-20',
     maxOutput: 65_536,
     pricing: {
+      cachedInput: 0.0375,
       input: 0.15,
       output: 3.5, // Thinking
     },
@@ -162,6 +165,7 @@ const googleChatModels: AIChatModelCard[] = [
     id: 'gemini-2.5-flash-preview-04-17',
     maxOutput: 65_536,
     pricing: {
+      cachedInput: 0.0375,
       input: 0.15,
       output: 3.5, // Thinking
     },
@@ -187,7 +191,7 @@ const googleChatModels: AIChatModelCard[] = [
     maxOutput: 65_536,
     pricing: {
       input: 0.15,
-      output: 3.5, // Thinking
+      output: 3.5,
     },
     settings: {
       searchImpl: 'params',
@@ -314,7 +318,6 @@ const googleChatModels: AIChatModelCard[] = [
     id: 'gemini-2.0-flash-lite',
     maxOutput: 8192,
     pricing: {
-      cachedInput: 0.018_75,
       input: 0.075,
       output: 0.3,
     },
@@ -331,7 +334,6 @@ const googleChatModels: AIChatModelCard[] = [
     id: 'gemini-2.0-flash-lite-001',
     maxOutput: 8192,
     pricing: {
-      cachedInput: 0.018_75,
       input: 0.075,
       output: 0.3,
     },
@@ -366,7 +368,6 @@ const googleChatModels: AIChatModelCard[] = [
     id: 'learnlm-2.0-flash-experimental',
     maxOutput: 32_768,
     pricing: {
-      cachedInput: 0,
       input: 0,
       output: 0,
     },
@@ -383,7 +384,6 @@ const googleChatModels: AIChatModelCard[] = [
     id: 'learnlm-1.5-pro-experimental',
     maxOutput: 8192,
     pricing: {
-      cachedInput: 0,
       input: 0,
       output: 0,
     },
@@ -408,23 +408,6 @@ const googleChatModels: AIChatModelCard[] = [
     releasedAt: '2024-09-25',
     type: 'chat',
   },
-  {
-    abilities: {
-      functionCall: true,
-      vision: true,
-    },
-    contextWindowTokens: 1_008_192,
-    description: 'Gemini 1.5 Flash 001 是一款高效的多模态模型，支持广泛应用的扩展。',
-    displayName: 'Gemini 1.5 Flash 001',
-    id: 'gemini-1.5-flash-001', // Deprecated on 2025-05-27
-    maxOutput: 8192,
-    pricing: {
-      cachedInput: 0.018_75,
-      input: 0.075,
-      output: 0.3,
-    },
-    type: 'chat',
-  },
   {
     abilities: {
       functionCall: true,
@@ -444,24 +427,6 @@ const googleChatModels: AIChatModelCard[] = [
     releasedAt: '2024-09-24',
     type: 'chat',
   },
-  {
-    abilities: {
-      functionCall: true,
-      vision: true,
-    },
-    contextWindowTokens: 2_008_192,
-    description: 'Gemini 1.5 Pro 001 是可扩展的多模态AI解决方案，支持广泛的复杂任务。',
-    displayName: 'Gemini 1.5 Pro 001 (Paid)',
-    id: 'gemini-1.5-pro-001', // Deprecated on 2025-05-27
-    maxOutput: 8192,
-    pricing: {
-      cachedInput: 0.3125,
-      input: 1.25,
-      output: 5,
-    },
-    releasedAt: '2024-02-15',
-    type: 'chat',
-  },
   {
     abilities: {
       functionCall: true,
diff --git a/src/config/aiModels/openai.ts b/src/config/aiModels/openai.ts
index d8dc43400408e..2a054db9e6c20 100644
--- a/src/config/aiModels/openai.ts
+++ b/src/config/aiModels/openai.ts
@@ -186,7 +186,7 @@ export const openaiChatModels: AIChatModelCard[] = [
     description:
       'o1-mini是一款针对编程、数学和科学应用场景而设计的快速、经济高效的推理模型。该模型具有128K上下文和2023年10月的知识截止日期。',
     displayName: 'o1-mini',
-    id: 'o1-mini',
+    id: 'o1-mini', // deprecated on 2025-10-27
     maxOutput: 65_536,
     pricing: {
       cachedInput: 0.55,
@@ -490,7 +490,7 @@ export const openaiChatModels: AIChatModelCard[] = [
       input: 2.5,
       output: 10,
     },
-    releasedAt: '2024-10-01',
+    releasedAt: '2024-12-17',
     /*
     settings: {
       searchImpl: 'params',
@@ -626,23 +626,6 @@ export const openaiChatModels: AIChatModelCard[] = [
     releasedAt: '2023-06-13',
     type: 'chat',
   },
-  {
-    abilities: {
-      functionCall: true,
-    },
-    contextWindowTokens: 32_768,
-
-    description:
-      'GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。',
-    displayName: 'GPT-4 32K',
-    id: 'gpt-4-32k', // deprecated on 2025-06-06
-    legacy: true,
-    pricing: {
-      input: 60,
-      output: 120,
-    },
-    type: 'chat',
-  },
   {
     abilities: {
       functionCall: true,
@@ -713,6 +696,7 @@ export const openaiChatModels: AIChatModelCard[] = [
     id: 'codex-mini-latest',
     maxOutput: 100_000,
     pricing: {
+      cachedInput: 0.375,
       input: 1.5,
       output: 6,
     },
@@ -800,7 +784,8 @@ export const openaiTTSModels: AITTSModelCard[] = [
     displayName: 'GPT-4o Mini TTS',
     id: 'gpt-4o-mini-tts',
     pricing: {
-      input: 10,
+      input: 0.6,
+      output: 12,
     },
     type: 'tts',
   },
@@ -809,7 +794,7 @@ export const openaiTTSModels: AITTSModelCard[] = [
 // 语音识别模型
 export const openaiSTTModels: AISTTModelCard[] = [
   {
-    description: '通用语音识别模型，支持多语言语音识别、语音翻译和语言识别',
+    description: '通用语音识别模型，支持多语言语音识别、语音翻译和语言识别。',
     displayName: 'Whisper',
     id: 'whisper-1',
     pricing: {
@@ -817,6 +802,30 @@ export const openaiSTTModels: AISTTModelCard[] = [
     },
     type: 'stt',
   },
+  {
+    contextWindowTokens: 16_000,
+    description: 'GPT-4o Transcribe 是一种使用 GPT-4o 转录音频的语音转文本模型。与原始 Whisper 模型相比，它提高了单词错误率，并提高了语言识别和准确性。使用它来获得更准确的转录。',
+    displayName: 'GPT-4o Transcribe',
+    id: 'gpt-4o-transcribe',
+    maxOutput: 2000,
+    pricing: {
+      input: 6, // Audio
+      output: 10,
+    },
+    type: 'stt',
+  },
+  {
+    contextWindowTokens: 16_000,
+    description: 'GPT-4o Mini Transcribe 是一种使用 GPT-4o 转录音频的语音转文本模型。与原始 Whisper 模型相比，它提高了单词错误率，并提高了语言识别和准确性。使用它来获得更准确的转录。',
+    displayName: 'GPT-4o Mini Transcribe',
+    id: 'gpt-4o-mini-transcribe',
+    maxOutput: 2000,
+    pricing: {
+      input: 3, // Audio
+      output: 5,
+    },
+    type: 'stt',
+  },
 ];
 
 // 图像生成模型
@@ -848,54 +857,54 @@ export const openaiImageModels: AIText2ImageModelCard[] = [
 // GPT-4o 和 GPT-4o-mini 实时模型
 export const openaiRealtimeModels: AIRealtimeModelCard[] = [
   {
-    contextWindowTokens: 128_000,
+    contextWindowTokens: 16_000,
     description: 'GPT-4o 实时版本，支持音频和文本实时输入输出',
-    displayName: 'GPT-4o Realtime',
+    displayName: 'GPT-4o Realtime 241217',
     id: 'gpt-4o-realtime-preview',
     maxOutput: 4096,
     pricing: {
-      audioInput: 100,
-      audioOutput: 200,
-      cachedAudioInput: 20,
+      audioInput: 40,
+      audioOutput: 80,
+      cachedAudioInput: 2.5,
       cachedInput: 2.5,
       input: 5,
       output: 20,
     },
-    releasedAt: '2024-10-01',
+    releasedAt: '2024-12-17',
     type: 'realtime',
   },
   {
-    contextWindowTokens: 128_000,
+    contextWindowTokens: 32_000,
     description: 'GPT-4o 实时版本，支持音频和文本实时输入输出',
-    displayName: 'GPT-4o Realtime 10-01',
-    id: 'gpt-4o-realtime-preview-2024-10-01',
+    displayName: 'GPT-4o Realtime 250603',
+    id: 'gpt-4o-realtime-preview-2025-06-03',
     maxOutput: 4096,
     pricing: {
-      audioInput: 100,
-      audioOutput: 200,
-      cachedAudioInput: 20,
+      audioInput: 40,
+      audioOutput: 80,
+      cachedAudioInput: 2.5,
       cachedInput: 2.5,
       input: 5,
       output: 20,
     },
-    releasedAt: '2024-10-01',
+    releasedAt: '2025-06-03',
     type: 'realtime',
   },
   {
-    contextWindowTokens: 128_000,
+    contextWindowTokens: 16_000,
     description: 'GPT-4o 实时版本，支持音频和文本实时输入输出',
-    displayName: 'GPT-4o Realtime 12-17',
-    id: 'gpt-4o-realtime-preview-2024-12-17',
+    displayName: 'GPT-4o Realtime 241001',
+    id: 'gpt-4o-realtime-preview-2024-10-01', // deprecated on 2025-09-10
     maxOutput: 4096,
     pricing: {
-      audioInput: 40,
-      audioOutput: 80,
-      cachedAudioInput: 2.5,
+      audioInput: 100,
+      audioOutput: 200,
+      cachedAudioInput: 20,
       cachedInput: 2.5,
       input: 5,
       output: 20,
     },
-    releasedAt: '2024-12-17',
+    releasedAt: '2024-10-01',
     type: 'realtime',
   },
   {
diff --git a/src/config/aiModels/volcengine.ts b/src/config/aiModels/volcengine.ts
index af9b565e80e1e..4db4dc97159ec 100644
--- a/src/config/aiModels/volcengine.ts
+++ b/src/config/aiModels/volcengine.ts
@@ -22,8 +22,8 @@ const doubaoChatModels: AIChatModelCard[] = [
     maxOutput: 16_000,
     pricing: {
       currency: 'CNY',
-      input: 2.4,
-      output: 12,
+      input: 1.2, // 输入长度 (32, 128] 千 token
+      output: 16,
     },
     type: 'chat',
   },
@@ -45,8 +45,11 @@ const doubaoChatModels: AIChatModelCard[] = [
     maxOutput: 16_000,
     pricing: {
       currency: 'CNY',
-      input: 2.4,
-      output: 24,
+      input: 1.2, // 输入长度 (32, 128] 千 token
+      output: 16,
+    },
+    settings: {
+      extendParams: ['thinking'],
     },
     type: 'chat',
   },
@@ -68,8 +71,36 @@ const doubaoChatModels: AIChatModelCard[] = [
     maxOutput: 16_000,
     pricing: {
       currency: 'CNY',
-      input: 0.6,
-      output: 6,
+      input: 0.3, // 输入长度 (32, 128] 千 token
+      output: 3,
+    },
+    settings: {
+      extendParams: ['enableReasoning'],
+    },
+    type: 'chat',
+  },
+  {
+    abilities: {
+      functionCall: true,
+      reasoning: true,
+      vision: true,
+    },
+    config: {
+      deploymentName: 'doubao-1-5-ui-tars-250428',
+    },
+    contextWindowTokens: 131_072,
+    description:
+      'Doubao-1.5-UI-TARS 是一款原生面向图形界面交互（GUI）的Agent模型。通过感知、推理和行动等类人的能力，与 GUI 进行无缝交互。',
+    displayName: 'Doubao 1.5 UI TARS',
+    id: 'doubao-1.5-ui-tars',
+    maxOutput: 16_000,
+    pricing: {
+      currency: 'CNY',
+      input: 3.5,
+      output: 12,
+    },
+    settings: {
+      extendParams: ['thinking'],
     },
     type: 'chat',
   },
@@ -86,8 +117,7 @@ const doubaoChatModels: AIChatModelCard[] = [
     description:
       '全新视觉深度思考模型，具备更强的通用多模态理解和推理能力，在 59 个公开评测基准中的 37 个上取得 SOTA 表现。',
     displayName: 'Doubao 1.5 Thinking Vision Pro',
-    enabled: true,
-    id: 'Doubao-1.5-thinking-vision-pro',
+    id: 'doubao-1.5-thinking-vision-pro',
     maxOutput: 16_000,
     pricing: {
       currency: 'CNY',
@@ -95,7 +125,7 @@ const doubaoChatModels: AIChatModelCard[] = [
       output: 9,
     },
     settings: {
-      extendParams: ['enableReasoning'],
+      extendParams: ['thinking'],
     },
     type: 'chat',
   },
@@ -111,7 +141,6 @@ const doubaoChatModels: AIChatModelCard[] = [
     description:
       'Doubao-1.5全新深度思考模型，在数学、编程、科学推理等专业领域及创意写作等通用任务中表现突出，在AIME 2024、Codeforces、GPQA等多项权威基准上达到或接近业界第一梯队水平。支持128k上下文窗口，16k输出。',
     displayName: 'Doubao 1.5 Thinking Pro',
-    enabled: true,
     id: 'doubao-1.5-thinking-pro',
     maxOutput: 16_000,
     pricing: {
@@ -128,19 +157,22 @@ const doubaoChatModels: AIChatModelCard[] = [
       vision: true,
     },
     config: {
-      deploymentName: 'doubao-1-5-thinking-pro-m-250415',
+      deploymentName: 'doubao-1-5-thinking-pro-m-250428',
     },
     contextWindowTokens: 131_072,
     description:
       'Doubao-1.5全新深度思考模型 (m 版本自带原生多模态深度推理能力)，在数学、编程、科学推理等专业领域及创意写作等通用任务中表现突出，在AIME 2024、Codeforces、GPQA等多项权威基准上达到或接近业界第一梯队水平。支持128k上下文窗口，16k输出。',
     displayName: 'Doubao 1.5 Thinking Pro M',
-    id: 'Doubao-1.5-thinking-pro-m',
+    id: 'doubao-1.5-thinking-pro-m',
     maxOutput: 16_000,
     pricing: {
       currency: 'CNY',
       input: 4,
       output: 16,
     },
+    settings: {
+      extendParams: ['enableReasoning'],
+    },
     type: 'chat',
   },
   {
@@ -233,13 +265,12 @@ const doubaoChatModels: AIChatModelCard[] = [
     config: {
       deploymentName: 'doubao-1-5-pro-32k-250115',
     },
-    contextWindowTokens: 32_768,
+    contextWindowTokens: 128_000,
     description:
       'Doubao-1.5-pro 全新一代主力模型，性能全面升级，在知识、代码、推理、等方面表现卓越。',
     displayName: 'Doubao 1.5 Pro 32k',
-    enabled: true,
     id: 'doubao-1.5-pro-32k',
-    maxOutput: 12_288,
+    maxOutput: 16_384,
     pricing: {
       currency: 'CNY',
       input: 0.8,
@@ -274,7 +305,6 @@ const doubaoChatModels: AIChatModelCard[] = [
     contextWindowTokens: 32_768,
     description: 'Doubao-1.5-lite 全新一代轻量版模型，极致响应速度，效果与时延均达到全球一流水平。',
     displayName: 'Doubao 1.5 Lite 32k',
-    enabled: true,
     id: 'doubao-1.5-lite-32k',
     maxOutput: 12_288,
     pricing: {
@@ -296,7 +326,7 @@ const doubaoChatModels: AIChatModelCard[] = [
     description:
       'Doubao-1.5-vision-pro 全新升级的多模态大模型，支持任意分辨率和极端长宽比图像识别，增强视觉推理、文档识别、细节信息理解和指令遵循能力。',
     displayName: 'Doubao 1.5 Vision Pro 32k',
-    id: 'Doubao-1.5-vision-pro-32k',
+    id: 'doubao-1.5-vision-pro-32k',
     maxOutput: 12_288,
     pricing: {
       currency: 'CNY',
@@ -318,7 +348,7 @@ const doubaoChatModels: AIChatModelCard[] = [
     description:
       'Doubao-1.5-vision-pro 全新升级的多模态大模型，支持任意分辨率和极端长宽比图像识别，增强视觉推理、文档识别、细节信息理解和指令遵循能力。',
     displayName: 'Doubao 1.5 Vision Pro',
-    id: 'Doubao-1.5-vision-pro',
+    id: 'doubao-1.5-vision-pro',
     maxOutput: 16_384,
     pricing: {
       currency: 'CNY',
@@ -361,7 +391,7 @@ const doubaoChatModels: AIChatModelCard[] = [
     description:
       'Doubao-vision 模型是豆包推出的多模态大模型，具备强大的图片理解与推理能力，以及精准的指令理解能力。模型在图像文本信息抽取、基于图像的推理任务上有展现出了强大的性能，能够应用于更复杂、更广泛的视觉问答任务。',
     displayName: 'Doubao Vision Pro 32k',
-    id: 'Doubao-vision-pro-32k',
+    id: 'doubao-vision-pro-32k',
     maxOutput: 4096,
     pricing: {
       currency: 'CNY',
@@ -382,7 +412,7 @@ const doubaoChatModels: AIChatModelCard[] = [
     description:
       'Doubao-vision 模型是豆包推出的多模态大模型，具备强大的图片理解与推理能力，以及精准的指令理解能力。模型在图像文本信息抽取、基于图像的推理任务上有展现出了强大的性能，能够应用于更复杂、更广泛的视觉问答任务。',
     displayName: 'Doubao Vision Lite 32k',
-    id: 'Doubao-vision-lite-32k',
+    id: 'doubao-vision-lite-32k',
     maxOutput: 4096,
     pricing: {
       currency: 'CNY',
@@ -393,11 +423,14 @@ const doubaoChatModels: AIChatModelCard[] = [
     type: 'chat',
   },
   {
+    config: {
+      deploymentName: 'doubao-lite-4k-character-240828',
+    },
     contextWindowTokens: 4096,
     description:
       '拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持 4k 上下文窗口的推理和精调。',
     displayName: 'Doubao Lite 4k',
-    id: 'Doubao-lite-4k',
+    id: 'doubao-lite-4k',
     maxOutput: 4096,
     pricing: {
       currency: 'CNY',
@@ -414,7 +447,7 @@ const doubaoChatModels: AIChatModelCard[] = [
     description:
       '拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持 32k 上下文窗口的推理和精调。',
     displayName: 'Doubao Lite 32k',
-    id: 'Doubao-lite-32k',
+    id: 'doubao-lite-32k',
     maxOutput: 4096,
     pricing: {
       currency: 'CNY',
@@ -431,7 +464,7 @@ const doubaoChatModels: AIChatModelCard[] = [
     description:
       '拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持 128k 上下文窗口的推理和精调。',
     displayName: 'Doubao Lite 128k',
-    id: 'Doubao-lite-128k',
+    id: 'doubao-lite-128k',
     maxOutput: 4096,
     pricing: {
       currency: 'CNY',
@@ -440,20 +473,6 @@ const doubaoChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
-  {
-    contextWindowTokens: 4096,
-    description:
-      '效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持 4k 上下文窗口的推理和精调。',
-    displayName: 'Doubao Pro 4k',
-    id: 'Doubao-pro-4k',
-    maxOutput: 4096,
-    pricing: {
-      currency: 'CNY',
-      input: 0.8,
-      output: 2,
-    },
-    type: 'chat',
-  },
   {
     config: {
       deploymentName: 'doubao-pro-32k-241215',
@@ -462,7 +481,7 @@ const doubaoChatModels: AIChatModelCard[] = [
     description:
       '效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持 32k 上下文窗口的推理和精调。',
     displayName: 'Doubao Pro 32k',
-    id: 'Doubao-pro-32k',
+    id: 'doubao-pro-32k',
     maxOutput: 4096,
     pricing: {
       currency: 'CNY',
@@ -471,20 +490,6 @@ const doubaoChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
-  {
-    contextWindowTokens: 128_000,
-    description:
-      '效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持 128k 上下文窗口的推理和精调。',
-    displayName: 'Doubao Pro 128k',
-    id: 'Doubao-pro-128k',
-    maxOutput: 4096,
-    pricing: {
-      currency: 'CNY',
-      input: 5,
-      output: 9,
-    },
-    type: 'chat',
-  },
   {
     config: {
       deploymentName: 'doubao-pro-256k-241115',
@@ -493,7 +498,7 @@ const doubaoChatModels: AIChatModelCard[] = [
     description:
       '效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持 256k 上下文窗口的推理和精调。',
     displayName: 'Doubao Pro 256k',
-    id: 'Doubao-pro-256k',
+    id: 'doubao-pro-256k',
     maxOutput: 4096,
     pricing: {
       currency: 'CNY',
diff --git a/src/features/ChatInput/ActionBar/Model/ControlsForm.tsx b/src/features/ChatInput/ActionBar/Model/ControlsForm.tsx
index 5067f24d2549d..41b6f7a5ffc24 100644
--- a/src/features/ChatInput/ActionBar/Model/ControlsForm.tsx
+++ b/src/features/ChatInput/ActionBar/Model/ControlsForm.tsx
@@ -14,6 +14,7 @@ import ContextCachingSwitch from './ContextCachingSwitch';
 import ReasoningEffortSlider from './ReasoningEffortSlider';
 import ReasoningTokenSlider from './ReasoningTokenSlider';
 import ThinkingBudgetSlider from './ThinkingBudgetSlider';
+import ThinkingSlider from './ThinkingSlider';
 
 const ControlsForm = memo(() => {
   const { t } = useTranslation('chat');
@@ -105,6 +106,16 @@ const ControlsForm = memo(() => {
       },
       tag: 'thinkingBudget',
     },
+    {
+      children: <ThinkingSlider />,
+      label: t('extendParams.thinking.title'),
+      layout: 'horizontal',
+      minWidth: undefined,
+      name: 'thinking',
+      style: {
+        paddingBottom: 0,
+      },
+    },
   ].filter(Boolean) as FormItemProps[];
 
   return (
diff --git a/src/features/ChatInput/ActionBar/Model/ThinkingSlider.tsx b/src/features/ChatInput/ActionBar/Model/ThinkingSlider.tsx
new file mode 100644
index 0000000000000..a25ff483ceb08
--- /dev/null
+++ b/src/features/ChatInput/ActionBar/Model/ThinkingSlider.tsx
@@ -0,0 +1,57 @@
+import { Slider } from 'antd';
+import { memo, useCallback } from 'react';
+import { Flexbox } from 'react-layout-kit';
+
+import { useAgentStore } from '@/store/agent';
+import { agentChatConfigSelectors } from '@/store/agent/selectors';
+
+const ThinkingSlider = memo(() => {
+  const [config, updateAgentChatConfig] = useAgentStore((s) => [
+    agentChatConfigSelectors.currentChatConfig(s),
+    s.updateAgentChatConfig,
+  ]);
+
+  const thinking = config.thinking || 'auto'; // Default to 'auto' if not set
+
+  const marks = {
+    0: 'OFF',
+    1: 'Auto',
+    2: 'ON',
+  };
+
+  const thinkingValues = ['disabled', 'auto', 'enabled'];
+  const indexValue = thinkingValues.indexOf(thinking);
+  const currentValue = indexValue === -1 ? 1 : indexValue;
+
+  const updateThinking = useCallback(
+    (value: number) => {
+      const thinkingMode = thinkingValues[value] as 'disabled' | 'auto' | 'enabled';
+      updateAgentChatConfig({ thinking: thinkingMode });
+    },
+    [updateAgentChatConfig],
+  );
+
+  return (
+    <Flexbox
+      align={'center'}
+      gap={12}
+      horizontal
+      paddingInline={'0 20px'}
+      style={{ minWidth: 200, width: '100%' }}
+    >
+      <Flexbox flex={1}>
+        <Slider
+          marks={marks}
+          max={2}
+          min={0}
+          onChange={updateThinking}
+          step={1}
+          tooltip={{ open: false }}
+          value={currentValue}
+        />
+      </Flexbox>
+    </Flexbox>
+  );
+});
+
+export default ThinkingSlider;
diff --git a/src/libs/model-runtime/volcengine/index.ts b/src/libs/model-runtime/volcengine/index.ts
index 7c749263acc61..dbdc99917a464 100644
--- a/src/libs/model-runtime/volcengine/index.ts
+++ b/src/libs/model-runtime/volcengine/index.ts
@@ -2,6 +2,13 @@ import { ModelProvider } from '../types';
 import { createOpenAICompatibleRuntime } from '../utils/openaiCompatibleFactory';
 import { MODEL_LIST_CONFIGS, processModelList } from '../utils/modelParse';
 
+const THINKING_MODELS = [
+  'thinking-vision-pro',
+  'thinking-pro-m', 
+  'doubao-seed-1-6',
+  'doubao-1-5-ui-tars'
+];
+
 export interface VolcengineModelCard {
   id: string;
 }
@@ -15,12 +22,9 @@ export const LobeVolcengineAI = createOpenAICompatibleRuntime({
       return {
         ...rest,
         model,
-        ...(['thinking-vision-pro'].some((keyword) => model.toLowerCase().includes(keyword))
+        ...(THINKING_MODELS.some((keyword) => model.toLowerCase().includes(keyword))
           ? {
-              thinking:
-                thinking !== undefined && thinking.type === 'enabled'
-                  ? { type: 'enabled' }
-                  : { type: 'disabled' },
+              thinking: { type: thinking?.type }
             }
           : {}),
       } as any;
diff --git a/src/locales/default/chat.ts b/src/locales/default/chat.ts
index 8f071c02f1dbe..1814f51bc43a7 100644
--- a/src/locales/default/chat.ts
+++ b/src/locales/default/chat.ts
@@ -47,6 +47,9 @@ export default {
     reasoningEffort: {
       title: '推理强度',
     },
+    thinking: {
+      title: '深度思考开关',
+    },
     title: '模型扩展功能',
   },
   history: {
diff --git a/src/services/chat.ts b/src/services/chat.ts
index ed42b1511456d..9988fbafd39f0 100644
--- a/src/services/chat.ts
+++ b/src/services/chat.ts
@@ -264,6 +264,10 @@ class ChatService {
         extendParams.reasoning_effort = chatConfig.reasoningEffort;
       }
 
+      if (modelExtendParams!.includes('thinking') && chatConfig.thinking) {
+        extendParams.thinking = { type: chatConfig.thinking };
+      }
+
       if (
         modelExtendParams!.includes('thinkingBudget') &&
         chatConfig.thinkingBudget !== undefined
diff --git a/src/types/agent/chatConfig.ts b/src/types/agent/chatConfig.ts
index ff9beea240728..74fa0ef55a3b2 100644
--- a/src/types/agent/chatConfig.ts
+++ b/src/types/agent/chatConfig.ts
@@ -26,6 +26,7 @@ export interface LobeAgentChatConfig {
   enableReasoningEffort?: boolean;
   reasoningBudgetToken?: number;
   reasoningEffort?: 'low' | 'medium' | 'high';
+  thinking?: 'disabled' | 'auto' | 'enabled';
   thinkingBudget?: number;
   /**
    * 禁用上下文缓存
diff --git a/src/types/aiModel.ts b/src/types/aiModel.ts
index 238d42ffbcc43..eb86b049eb44a 100644
--- a/src/types/aiModel.ts
+++ b/src/types/aiModel.ts
@@ -121,6 +121,7 @@ export interface AIBaseModelCard {
    * whether model is legacy (deprecated but not removed yet)
    */
   legacy?: boolean;
+  maxOutput?: number;
   /**
    * who create this model
    */
@@ -148,6 +149,7 @@ export type ExtendParamsType =
   | 'enableReasoning'
   | 'disableContextCaching'
   | 'reasoningEffort'
+  | 'thinking'
   | 'thinkingBudget';
 
 export interface AiModelSettings {
@@ -207,6 +209,7 @@ export interface AITTSModelCard extends AIBaseModelCard {
      * the input pricing, e.g. $1 / 1M tokens
      */
     input?: number;
+    output?: number;
   };
   type: 'tts';
 }
@@ -222,6 +225,7 @@ export interface AISTTModelCard extends AIBaseModelCard {
      * the input pricing, e.g. $1 / 1M tokens
      */
     input?: number;
+    output?: number;
   };
   type: 'stt';
 }
