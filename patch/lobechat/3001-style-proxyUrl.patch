diff --git a/src/app/(backend)/_deprecated/createBizOpenAI/createAzureOpenai.ts b/src/app/(backend)/_deprecated/createBizOpenAI/createAzureOpenai.ts
index cd04d63a7089..a1d8144595cc 100644
--- a/src/app/(backend)/_deprecated/createBizOpenAI/createAzureOpenai.ts
+++ b/src/app/(backend)/_deprecated/createBizOpenAI/createAzureOpenai.ts
@@ -11,9 +11,9 @@ export const createAzureOpenai = (params: {
   model: string;
   userApiKey?: string | null;
 }) => {
-  const { OPENAI_PROXY_URL = '', AZURE_API_VERSION, AZURE_API_KEY } = getLLMConfig();
+  const { AZURE_API_VERSION, AZURE_API_KEY } = getLLMConfig();
 
-  const endpoint = !params.endpoint ? OPENAI_PROXY_URL : params.endpoint;
+  const endpoint = !params.endpoint ? process.env.OPENAI_PROXY_URL || '' : params.endpoint;
   const baseURL = urlJoin(endpoint, `/openai/deployments/${params.model.replace('.', '')}`); // refs: https://test-001.openai.azure.com/openai/deployments/gpt-35-turbo
 
   const defaultApiVersion = AZURE_API_VERSION || '2023-08-01-preview';
diff --git a/src/app/(backend)/_deprecated/createBizOpenAI/createOpenai.ts b/src/app/(backend)/_deprecated/createBizOpenAI/createOpenai.ts
index d2ae53d432a8..19d548015278 100644
--- a/src/app/(backend)/_deprecated/createBizOpenAI/createOpenai.ts
+++ b/src/app/(backend)/_deprecated/createBizOpenAI/createOpenai.ts
@@ -5,7 +5,8 @@ import { ChatErrorType } from '@/types/fetch';
 
 // create OpenAI instance
 export const createOpenai = (userApiKey: string | null, endpoint?: string | null) => {
-  const { OPENAI_API_KEY, OPENAI_PROXY_URL } = getLLMConfig();
+  const { OPENAI_API_KEY } = getLLMConfig();
+  const OPENAI_PROXY_URL = process.env.OPENAI_PROXY_URL;
 
   const baseURL = endpoint ? endpoint : OPENAI_PROXY_URL ? OPENAI_PROXY_URL : undefined;
 
diff --git a/src/config/llm.ts b/src/config/llm.ts
index 4c9a831d4843..87a364a7bef6 100644
--- a/src/config/llm.ts
+++ b/src/config/llm.ts
@@ -9,7 +9,6 @@ export const getLLMConfig = () => {
 
       ENABLED_OPENAI: z.boolean(),
       OPENAI_API_KEY: z.string().optional(),
-      OPENAI_PROXY_URL: z.string().optional(),
 
       ENABLED_AZURE_OPENAI: z.boolean(),
       AZURE_API_KEY: z.string().optional(),
@@ -24,19 +23,15 @@ export const getLLMConfig = () => {
 
       ENABLED_GOOGLE: z.boolean(),
       GOOGLE_API_KEY: z.string().optional(),
-      GOOGLE_PROXY_URL: z.string().optional(),
 
       ENABLED_MOONSHOT: z.boolean(),
       MOONSHOT_API_KEY: z.string().optional(),
-      MOONSHOT_PROXY_URL: z.string().optional(),
 
       ENABLED_PERPLEXITY: z.boolean(),
       PERPLEXITY_API_KEY: z.string().optional(),
-      PERPLEXITY_PROXY_URL: z.string().optional(),
 
       ENABLED_ANTHROPIC: z.boolean(),
       ANTHROPIC_API_KEY: z.string().optional(),
-      ANTHROPIC_PROXY_URL: z.string().optional(),
 
       ENABLED_MINIMAX: z.boolean(),
       MINIMAX_API_KEY: z.string().optional(),
@@ -46,7 +41,6 @@ export const getLLMConfig = () => {
 
       ENABLED_GROQ: z.boolean(),
       GROQ_API_KEY: z.string().optional(),
-      GROQ_PROXY_URL: z.string().optional(),
 
       ENABLED_GITHUB: z.boolean(),
       GITHUB_TOKEN: z.string().optional(),
@@ -74,7 +68,6 @@ export const getLLMConfig = () => {
       WENXIN_SECRET_KEY: z.string().optional(),
 
       ENABLED_OLLAMA: z.boolean(),
-      OLLAMA_PROXY_URL: z.string().optional(),
 
       ENABLED_QWEN: z.boolean(),
       QWEN_API_KEY: z.string().optional(),
@@ -100,7 +93,6 @@ export const getLLMConfig = () => {
 
       ENABLED_SILICONCLOUD: z.boolean(),
       SILICONCLOUD_API_KEY: z.string().optional(),
-      SILICONCLOUD_PROXY_URL: z.string().optional(),
 
       ENABLED_UPSTAGE: z.boolean(),
       UPSTAGE_API_KEY: z.string().optional(),
@@ -116,7 +108,6 @@ export const getLLMConfig = () => {
 
       ENABLED_HUGGINGFACE: z.boolean(),
       HUGGINGFACE_API_KEY: z.string().optional(),
-      HUGGINGFACE_PROXY_URL: z.string().optional(),
 
       ENABLED_SENSENOVA: z.boolean(),
       SENSENOVA_ACCESS_KEY_ID: z.string().optional(),
@@ -133,7 +124,6 @@ export const getLLMConfig = () => {
 
       ENABLED_OPENAI: process.env.ENABLED_OPENAI !== '0',
       OPENAI_API_KEY: process.env.OPENAI_API_KEY,
-      OPENAI_PROXY_URL: process.env.OPENAI_PROXY_URL,
 
       ENABLED_AZURE_OPENAI: !!process.env.AZURE_API_KEY,
       AZURE_API_KEY: process.env.AZURE_API_KEY,
@@ -148,15 +138,12 @@ export const getLLMConfig = () => {
 
       ENABLED_GOOGLE: !!process.env.GOOGLE_API_KEY,
       GOOGLE_API_KEY: process.env.GOOGLE_API_KEY,
-      GOOGLE_PROXY_URL: process.env.GOOGLE_PROXY_URL,
 
       ENABLED_PERPLEXITY: !!process.env.PERPLEXITY_API_KEY,
       PERPLEXITY_API_KEY: process.env.PERPLEXITY_API_KEY,
-      PERPLEXITY_PROXY_URL: process.env.PERPLEXITY_PROXY_URL,
 
       ENABLED_ANTHROPIC: !!process.env.ANTHROPIC_API_KEY,
       ANTHROPIC_API_KEY: process.env.ANTHROPIC_API_KEY,
-      ANTHROPIC_PROXY_URL: process.env.ANTHROPIC_PROXY_URL,
 
       ENABLED_MINIMAX: !!process.env.MINIMAX_API_KEY,
       MINIMAX_API_KEY: process.env.MINIMAX_API_KEY,
@@ -175,11 +162,9 @@ export const getLLMConfig = () => {
 
       ENABLED_MOONSHOT: !!process.env.MOONSHOT_API_KEY,
       MOONSHOT_API_KEY: process.env.MOONSHOT_API_KEY,
-      MOONSHOT_PROXY_URL: process.env.MOONSHOT_PROXY_URL,
 
       ENABLED_GROQ: !!process.env.GROQ_API_KEY,
       GROQ_API_KEY: process.env.GROQ_API_KEY,
-      GROQ_PROXY_URL: process.env.GROQ_PROXY_URL,
 
       ENABLED_GITHUB: !!process.env.GITHUB_TOKEN,
       GITHUB_TOKEN: process.env.GITHUB_TOKEN,
@@ -198,7 +183,6 @@ export const getLLMConfig = () => {
       WENXIN_SECRET_KEY: process.env.WENXIN_SECRET_KEY,
 
       ENABLED_OLLAMA: process.env.ENABLED_OLLAMA !== '0',
-      OLLAMA_PROXY_URL: process.env.OLLAMA_PROXY_URL || '',
 
       ENABLED_QWEN: !!process.env.QWEN_API_KEY,
       QWEN_API_KEY: process.env.QWEN_API_KEY,
@@ -225,7 +209,6 @@ export const getLLMConfig = () => {
 
       ENABLED_SILICONCLOUD: !!process.env.SILICONCLOUD_API_KEY,
       SILICONCLOUD_API_KEY: process.env.SILICONCLOUD_API_KEY,
-      SILICONCLOUD_PROXY_URL: process.env.SILICONCLOUD_PROXY_URL,
 
       ENABLED_UPSTAGE: !!process.env.UPSTAGE_API_KEY,
       UPSTAGE_API_KEY: process.env.UPSTAGE_API_KEY,
@@ -241,7 +224,6 @@ export const getLLMConfig = () => {
 
       ENABLED_HUGGINGFACE: !!process.env.HUGGINGFACE_API_KEY,
       HUGGINGFACE_API_KEY: process.env.HUGGINGFACE_API_KEY,
-      HUGGINGFACE_PROXY_URL: process.env.HUGGINGFACE_PROXY_URL,
 
       ENABLED_SENSENOVA: !!process.env.SENSENOVA_ACCESS_KEY_ID && !!process.env.SENSENOVA_ACCESS_KEY_SECRET,
       SENSENOVA_ACCESS_KEY_ID: process.env.SENSENOVA_ACCESS_KEY_ID,
diff --git a/src/server/globalConfig/genServerLLMConfig.test.ts b/src/server/globalConfig/genServerLLMConfig.test.ts
index 6f5c421fc2d7..a40ecceb12a6 100644
--- a/src/server/globalConfig/genServerLLMConfig.test.ts
+++ b/src/server/globalConfig/genServerLLMConfig.test.ts
@@ -67,7 +67,7 @@ describe('genServerLLMConfig', () => {
         modelListKey: 'AWS_BEDROCK_MODEL_LIST',
       },
       ollama: {
-        fetchOnClient: !getLLMConfig().OLLAMA_PROXY_URL,
+        fetchOnClient: !process.env.OLLAMA_PROXY_URL,
       },
     };
     const config = genServerLLMConfig(specificConfig);
diff --git a/src/server/globalConfig/index.ts b/src/server/globalConfig/index.ts
index 65822bd171b1..97e1d6c1f0c4 100644
--- a/src/server/globalConfig/index.ts
+++ b/src/server/globalConfig/index.ts
@@ -2,7 +2,6 @@ import { appEnv, getAppConfig } from '@/config/app';
 import { authEnv } from '@/config/auth';
 import { fileEnv } from '@/config/file';
 import { langfuseEnv } from '@/config/langfuse';
-import { getLLMConfig } from '@/config/llm';
 import { enableNextAuth } from '@/const/auth';
 import { parseSystemAgent } from '@/server/globalConfig/parseSystemAgent';
 import { GlobalServerConfig } from '@/types/serverConfig';
@@ -31,7 +30,7 @@ export const getServerGlobalConfig = () => {
         modelListKey: 'AWS_BEDROCK_MODEL_LIST',
       },
       ollama: {
-        fetchOnClient: !getLLMConfig().OLLAMA_PROXY_URL,
+        fetchOnClient: !process.env.OLLAMA_PROXY_URL,
       },
     }),
     oAuthSSOProviders: authEnv.NEXT_AUTH_SSO_PROVIDERS.trim().split(/[,ï¼Œ]/),
diff --git a/src/server/modules/AgentRuntime/index.ts b/src/server/modules/AgentRuntime/index.ts
index 8134bed5c7a2..e01d84d6d516 100644
--- a/src/server/modules/AgentRuntime/index.ts
+++ b/src/server/modules/AgentRuntime/index.ts
@@ -30,9 +30,9 @@ const getLlmOptionsFromPayload = (provider: string, payload: JWTPayload) => {
   switch (provider) {
     default: // Use Openai options as default
     case ModelProvider.OpenAI: {
-      const { OPENAI_API_KEY, OPENAI_PROXY_URL } = getLLMConfig();
+      const { OPENAI_API_KEY } = getLLMConfig();
       const openaiApiKey = payload?.apiKey || OPENAI_API_KEY;
-      const baseURL = payload?.endpoint || OPENAI_PROXY_URL;
+      const baseURL = payload?.endpoint || process.env.OPENAI_PROXY_URL;
       const apiKey = apiKeyManager.pick(openaiApiKey);
       return {
         apiKey,
@@ -58,20 +58,20 @@ const getLlmOptionsFromPayload = (provider: string, payload: JWTPayload) => {
       };
     }
     case ModelProvider.Google: {
-      const { GOOGLE_API_KEY, GOOGLE_PROXY_URL } = getLLMConfig();
+      const { GOOGLE_API_KEY } = getLLMConfig();
       const apiKey = apiKeyManager.pick(payload?.apiKey || GOOGLE_API_KEY);
-      const baseURL = payload?.endpoint || GOOGLE_PROXY_URL;
+      const baseURL = payload?.endpoint || process.env.GOOGLE_PROXY_URL;
       return {
         apiKey,
         baseURL,
       };
     }
     case ModelProvider.Moonshot: {
-      const { MOONSHOT_API_KEY, MOONSHOT_PROXY_URL } = getLLMConfig();
+      const { MOONSHOT_API_KEY } = getLLMConfig();
       const apiKey = apiKeyManager.pick(payload?.apiKey || MOONSHOT_API_KEY);
       return {
         apiKey,
-        baseURL: MOONSHOT_PROXY_URL,
+        baseURL: process.env.MOONSHOT_PROXY_URL,
       };
     }
     case ModelProvider.Bedrock: {
@@ -91,23 +91,22 @@ const getLlmOptionsFromPayload = (provider: string, payload: JWTPayload) => {
       return { accessKeyId, accessKeySecret, region, sessionToken };
     }
     case ModelProvider.Ollama: {
-      const { OLLAMA_PROXY_URL } = getLLMConfig();
-      const baseURL = payload?.endpoint || OLLAMA_PROXY_URL;
+      const baseURL = payload?.endpoint || process.env.OLLAMA_PROXY_URL;
       return { baseURL };
     }
     case ModelProvider.Perplexity: {
-      const { PERPLEXITY_API_KEY, PERPLEXITY_PROXY_URL } = getLLMConfig();
+      const { PERPLEXITY_API_KEY } = getLLMConfig();
 
       const apiKey = apiKeyManager.pick(payload?.apiKey || PERPLEXITY_API_KEY);
-      const baseURL = payload?.endpoint || PERPLEXITY_PROXY_URL;
+      const baseURL = payload?.endpoint || process.env.PERPLEXITY_PROXY_URL;
 
       return { apiKey, baseURL };
     }
     case ModelProvider.Anthropic: {
-      const { ANTHROPIC_API_KEY, ANTHROPIC_PROXY_URL } = getLLMConfig();
+      const { ANTHROPIC_API_KEY } = getLLMConfig();
 
       const apiKey = apiKeyManager.pick(payload?.apiKey || ANTHROPIC_API_KEY);
-      const baseURL = payload?.endpoint || ANTHROPIC_PROXY_URL;
+      const baseURL = payload?.endpoint || process.env.ANTHROPIC_PROXY_URL;
 
       return { apiKey, baseURL };
     }
@@ -126,10 +125,10 @@ const getLlmOptionsFromPayload = (provider: string, payload: JWTPayload) => {
       return { apiKey };
     }
     case ModelProvider.Groq: {
-      const { GROQ_API_KEY, GROQ_PROXY_URL } = getLLMConfig();
+      const { GROQ_API_KEY } = getLLMConfig();
 
       const apiKey = apiKeyManager.pick(payload?.apiKey || GROQ_API_KEY);
-      const baseURL = payload?.endpoint || GROQ_PROXY_URL;
+      const baseURL = payload?.endpoint || process.env.GROQ_PROXY_URL;
 
       return { apiKey, baseURL };
     }
@@ -229,19 +228,19 @@ const getLlmOptionsFromPayload = (provider: string, payload: JWTPayload) => {
       return { apiKey };
     }
     case ModelProvider.SiliconCloud: {
-      const { SILICONCLOUD_API_KEY, SILICONCLOUD_PROXY_URL } = getLLMConfig();
+      const { SILICONCLOUD_API_KEY } = getLLMConfig();
 
       const apiKey = apiKeyManager.pick(payload?.apiKey || SILICONCLOUD_API_KEY);
-      const baseURL = payload?.endpoint || SILICONCLOUD_PROXY_URL;
+      const baseURL = payload?.endpoint || process.env.SILICONCLOUD_PROXY_URL;
 
       return { apiKey, baseURL };
     }
 
     case ModelProvider.HuggingFace: {
-      const { HUGGINGFACE_PROXY_URL, HUGGINGFACE_API_KEY } = getLLMConfig();
+      const { HUGGINGFACE_API_KEY } = getLLMConfig();
 
       const apiKey = apiKeyManager.pick(payload?.apiKey || HUGGINGFACE_API_KEY);
-      const baseURL = payload?.endpoint || HUGGINGFACE_PROXY_URL;
+      const baseURL = payload?.endpoint || process.env.HUGGINGFACE_PROXY_URL;
 
       return { apiKey, baseURL };
     }
@@ -292,8 +291,9 @@ const getLlmOptionsFromPayload = (provider: string, payload: JWTPayload) => {
       const { XAI_API_KEY } = getLLMConfig();
 
       const apiKey = apiKeyManager.pick(payload?.apiKey || XAI_API_KEY);
+      const baseURL = payload?.endpoint || process.env.XAI_PROXY_URL;
 
-      return { apiKey };
+      return { apiKey, baseURL };
     }
     case ModelProvider.InternLM: {
       const { INTERNLM_API_KEY } = getLLMConfig();
