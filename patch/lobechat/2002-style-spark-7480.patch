diff --git a/src/config/aiModels/spark.ts b/src/config/aiModels/spark.ts
index 99f1990d858e4..97c7c3d78ed45 100644
--- a/src/config/aiModels/spark.ts
+++ b/src/config/aiModels/spark.ts
@@ -3,8 +3,21 @@ import { AIChatModelCard } from '@/types/aiModel';
 const sparkChatModels: AIChatModelCard[] = [
   {
     abilities: {
+      reasoning: true,
       search: true,
     },
+    contextWindowTokens: 32_768,
+    description:
+      'Spark X1 模型将进一步升级，在原来数学任务国内领先基础上，推理、文本生成、语言理解等通用任务实现效果对标 OpenAI o1 和 DeepSeek R1。',
+    displayName: 'Spark X1',
+    id: 'x1',
+    maxOutput: 32_768,
+    settings: {
+      searchImpl: 'internal',
+    },
+    type: 'chat',
+  },
+  {
     contextWindowTokens: 8192,
     description:
       'Spark Lite 是一款轻量级大语言模型，具备极低的延迟与高效的处理能力，完全免费开放，支持实时在线搜索功能。其快速响应的特性使其在低算力设备上的推理应用和模型微调中表现出色，为用户带来出色的成本效益和智能体验，尤其在知识问答、内容生成及搜索场景下表现不俗。',
@@ -12,9 +25,6 @@ const sparkChatModels: AIChatModelCard[] = [
     enabled: true,
     id: 'lite',
     maxOutput: 4096,
-    settings: {
-      searchImpl: 'internal',
-    },
     type: 'chat',
   },
   {
@@ -34,19 +44,12 @@ const sparkChatModels: AIChatModelCard[] = [
     type: 'chat',
   },
   {
-    abilities: {
-      search: true,
-    },
     contextWindowTokens: 131_072,
     description:
       'Spark Pro 128K 配置了特大上下文处理能力，能够处理多达128K的上下文信息，特别适合需通篇分析和长期逻辑关联处理的长文内容，可在复杂文本沟通中提供流畅一致的逻辑与多样的引用支持。',
     displayName: 'Spark Pro 128K',
-    enabled: true,
     id: 'pro-128k',
     maxOutput: 4096,
-    settings: {
-      searchImpl: 'internal',
-    },
     type: 'chat',
   },
   {
@@ -62,7 +65,7 @@ const sparkChatModels: AIChatModelCard[] = [
     id: 'generalv3.5',
     maxOutput: 8192,
     settings: {
-      searchImpl: 'internal',
+      searchImpl: 'params',
     },
     type: 'chat',
   },
@@ -75,7 +78,6 @@ const sparkChatModels: AIChatModelCard[] = [
     description:
       'Spark Max 32K 配置了大上下文处理能力，更强的上下文理解和逻辑推理能力，支持32K tokens的文本输入，适用于长文档阅读、私有知识问答等场景',
     displayName: 'Spark Max 32K',
-    enabled: true,
     id: 'max-32k',
     maxOutput: 8192,
     settings: {
@@ -96,7 +98,7 @@ const sparkChatModels: AIChatModelCard[] = [
     id: '4.0Ultra',
     maxOutput: 8192,
     settings: {
-      searchImpl: 'internal',
+      searchImpl: 'params',
     },
     type: 'chat',
   },
diff --git a/src/config/modelProviders/spark.ts b/src/config/modelProviders/spark.ts
index dd1d705dafaeb..ffdeac6cd3be4 100644
--- a/src/config/modelProviders/spark.ts
+++ b/src/config/modelProviders/spark.ts
@@ -70,6 +70,9 @@ const Spark: ModelProviderCard = {
   name: 'Spark',
   settings: {
     modelEditable: false,
+    proxyUrl: {
+      placeholder: 'https://spark-api-open.xf-yun.com/v1',
+    },
     sdkType: 'openai',
     showModelFetcher: false,
     smoothing: {
diff --git a/src/libs/agent-runtime/spark/index.ts b/src/libs/agent-runtime/spark/index.ts
index 95d3f3e81d45a..3dfce3e844db1 100644
--- a/src/libs/agent-runtime/spark/index.ts
+++ b/src/libs/agent-runtime/spark/index.ts
@@ -1,4 +1,4 @@
-import { ModelProvider } from '../types';
+import { ChatStreamPayload, ModelProvider } from '../types';
 import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
 
 import { transformSparkResponseToStream, SparkAIStream } from '../utils/streams';
@@ -6,6 +6,26 @@ import { transformSparkResponseToStream, SparkAIStream } from '../utils/streams'
 export const LobeSparkAI = LobeOpenAICompatibleFactory({
   baseURL: 'https://spark-api-open.xf-yun.com/v1',
   chatCompletion: {
+    handlePayload: (payload: ChatStreamPayload) => {
+      const { enabledSearch, tools, ...rest } = payload;
+
+      const sparkTools = enabledSearch ? [
+        ...(tools || []),
+        {
+          type: "web_search",
+          web_search: {
+            enable: true,
+            search_mode: process.env.SPARK_SEARCH_MODE || "normal", // normal or deep
+            show_ref_label: true,
+          },
+        }
+      ] : tools;
+
+      return {
+        ...rest,
+        tools: sparkTools,
+      } as any;
+    },
     handleStream: SparkAIStream,
     handleTransformResponseToStream: transformSparkResponseToStream,
     noUserId: true,
