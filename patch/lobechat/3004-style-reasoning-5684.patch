diff --git a/locales/ar/modelProvider.json b/locales/ar/modelProvider.json
index 6a814b9c43cd..7d6c29842c1c 100644
--- a/locales/ar/modelProvider.json
+++ b/locales/ar/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "معرف النموذج"
         },
         "modalTitle": "تكوين النموذج المخصص",
+        "reasoning": {
+          "extra": "هذا الإعداد سيفتح فقط قدرة النموذج على التفكير العميق، التأثير الفعلي يعتمد بالكامل على النموذج نفسه، يرجى اختبار ما إذا كان هذا النموذج يمتلك القدرة على التفكير العميق القابل للاستخدام",
+          "title": "يدعم التفكير العميق"
+        },
         "tokens": {
           "extra": "تعيين الحد الأقصى لعدد الرموز المدعومة من قبل النموذج",
           "title": "أقصى نافذة سياق",
diff --git a/locales/bg-BG/modelProvider.json b/locales/bg-BG/modelProvider.json
index 052e9348a063..3cd8cab8372d 100644
--- a/locales/bg-BG/modelProvider.json
+++ b/locales/bg-BG/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID на модела"
         },
         "modalTitle": "Конфигурация на персонализиран модел",
+        "reasoning": {
+          "extra": "Тази конфигурация ще активира само способността на модела за дълбоко мислене, конкретният ефект зависи изцяло от самия модел, моля, тествайте сами дали моделът притежава налична способност за дълбоко мислене",
+          "title": "Поддръжка на дълбоко мислене"
+        },
         "tokens": {
           "extra": "Настройте максималния брой токени, поддържани от модела",
           "title": "Максимален контекстуален прозорец",
diff --git a/locales/de-DE/modelProvider.json b/locales/de-DE/modelProvider.json
index 5fc4ac96ff9b..e2d0b0239d81 100644
--- a/locales/de-DE/modelProvider.json
+++ b/locales/de-DE/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "Modell-ID"
         },
         "modalTitle": "Benutzerdefinierte Modellkonfiguration",
+        "reasoning": {
+          "extra": "Diese Konfiguration aktiviert nur die Fähigkeit des Modells zu tiefem Denken. Die tatsächlichen Ergebnisse hängen vollständig vom Modell selbst ab. Bitte testen Sie selbst, ob das Modell über die Fähigkeit zum tiefen Denken verfügt.",
+          "title": "Unterstützung für tiefes Denken"
+        },
         "tokens": {
           "extra": "Maximale Token-Anzahl für das Modell festlegen",
           "title": "Maximales Kontextfenster",
diff --git a/locales/en-US/modelProvider.json b/locales/en-US/modelProvider.json
index 9bd84f6d8303..5895b3d23947 100644
--- a/locales/en-US/modelProvider.json
+++ b/locales/en-US/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "Model ID"
         },
         "modalTitle": "Custom Model Configuration",
+        "reasoning": {
+          "extra": "This configuration will enable the model's deep thinking capabilities, and the specific effects depend entirely on the model itself. Please test whether this model has usable deep thinking abilities.",
+          "title": "Support Deep Thinking"
+        },
         "tokens": {
           "extra": "Set the maximum number of tokens supported by the model",
           "title": "Maximum Context Window",
diff --git a/locales/es-ES/modelProvider.json b/locales/es-ES/modelProvider.json
index 5ae011c2f271..5e458c09e642 100644
--- a/locales/es-ES/modelProvider.json
+++ b/locales/es-ES/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID del modelo"
         },
         "modalTitle": "Configuración del modelo personalizado",
+        "reasoning": {
+          "extra": "Esta configuración solo activará la capacidad de pensamiento profundo del modelo, el efecto específico depende completamente del modelo en sí, por favor, pruebe si este modelo tiene la capacidad de pensamiento profundo utilizable",
+          "title": "Soporte para pensamiento profundo"
+        },
         "tokens": {
           "extra": "Establecer el número máximo de tokens que el modelo puede soportar",
           "title": "Máximo de ventana de contexto",
diff --git a/locales/fa-IR/modelProvider.json b/locales/fa-IR/modelProvider.json
index 9be7c95a9545..58401a196c4c 100644
--- a/locales/fa-IR/modelProvider.json
+++ b/locales/fa-IR/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "شناسه مدل"
         },
         "modalTitle": "پیکربندی مدل سفارشی",
+        "reasoning": {
+          "extra": "این تنظیم فقط قابلیت تفکر عمیق مدل را فعال می‌کند و تأثیر دقیق آن کاملاً به خود مدل بستگی دارد، لطفاً خودتان آزمایش کنید که آیا این مدل قابلیت تفکر عمیق قابل استفاده را دارد یا خیر",
+          "title": "پشتیبانی از تفکر عمیق"
+        },
         "tokens": {
           "extra": "حداکثر تعداد توکن‌های پشتیبانی شده توسط مدل را تنظیم کنید",
           "title": "حداکثر پنجره زمینه",
diff --git a/locales/fr-FR/modelProvider.json b/locales/fr-FR/modelProvider.json
index 662d390eb042..2970a349be81 100644
--- a/locales/fr-FR/modelProvider.json
+++ b/locales/fr-FR/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID du modèle"
         },
         "modalTitle": "Configuration du modèle personnalisé",
+        "reasoning": {
+          "extra": "Cette configuration activera uniquement la capacité de réflexion approfondie du modèle. Les résultats dépendent entièrement du modèle lui-même, veuillez tester si ce modèle possède une capacité de réflexion approfondie utilisable.",
+          "title": "Support de la réflexion approfondie"
+        },
         "tokens": {
           "extra": "Définir le nombre maximal de tokens pris en charge par le modèle",
           "title": "Fenêtre de contexte maximale",
diff --git a/locales/it-IT/modelProvider.json b/locales/it-IT/modelProvider.json
index 95323fb88db6..c9f95e302a81 100644
--- a/locales/it-IT/modelProvider.json
+++ b/locales/it-IT/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID del modello"
         },
         "modalTitle": "Configurazione modello personalizzato",
+        "reasoning": {
+          "extra": "Questa configurazione attiverà solo la capacità di pensiero profondo del modello; l'effetto specifico dipende interamente dal modello stesso. Si prega di testare autonomamente se il modello possiede una capacità di pensiero profondo utilizzabile.",
+          "title": "Supporto per il pensiero profondo"
+        },
         "tokens": {
           "extra": "Imposta il numero massimo di token supportati dal modello",
           "title": "Finestra di contesto massima",
diff --git a/locales/ja-JP/modelProvider.json b/locales/ja-JP/modelProvider.json
index 1a224fe1cef8..24498acbff46 100644
--- a/locales/ja-JP/modelProvider.json
+++ b/locales/ja-JP/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "モデル ID"
         },
         "modalTitle": "カスタムモデル設定",
+        "reasoning": {
+          "extra": "この設定は、モデルの深い思考能力を有効にするだけです。具体的な効果はモデル自体に依存しますので、このモデルが利用可能な深い思考能力を持っているかどうかはご自身でテストしてください。",
+          "title": "深い思考をサポート"
+        },
         "tokens": {
           "extra": "モデルがサポートする最大トークン数を設定する",
           "title": "最大コンテキストウィンドウ",
diff --git a/locales/ko-KR/modelProvider.json b/locales/ko-KR/modelProvider.json
index f1010cf5dbd8..380c975bb68b 100644
--- a/locales/ko-KR/modelProvider.json
+++ b/locales/ko-KR/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "모델 ID"
         },
         "modalTitle": "사용자 정의 모델 구성",
+        "reasoning": {
+          "extra": "이 설정은 모델의 심층 사고 능력만을 활성화합니다. 구체적인 효과는 모델 자체에 따라 다르므로, 해당 모델이 사용 가능한 심층 사고 능력을 갖추고 있는지 직접 테스트해 보시기 바랍니다.",
+          "title": "심층 사고 지원"
+        },
         "tokens": {
           "extra": "모델이 지원하는 최대 토큰 수 설정",
           "title": "최대 컨텍스트 창",
diff --git a/locales/nl-NL/modelProvider.json b/locales/nl-NL/modelProvider.json
index e65cd18ec4ca..d973fcafaff7 100644
--- a/locales/nl-NL/modelProvider.json
+++ b/locales/nl-NL/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "Model ID"
         },
         "modalTitle": "Configuratie van aangepast model",
+        "reasoning": {
+          "extra": "Deze configuratie schakelt alleen de mogelijkheid voor diepgaand denken van het model in. Het specifieke effect hangt volledig af van het model zelf, test zelf of dit model in staat is tot bruikbaar diepgaand denken.",
+          "title": "Ondersteuning voor diepgaand denken"
+        },
         "tokens": {
           "extra": "Stel het maximale aantal tokens in dat door het model wordt ondersteund",
           "title": "Maximale contextvenster",
diff --git a/locales/pl-PL/modelProvider.json b/locales/pl-PL/modelProvider.json
index 99e4c20db382..8d030af0513a 100644
--- a/locales/pl-PL/modelProvider.json
+++ b/locales/pl-PL/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID modelu"
         },
         "modalTitle": "Konfiguracja niestandardowego modelu",
+        "reasoning": {
+          "extra": "Ta konfiguracja włączy jedynie zdolność modelu do głębokiego myślenia, a konkretne efekty w pełni zależą od samego modelu. Proszę samodzielnie przetestować, czy model ma zdolność do głębokiego myślenia.",
+          "title": "Wsparcie dla głębokiego myślenia"
+        },
         "tokens": {
           "extra": "Ustaw maksymalną liczbę tokenów wspieranych przez model",
           "title": "Maksymalne okno kontekstu",
diff --git a/locales/pt-BR/modelProvider.json b/locales/pt-BR/modelProvider.json
index 618913550995..d7f953807427 100644
--- a/locales/pt-BR/modelProvider.json
+++ b/locales/pt-BR/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID do Modelo"
         },
         "modalTitle": "Configuração do Modelo Personalizado",
+        "reasoning": {
+          "extra": "Esta configuração ativará apenas a capacidade de pensamento profundo do modelo, e o efeito específico depende totalmente do próprio modelo. Por favor, teste se este modelo possui a capacidade de pensamento profundo utilizável.",
+          "title": "Suporte a Pensamento Profundo"
+        },
         "tokens": {
           "extra": "Configurar o número máximo de tokens suportados pelo modelo",
           "title": "Janela de contexto máxima",
diff --git a/locales/ru-RU/modelProvider.json b/locales/ru-RU/modelProvider.json
index 538edac4ee26..13db95d4a9de 100644
--- a/locales/ru-RU/modelProvider.json
+++ b/locales/ru-RU/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID модели"
         },
         "modalTitle": "Настройка пользовательской модели",
+        "reasoning": {
+          "extra": "Эта настройка активирует возможность глубокого мышления модели, конкретный эффект полностью зависит от самой модели, пожалуйста, протестируйте, обладает ли модель доступной способностью к глубокому мышлению",
+          "title": "Поддержка глубокого мышления"
+        },
         "tokens": {
           "extra": "Установите максимальное количество токенов, поддерживаемое моделью",
           "title": "Максимальное окно контекста",
diff --git a/locales/tr-TR/modelProvider.json b/locales/tr-TR/modelProvider.json
index ee5320b69e24..4641fdd5979b 100644
--- a/locales/tr-TR/modelProvider.json
+++ b/locales/tr-TR/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "Model ID"
         },
         "modalTitle": "Özel Model Yapılandırması",
+        "reasoning": {
+          "extra": "Bu yapılandırma yalnızca modelin derin düşünme yeteneğini açacaktır, belirli etkiler tamamen modelin kendisine bağlıdır, lütfen bu modelin kullanılabilir derin düşünme yeteneğine sahip olup olmadığını kendiniz test edin",
+          "title": "Derin düşünmeyi destekler"
+        },
         "tokens": {
           "extra": "Modelin desteklediği maksimum Token sayısını ayarlayın",
           "title": "Maksimum bağlam penceresi",
diff --git a/locales/vi-VN/modelProvider.json b/locales/vi-VN/modelProvider.json
index c8be40a87c5a..fd3aaa317530 100644
--- a/locales/vi-VN/modelProvider.json
+++ b/locales/vi-VN/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID mô hình"
         },
         "modalTitle": "Cấu hình mô hình tùy chỉnh",
+        "reasoning": {
+          "extra": "Cấu hình này sẽ chỉ kích hoạt khả năng suy nghĩ sâu của mô hình, hiệu quả cụ thể hoàn toàn phụ thuộc vào chính mô hình, vui lòng tự kiểm tra xem mô hình này có khả năng suy nghĩ sâu có thể sử dụng hay không",
+          "title": "Hỗ trợ suy nghĩ sâu"
+        },
         "tokens": {
           "extra": "Cài đặt số Token tối đa mà mô hình hỗ trợ",
           "title": "Cửa sổ ngữ cảnh tối đa",
diff --git a/locales/zh-CN/modelProvider.json b/locales/zh-CN/modelProvider.json
index 5af434fcb767..cacab2e2e088 100644
--- a/locales/zh-CN/modelProvider.json
+++ b/locales/zh-CN/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "模型 ID"
         },
         "modalTitle": "自定义模型配置",
+        "reasoning": {
+          "extra": "此配置将仅开启模型深度思考的能力，具体效果完全取决于模型本身，请自行测试该模型是否具备可用的深度思考能力",
+          "title": "支持深度思考"
+        },
         "tokens": {
           "extra": "设置模型支持的最大 Token 数",
           "title": "最大上下文窗口",
diff --git a/locales/zh-TW/modelProvider.json b/locales/zh-TW/modelProvider.json
index 38426be40fac..7377275deccd 100644
--- a/locales/zh-TW/modelProvider.json
+++ b/locales/zh-TW/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "模型 ID"
         },
         "modalTitle": "自定義模型配置",
+        "reasoning": {
+          "extra": "此配置將僅開啟模型深度思考的能力，具體效果完全取決於模型本身，請自行測試該模型是否具備可用的深度思考能力",
+          "title": "支持深度思考"
+        },
         "tokens": {
           "extra": "設定模型支持的最大 Token 數",
           "title": "最大上下文窗口",
diff --git a/src/app/(main)/settings/provider/features/ModelList/CreateNewModelModal/Form.tsx b/src/app/(main)/settings/provider/features/ModelList/CreateNewModelModal/Form.tsx
index e7eadc99874a..a8ed2b50bf05 100644
--- a/src/app/(main)/settings/provider/features/ModelList/CreateNewModelModal/Form.tsx
+++ b/src/app/(main)/settings/provider/features/ModelList/CreateNewModelModal/Form.tsx
@@ -95,6 +95,14 @@ const ModelConfigForm = memo<ModelConfigFormProps>(
           >
             <Checkbox />
           </Form.Item>
+          <Form.Item
+            extra={t('providerModels.item.modelConfig.reasoning.extra')}
+            label={t('providerModels.item.modelConfig.reasoning.title')}
+            name={['abilities', 'reasoning']}
+            valuePropName={'checked'}
+          >
+            <Checkbox />
+          </Form.Item>
           {/*<Form.Item*/}
           {/*  extra={t('providerModels.item.modelConfig.files.extra')}*/}
           {/*  label={t('providerModels.item.modelConfig.files.title')}*/}
diff --git a/src/hooks/useModelSupportReasoning.ts b/src/hooks/useModelSupportReasoning.ts
new file mode 100644
index 000000000000..fdbdf5e01b76
--- /dev/null
+++ b/src/hooks/useModelSupportReasoning.ts
@@ -0,0 +1,15 @@
+import { isDeprecatedEdition } from '@/const/version';
+import { aiModelSelectors, useAiInfraStore } from '@/store/aiInfra';
+import { useUserStore } from '@/store/user';
+import { modelProviderSelectors } from '@/store/user/selectors';
+
+export const useModelSupportReasoning = (model: string, provider: string) => {
+  const newValue = useAiInfraStore(aiModelSelectors.isModelSupportReasoning(model, provider));
+
+  // TODO: remove this in V2.0
+  const oldValue = useUserStore(modelProviderSelectors.isModelEnabledReasoning(model));
+  if (isDeprecatedEdition) return oldValue;
+  //
+
+  return newValue;
+};
diff --git a/src/locales/default/modelProvider.ts b/src/locales/default/modelProvider.ts
index f86f94035e9b..0146a604dd90 100644
--- a/src/locales/default/modelProvider.ts
+++ b/src/locales/default/modelProvider.ts
@@ -231,6 +231,11 @@ export default {
           title: '模型 ID',
         },
         modalTitle: '自定义模型配置',
+        reasoning: {
+          extra:
+            '此配置将仅开启模型深度思考的能力，具体效果完全取决于模型本身，请自行测试该模型是否具备可用的深度思考能力',
+          title: '支持深度思考',
+        },
         tokens: {
           extra: '设置模型支持的最大 Token 数',
           title: '最大上下文窗口',
diff --git a/src/store/aiInfra/slices/aiModel/action.ts b/src/store/aiInfra/slices/aiModel/action.ts
index 5aa452179611..53db78c696ea 100644
--- a/src/store/aiInfra/slices/aiModel/action.ts
+++ b/src/store/aiInfra/slices/aiModel/action.ts
@@ -74,6 +74,7 @@ export const createAiModelSlice: StateCreator<
           abilities: {
             files: model.files,
             functionCall: model.functionCall,
+            reasoning: model.reasoning,
             vision: model.vision,
           },
           enabled: model.enabled || false,
diff --git a/src/store/aiInfra/slices/aiModel/selectors.ts b/src/store/aiInfra/slices/aiModel/selectors.ts
index bd6030d77d16..9c9915a393b4 100644
--- a/src/store/aiInfra/slices/aiModel/selectors.ts
+++ b/src/store/aiInfra/slices/aiModel/selectors.ts
@@ -48,6 +48,12 @@ const isModelSupportVision = (id: string, provider: string) => (s: AIProviderSto
   return model?.abilities?.vision;
 };
 
+const isModelSupportReasoning = (id: string, provider: string) => (s: AIProviderStoreState) => {
+  const model = getEnabledModelById(id, provider)(s);
+
+  return model?.abilities?.reasoning;
+};
+
 const isModelHasContextWindowToken =
   (id: string, provider: string) => (s: AIProviderStoreState) => {
     const model = getEnabledModelById(id, provider)(s);
@@ -71,6 +77,7 @@ export const aiModelSelectors = {
   isModelEnabled,
   isModelHasContextWindowToken,
   isModelLoading,
+  isModelSupportReasoning,
   isModelSupportToolUse,
   isModelSupportVision,
   modelContextWindowTokens,
diff --git a/src/store/user/slices/modelList/selectors/modelProvider.ts b/src/store/user/slices/modelList/selectors/modelProvider.ts
index cf0c71f67243..84733a2838c6 100644
--- a/src/store/user/slices/modelList/selectors/modelProvider.ts
+++ b/src/store/user/slices/modelList/selectors/modelProvider.ts
@@ -122,6 +122,9 @@ const isModelEnabledFunctionCall = (id: string) => (s: UserStore) =>
 const isModelEnabledVision = (id: string) => (s: UserStore) =>
   getModelCardById(id)(s)?.vision || id.includes('vision');
 
+const isModelEnabledReasoning = (id: string) => (s: UserStore) =>
+  getModelCardById(id)(s)?.reasoning || false;
+
 const isModelEnabledFiles = (id: string) => (s: UserStore) => getModelCardById(id)(s)?.files;
 
 const isModelEnabledUpload = (id: string) => (s: UserStore) =>
@@ -144,6 +147,7 @@ export const modelProviderSelectors = {
   getModelCardsById,
   isModelEnabledFiles,
   isModelEnabledFunctionCall,
+  isModelEnabledReasoning,
   isModelEnabledUpload,
   isModelEnabledVision,
   isModelHasMaxToken,
diff --git a/src/types/aiModel.ts b/src/types/aiModel.ts
index 8e2f0c3076ad..57fa549f9b1a 100644
--- a/src/types/aiModel.ts
+++ b/src/types/aiModel.ts
@@ -43,6 +43,7 @@ export interface ModelAbilities {
 const AiModelAbilitiesSchema = z.object({
   // files: z.boolean().optional(),
   functionCall: z.boolean().optional(),
+  reasoning: z.boolean().optional(),
   vision: z.boolean().optional(),
 });
 
@@ -205,6 +206,10 @@ export interface AIRealtimeModelCard extends AIBaseModelCard {
      * whether model supports function call
      */
     functionCall?: boolean;
+    /**
+     *  whether model supports reasoning
+     */
+    reasoning?: boolean;
     /**
      *  whether model supports vision
      */
diff --git a/src/types/llm.ts b/src/types/llm.ts
index bfde6dd57cf5..930283580677 100644
--- a/src/types/llm.ts
+++ b/src/types/llm.ts
@@ -42,6 +42,15 @@ export interface ChatModelCard {
   legacy?: boolean;
   maxOutput?: number;
   pricing?: ChatModelPricing;
+
+  /**
+   *  whether model supports reasoning
+   */
+  reasoning?: boolean;
+
+  /**
+   * whether model is legacy (deprecated but not removed yet)
+   */
   releasedAt?: string;
 
   /**
diff --git a/src/utils/_deprecated/parseModels.test.ts b/src/utils/_deprecated/parseModels.test.ts
index 7adfca0925d0..8f2ad1607d4c 100644
--- a/src/utils/_deprecated/parseModels.test.ts
+++ b/src/utils/_deprecated/parseModels.test.ts
@@ -52,6 +52,17 @@ describe('parseModelString', () => {
       });
     });
 
+    it('token and reasoning', () => {
+      const result = parseModelString('deepseek-r1=Deepseek R1<65536:reasoning>');
+
+      expect(result.add[0]).toEqual({
+        displayName: 'Deepseek R1',
+        reasoning: true,
+        id: 'deepseek-r1',
+        contextWindowTokens: 65_536,
+      });
+    });
+
     it('multi models', () => {
       const result = parseModelString(
         'gemini-1.5-flash-latest=Gemini 1.5 Flash<16000:vision>,gpt-4-all=ChatGPT Plus<128000:fc:vision:file>',
diff --git a/src/utils/_deprecated/parseModels.ts b/src/utils/_deprecated/parseModels.ts
index 7e965902998b..8cd61e0a2151 100644
--- a/src/utils/_deprecated/parseModels.ts
+++ b/src/utils/_deprecated/parseModels.ts
@@ -60,6 +60,10 @@ export const parseModelString = (modelString: string = '', withDeploymentName =
 
       for (const capability of capabilityList) {
         switch (capability) {
+          case 'reasoning': {
+            model.reasoning = true;
+            break;
+          }
           case 'vision': {
             model.vision = true;
             break;
diff --git a/src/utils/parseModels.test.ts b/src/utils/parseModels.test.ts
index a11a05c50f5b..428cf5950463 100644
--- a/src/utils/parseModels.test.ts
+++ b/src/utils/parseModels.test.ts
@@ -58,6 +58,20 @@ describe('parseModelString', () => {
       });
     });
 
+    it('token and reasoning', () => {
+      const result = parseModelString('deepseek-r1=Deepseek R1<65536:reasoning>');
+
+      expect(result.add[0]).toEqual({
+        displayName: 'Deepseek R1',
+        abilities: {
+          reasoning: true,
+        },
+        id: 'deepseek-r1',
+        contextWindowTokens: 65_536,
+        type: 'chat',
+      });
+    });
+
     it('multi models', () => {
       const result = parseModelString(
         'gemini-1.5-flash-latest=Gemini 1.5 Flash<16000:vision>,gpt-4-all=ChatGPT Plus<128000:fc:vision:file>',
diff --git a/src/utils/parseModels.ts b/src/utils/parseModels.ts
index 8b130394a3bf..690ceb356004 100644
--- a/src/utils/parseModels.ts
+++ b/src/utils/parseModels.ts
@@ -64,6 +64,10 @@ export const parseModelString = (modelString: string = '', withDeploymentName =
 
       for (const capability of capabilityList) {
         switch (capability) {
+          case 'reasoning': {
+            model.abilities!.reasoning = true;
+            break;
+          }
           case 'vision': {
             model.abilities!.vision = true;
             break;
