diff --git a/locales/ar/modelProvider.json b/locales/ar/modelProvider.json
index 6a814b9c43cd6..2eda467b48599 100644
--- a/locales/ar/modelProvider.json
+++ b/locales/ar/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "معرف النموذج"
         },
         "modalTitle": "تكوين النموذج المخصص",
+        "reasoning": {
+          "extra": "هذا الإعداد سيفتح فقط قدرة النموذج على التفكير العميق، وما إذا كان يدعم التعرف يعتمد بالكامل على النموذج نفسه، يرجى اختبار قابلية استخدام قدرة التفكير العميق لهذا النموذج بنفسك",
+          "title": "يدعم التفكير العميق"
+        },
         "tokens": {
           "extra": "تعيين الحد الأقصى لعدد الرموز المدعومة من قبل النموذج",
           "title": "أقصى نافذة سياق",
diff --git a/locales/bg-BG/modelProvider.json b/locales/bg-BG/modelProvider.json
index 052e9348a063d..9c4fb16ac51e1 100644
--- a/locales/bg-BG/modelProvider.json
+++ b/locales/bg-BG/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID на модела"
         },
         "modalTitle": "Конфигурация на персонализиран модел",
+        "reasoning": {
+          "extra": "Тази конфигурация ще активира само способността на модела за дълбоко мислене. Подкрепата за разпознаване зависи изцяло от самия модел. Моля, тествайте сами наличността на способността за дълбоко мислене на този модел.",
+          "title": "Подкрепа за дълбоко мислене"
+        },
         "tokens": {
           "extra": "Настройте максималния брой токени, поддържани от модела",
           "title": "Максимален контекстуален прозорец",
diff --git a/locales/de-DE/modelProvider.json b/locales/de-DE/modelProvider.json
index 5fc4ac96ff9bb..63fdd3897ad96 100644
--- a/locales/de-DE/modelProvider.json
+++ b/locales/de-DE/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "Modell-ID"
         },
         "modalTitle": "Benutzerdefinierte Modellkonfiguration",
+        "reasoning": {
+          "extra": "Diese Konfiguration aktiviert nur die Fähigkeit des Modells zum tiefen Denken. Ob die Erkennung unterstützt wird, hängt vollständig vom Modell selbst ab. Bitte testen Sie die Verfügbarkeit der tiefen Denkfähigkeit dieses Modells selbst.",
+          "title": "Unterstützung für tiefes Denken"
+        },
         "tokens": {
           "extra": "Maximale Token-Anzahl für das Modell festlegen",
           "title": "Maximales Kontextfenster",
diff --git a/locales/en-US/modelProvider.json b/locales/en-US/modelProvider.json
index 9bd84f6d8303b..4ff944bbda1b6 100644
--- a/locales/en-US/modelProvider.json
+++ b/locales/en-US/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "Model ID"
         },
         "modalTitle": "Custom Model Configuration",
+        "reasoning": {
+          "extra": "This configuration will only enable the model's deep thinking capabilities. Whether it supports recognition depends entirely on the model itself. Please test the availability of the model's deep thinking capabilities on your own.",
+          "title": "Support Deep Thinking"
+        },
         "tokens": {
           "extra": "Set the maximum number of tokens supported by the model",
           "title": "Maximum Context Window",
diff --git a/locales/es-ES/modelProvider.json b/locales/es-ES/modelProvider.json
index 5ae011c2f2719..f37ad756825b8 100644
--- a/locales/es-ES/modelProvider.json
+++ b/locales/es-ES/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID del modelo"
         },
         "modalTitle": "Configuración del modelo personalizado",
+        "reasoning": {
+          "extra": "Esta configuración solo activará la capacidad de pensamiento profundo del modelo; si admite el reconocimiento depende completamente del modelo en sí. Por favor, pruebe la disponibilidad de la capacidad de pensamiento profundo de este modelo.",
+          "title": "Soporte para pensamiento profundo"
+        },
         "tokens": {
           "extra": "Establecer el número máximo de tokens que el modelo puede soportar",
           "title": "Máximo de ventana de contexto",
diff --git a/locales/fa-IR/modelProvider.json b/locales/fa-IR/modelProvider.json
index 9be7c95a9545d..434f1ad961a46 100644
--- a/locales/fa-IR/modelProvider.json
+++ b/locales/fa-IR/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "شناسه مدل"
         },
         "modalTitle": "پیکربندی مدل سفارشی",
+        "reasoning": {
+          "extra": "این تنظیم فقط قابلیت تفکر عمیق مدل را فعال می‌کند و اینکه آیا شناسایی پشتیبانی می‌شود به خود مدل بستگی دارد، لطفاً قابلیت تفکر عمیق این مدل را خودتان آزمایش کنید",
+          "title": "پشتیبانی از تفکر عمیق"
+        },
         "tokens": {
           "extra": "حداکثر تعداد توکن‌های پشتیبانی شده توسط مدل را تنظیم کنید",
           "title": "حداکثر پنجره زمینه",
diff --git a/locales/fr-FR/modelProvider.json b/locales/fr-FR/modelProvider.json
index 662d390eb0427..cb8bfdc126b82 100644
--- a/locales/fr-FR/modelProvider.json
+++ b/locales/fr-FR/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID du modèle"
         },
         "modalTitle": "Configuration du modèle personnalisé",
+        "reasoning": {
+          "extra": "Cette configuration activera uniquement la capacité de réflexion approfondie du modèle. La prise en charge de la reconnaissance dépend entièrement du modèle lui-même. Veuillez tester vous-même la disponibilité de la capacité de réflexion approfondie de ce modèle.",
+          "title": "Support de la réflexion approfondie"
+        },
         "tokens": {
           "extra": "Définir le nombre maximal de tokens pris en charge par le modèle",
           "title": "Fenêtre de contexte maximale",
diff --git a/locales/it-IT/modelProvider.json b/locales/it-IT/modelProvider.json
index 95323fb88db62..ad146d070b81f 100644
--- a/locales/it-IT/modelProvider.json
+++ b/locales/it-IT/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID del modello"
         },
         "modalTitle": "Configurazione modello personalizzato",
+        "reasoning": {
+          "extra": "Questa configurazione attiverà solo la capacità di pensiero profondo del modello; se supporta il riconoscimento dipende interamente dal modello stesso. Si prega di testare autonomamente la disponibilità della capacità di pensiero profondo di questo modello.",
+          "title": "Supporta il pensiero profondo"
+        },
         "tokens": {
           "extra": "Imposta il numero massimo di token supportati dal modello",
           "title": "Finestra di contesto massima",
diff --git a/locales/ja-JP/modelProvider.json b/locales/ja-JP/modelProvider.json
index 1a224fe1cef84..a0b6c9735b22f 100644
--- a/locales/ja-JP/modelProvider.json
+++ b/locales/ja-JP/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "モデル ID"
         },
         "modalTitle": "カスタムモデル設定",
+        "reasoning": {
+          "extra": "この設定はモデルの深い思考能力を有効にするだけであり、認識のサポートはモデル自体に依存します。このモデルの深い思考能力の有用性を自分でテストしてください",
+          "title": "深い思考をサポート"
+        },
         "tokens": {
           "extra": "モデルがサポートする最大トークン数を設定する",
           "title": "最大コンテキストウィンドウ",
diff --git a/locales/ko-KR/modelProvider.json b/locales/ko-KR/modelProvider.json
index f1010cf5dbd8d..1bb6c3a3d4844 100644
--- a/locales/ko-KR/modelProvider.json
+++ b/locales/ko-KR/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "모델 ID"
         },
         "modalTitle": "사용자 정의 모델 구성",
+        "reasoning": {
+          "extra": "이 설정은 모델의 심층 사고 능력만 활성화합니다. 인식 지원 여부는 모델 자체에 따라 다르므로, 해당 모델의 심층 사고 능력의 유효성을 직접 테스트해 보시기 바랍니다.",
+          "title": "심층 사고 지원"
+        },
         "tokens": {
           "extra": "모델이 지원하는 최대 토큰 수 설정",
           "title": "최대 컨텍스트 창",
diff --git a/locales/nl-NL/modelProvider.json b/locales/nl-NL/modelProvider.json
index e65cd18ec4cad..b32ed17ab6afa 100644
--- a/locales/nl-NL/modelProvider.json
+++ b/locales/nl-NL/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "Model ID"
         },
         "modalTitle": "Configuratie van aangepast model",
+        "reasoning": {
+          "extra": "Deze configuratie zal alleen de mogelijkheid van diepgaand denken van het model inschakelen. Of het model in staat is om te herkennen, hangt volledig af van het model zelf. Test zelf de beschikbaarheid van het diepgaand denken van dit model.",
+          "title": "Ondersteuning voor diepgaand denken"
+        },
         "tokens": {
           "extra": "Stel het maximale aantal tokens in dat door het model wordt ondersteund",
           "title": "Maximale contextvenster",
diff --git a/locales/pl-PL/modelProvider.json b/locales/pl-PL/modelProvider.json
index 99e4c20db3828..913f86786c43e 100644
--- a/locales/pl-PL/modelProvider.json
+++ b/locales/pl-PL/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID modelu"
         },
         "modalTitle": "Konfiguracja niestandardowego modelu",
+        "reasoning": {
+          "extra": "Ta konfiguracja włączy jedynie zdolność modelu do głębokiego myślenia, a to, czy rozpoznawanie jest wspierane, zależy od samego modelu. Proszę samodzielnie przetestować dostępność zdolności głębokiego myślenia tego modelu.",
+          "title": "Wsparcie dla głębokiego myślenia"
+        },
         "tokens": {
           "extra": "Ustaw maksymalną liczbę tokenów wspieranych przez model",
           "title": "Maksymalne okno kontekstu",
diff --git a/locales/pt-BR/modelProvider.json b/locales/pt-BR/modelProvider.json
index 6189135509954..fb7135969c749 100644
--- a/locales/pt-BR/modelProvider.json
+++ b/locales/pt-BR/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID do Modelo"
         },
         "modalTitle": "Configuração do Modelo Personalizado",
+        "reasoning": {
+          "extra": "Esta configuração ativará apenas a capacidade de raciocínio profundo do modelo; a capacidade de reconhecimento depende do próprio modelo. Por favor, teste a disponibilidade da capacidade de raciocínio profundo deste modelo.",
+          "title": "Suporte a raciocínio profundo"
+        },
         "tokens": {
           "extra": "Configurar o número máximo de tokens suportados pelo modelo",
           "title": "Janela de contexto máxima",
diff --git a/locales/ru-RU/modelProvider.json b/locales/ru-RU/modelProvider.json
index 538edac4ee265..2628ba14ac436 100644
--- a/locales/ru-RU/modelProvider.json
+++ b/locales/ru-RU/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID модели"
         },
         "modalTitle": "Настройка пользовательской модели",
+        "reasoning": {
+          "extra": "Эта настройка активирует только возможность глубокого мышления модели, поддержка распознавания полностью зависит от самой модели, пожалуйста, протестируйте доступность глубокого мышления этой модели самостоятельно",
+          "title": "Поддержка глубокого мышления"
+        },
         "tokens": {
           "extra": "Установите максимальное количество токенов, поддерживаемое моделью",
           "title": "Максимальное окно контекста",
diff --git a/locales/tr-TR/modelProvider.json b/locales/tr-TR/modelProvider.json
index ee5320b69e241..dba46faecd196 100644
--- a/locales/tr-TR/modelProvider.json
+++ b/locales/tr-TR/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "Model ID"
         },
         "modalTitle": "Özel Model Yapılandırması",
+        "reasoning": {
+          "extra": "Bu yapılandırma yalnızca modelin derin düşünme yeteneğini açacaktır, tanıma desteği tamamen modele bağlıdır, lütfen bu modelin derin düşünme yeteneğini test edin",
+          "title": "Derin düşünmeyi destekle"
+        },
         "tokens": {
           "extra": "Modelin desteklediği maksimum Token sayısını ayarlayın",
           "title": "Maksimum bağlam penceresi",
diff --git a/locales/vi-VN/modelProvider.json b/locales/vi-VN/modelProvider.json
index c8be40a87c5a2..823d209054268 100644
--- a/locales/vi-VN/modelProvider.json
+++ b/locales/vi-VN/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "ID mô hình"
         },
         "modalTitle": "Cấu hình mô hình tùy chỉnh",
+        "reasoning": {
+          "extra": "Cấu hình này chỉ kích hoạt khả năng suy nghĩ sâu của mô hình, việc có hỗ trợ nhận diện hay không hoàn toàn phụ thuộc vào chính mô hình, vui lòng tự kiểm tra khả năng suy nghĩ sâu của mô hình này",
+          "title": "Hỗ trợ suy nghĩ sâu"
+        },
         "tokens": {
           "extra": "Cài đặt số Token tối đa mà mô hình hỗ trợ",
           "title": "Cửa sổ ngữ cảnh tối đa",
diff --git a/locales/zh-CN/modelProvider.json b/locales/zh-CN/modelProvider.json
index 5af434fcb767e..aaf5c6a1397b0 100644
--- a/locales/zh-CN/modelProvider.json
+++ b/locales/zh-CN/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "模型 ID"
         },
         "modalTitle": "自定义模型配置",
+        "reasoning": {
+          "extra": "此配置将仅开启模型深度思考的能力，是否支持识别完全取决于模型本身，请自行测试该模型的深度思考能力可用性",
+          "title": "支持深度思考"
+        },
         "tokens": {
           "extra": "设置模型支持的最大 Token 数",
           "title": "最大上下文窗口",
diff --git a/locales/zh-TW/modelProvider.json b/locales/zh-TW/modelProvider.json
index 38426be40facf..a53e1de61ba19 100644
--- a/locales/zh-TW/modelProvider.json
+++ b/locales/zh-TW/modelProvider.json
@@ -229,6 +229,10 @@
           "title": "模型 ID"
         },
         "modalTitle": "自定義模型配置",
+        "reasoning": {
+          "extra": "此配置將僅開啟模型深度思考的能力，是否支持識別完全取決於模型本身，請自行測試該模型的深度思考能力可用性",
+          "title": "支持深度思考"
+        },
         "tokens": {
           "extra": "設定模型支持的最大 Token 數",
           "title": "最大上下文窗口",
diff --git a/src/app/(main)/settings/provider/features/ModelList/CreateNewModelModal/Form.tsx b/src/app/(main)/settings/provider/features/ModelList/CreateNewModelModal/Form.tsx
index e7eadc99874ae..a8ed2b50bf05c 100644
--- a/src/app/(main)/settings/provider/features/ModelList/CreateNewModelModal/Form.tsx
+++ b/src/app/(main)/settings/provider/features/ModelList/CreateNewModelModal/Form.tsx
@@ -95,6 +95,14 @@ const ModelConfigForm = memo<ModelConfigFormProps>(
           >
             <Checkbox />
           </Form.Item>
+          <Form.Item
+            extra={t('providerModels.item.modelConfig.reasoning.extra')}
+            label={t('providerModels.item.modelConfig.reasoning.title')}
+            name={['abilities', 'reasoning']}
+            valuePropName={'checked'}
+          >
+            <Checkbox />
+          </Form.Item>
           {/*<Form.Item*/}
           {/*  extra={t('providerModels.item.modelConfig.files.extra')}*/}
           {/*  label={t('providerModels.item.modelConfig.files.title')}*/}
diff --git a/src/locales/default/modelProvider.ts b/src/locales/default/modelProvider.ts
index f86f94035e9b6..25657f252449b 100644
--- a/src/locales/default/modelProvider.ts
+++ b/src/locales/default/modelProvider.ts
@@ -231,6 +231,11 @@ export default {
           title: '模型 ID',
         },
         modalTitle: '自定义模型配置',
+        reasoning: {
+          extra:
+            '此配置将仅开启模型深度思考的能力，是否支持识别完全取决于模型本身，请自行测试该模型的深度思考能力可用性',
+          title: '支持深度思考',
+        },
         tokens: {
           extra: '设置模型支持的最大 Token 数',
           title: '最大上下文窗口',
diff --git a/src/utils/_deprecated/parseModels.ts b/src/utils/_deprecated/parseModels.ts
index 7e965902998b8..c6800b4cc6b6e 100644
--- a/src/utils/_deprecated/parseModels.ts
+++ b/src/utils/_deprecated/parseModels.ts
@@ -60,6 +60,13 @@ export const parseModelString = (modelString: string = '', withDeploymentName =
 
       for (const capability of capabilityList) {
         switch (capability) {
+          case 'reasoning': {
+            /*
+            * skip warning for reasoning
+            model.reasoning = true;
+            */
+            break;
+          }
           case 'vision': {
             model.vision = true;
             break;
diff --git a/src/utils/parseModels.test.ts b/src/utils/parseModels.test.ts
index a11a05c50f5b3..428cf59504634 100644
--- a/src/utils/parseModels.test.ts
+++ b/src/utils/parseModels.test.ts
@@ -58,6 +58,20 @@ describe('parseModelString', () => {
       });
     });
 
+    it('token and reasoning', () => {
+      const result = parseModelString('deepseek-r1=Deepseek R1<65536:reasoning>');
+
+      expect(result.add[0]).toEqual({
+        displayName: 'Deepseek R1',
+        abilities: {
+          reasoning: true,
+        },
+        id: 'deepseek-r1',
+        contextWindowTokens: 65_536,
+        type: 'chat',
+      });
+    });
+
     it('multi models', () => {
       const result = parseModelString(
         'gemini-1.5-flash-latest=Gemini 1.5 Flash<16000:vision>,gpt-4-all=ChatGPT Plus<128000:fc:vision:file>',
diff --git a/src/utils/parseModels.ts b/src/utils/parseModels.ts
index 8b130394a3bf2..690ceb3560043 100644
--- a/src/utils/parseModels.ts
+++ b/src/utils/parseModels.ts
@@ -64,6 +64,10 @@ export const parseModelString = (modelString: string = '', withDeploymentName =
 
       for (const capability of capabilityList) {
         switch (capability) {
+          case 'reasoning': {
+            model.abilities!.reasoning = true;
+            break;
+          }
           case 'vision': {
             model.abilities!.vision = true;
             break;
