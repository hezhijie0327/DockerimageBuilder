diff --git a/src/app/api/chat/agentRuntime.ts b/src/app/api/chat/agentRuntime.ts
index 71fc5ec23d84..c3532301a7c8 100644
--- a/src/app/api/chat/agentRuntime.ts
+++ b/src/app/api/chat/agentRuntime.ts
@@ -201,11 +201,12 @@ const getLlmOptionsFromPayload = (provider: string, payload: JWTPayload) => {
       return { apiKey };
     }
     case ModelProvider.SiliconCloud: {
-      const { SILICONCLOUD_API_KEY } = getLLMConfig();
+      const { SILICONCLOUD_API_KEY, SILICONCLOUD_PROXY_URL } = getLLMConfig();
 
       const apiKey = apiKeyManager.pick(payload?.apiKey || SILICONCLOUD_API_KEY);
+      const baseURL = payload?.endpoint || SILICONCLOUD_PROXY_URL;
 
-      return { apiKey };
+      return { apiKey, baseURL };
     }
   }
 };
diff --git a/src/config/llm.ts b/src/config/llm.ts
index 0fd194624290..efa57c8e25d5 100644
--- a/src/config/llm.ts
+++ b/src/config/llm.ts
@@ -90,6 +90,8 @@ export const getLLMConfig = () => {
 
       ENABLED_SILICONCLOUD: z.boolean(),
       SILICONCLOUD_API_KEY: z.string().optional(),
+      SILICONCLOUD_MODEL_LIST: z.string().optional(),
+      SILICONCLOUD_PROXY_URL: z.string().optional(),
     },
     runtimeEnv: {
       API_KEY_SELECT_MODE: process.env.API_KEY_SELECT_MODE,
@@ -177,6 +179,8 @@ export const getLLMConfig = () => {
 
       ENABLED_SILICONCLOUD: !!process.env.SILICONCLOUD_API_KEY,
       SILICONCLOUD_API_KEY: process.env.SILICONCLOUD_API_KEY,
+      SILICONCLOUD_MODEL_LIST: process.env.SILICONCLOUD_MODEL_LIST,
+      SILICONCLOUD_PROXY_URL: process.env.SILICONCLOUD_PROXY_URL,
     },
   });
 };
diff --git a/src/config/modelProviders/siliconcloud.ts b/src/config/modelProviders/siliconcloud.ts
index 6f811a88ead1..66986f2d6953 100644
--- a/src/config/modelProviders/siliconcloud.ts
+++ b/src/config/modelProviders/siliconcloud.ts
@@ -122,6 +122,9 @@ const SiliconCloud: ModelProviderCard = {
   id: 'siliconcloud',
   modelList: { showModelFetcher: true },
   name: 'SiliconCloud',
+  proxyUrl: {
+    placeholder: 'https://api.siliconflow.cn/v1',
+  },
 };
 
 export default SiliconCloud;
diff --git a/src/server/globalConfig/index.ts b/src/server/globalConfig/index.ts
index af6904dc38c2..9bbff0e0a32c 100644
--- a/src/server/globalConfig/index.ts
+++ b/src/server/globalConfig/index.ts
@@ -7,6 +7,7 @@ import {
   OllamaProviderCard,
   OpenAIProviderCard,
   OpenRouterProviderCard,
+  SiliconCloudProviderCard,
   TogetherAIProviderCard,
 } from '@/config/modelProviders';
 import { enableNextAuth } from '@/const/auth';
@@ -39,7 +40,9 @@ export const getServerGlobalConfig = () => {
     ENABLED_BAICHUAN,
     ENABLED_TAICHU,
     ENABLED_AI360,
+
     ENABLED_SILICONCLOUD,
+    SILICONCLOUD_MODEL_LIST,
 
     ENABLED_AZURE_OPENAI,
     AZURE_MODEL_LIST,
@@ -113,7 +116,14 @@ export const getServerGlobalConfig = () => {
       },
       perplexity: { enabled: ENABLED_PERPLEXITY },
       qwen: { enabled: ENABLED_QWEN },
-      siliconcloud: { enabled: ENABLED_SILICONCLOUD },
+      siliconcloud: {
+        enabled: ENABLED_SILICONCLOUD,
+        enabledModels: extractEnabledModels(SILICONCLOUD_MODEL_LIST),
+        serverModelCards: transformToChatModelCards({
+          defaultChatModels: SiliconCloudProviderCard.chatModels,
+          modelString: SILICONCLOUD_MODEL_LIST,
+        }),
+      },
       stepfun: { enabled: ENABLED_STEPFUN },
 
       taichu: { enabled: ENABLED_TAICHU },
