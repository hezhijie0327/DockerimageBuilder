diff --git a/src/config/aiModels/openai.ts b/src/config/aiModels/openai.ts
index 1382e660d0c95..d8dc43400408e 100644
--- a/src/config/aiModels/openai.ts
+++ b/src/config/aiModels/openai.ts
@@ -12,21 +12,25 @@ export const openaiChatModels: AIChatModelCard[] = [
     abilities: {
       functionCall: true,
       reasoning: true,
+      search: true,
       vision: true,
     },
     contextWindowTokens: 200_000,
     description:
-      'o3-pro 模型使用更多的计算来更深入地思考并始终提供更好的答案，仅支持 Responses API 下使用。',
-    displayName: 'o3-pro',
-    id: 'o3-pro',
+      'o4-mini 是我们最新的小型 o 系列模型。 它专为快速有效的推理而优化，在编码和视觉任务中表现出极高的效率和性能。',
+    displayName: 'o4-mini',
+    enabled: true,
+    id: 'o4-mini',
     maxOutput: 100_000,
     pricing: {
-      input: 20,
-      output: 80,
+      cachedInput: 0.275,
+      input: 1.1,
+      output: 4.4,
     },
-    releasedAt: '2025-06-10',
+    releasedAt: '2025-04-17',
     settings: {
       extendParams: ['reasoningEffort'],
+      searchImpl: 'params',
     },
     type: 'chat',
   },
@@ -34,23 +38,24 @@ export const openaiChatModels: AIChatModelCard[] = [
     abilities: {
       functionCall: true,
       reasoning: true,
+      search: true,
       vision: true,
     },
     contextWindowTokens: 200_000,
     description:
-      'o3 是一款全能强大的模型，在多个领域表现出色。它为数学、科学、编程和视觉推理任务树立了新标杆。它也擅长技术写作和指令遵循。用户可利用它分析文本、代码和图像，解决多步骤的复杂问题。',
-    displayName: 'o3',
-    enabled: true,
-    id: 'o3',
+      'o4-mini-deep-research 是我们更快速、更实惠的深度研究模型——非常适合处理复杂的多步骤研究任务。它可以从互联网上搜索和综合信息，也可以通过 MCP 连接器访问并利用你的自有数据。',
+    displayName: 'o4-mini Deep Research',
+    id: 'o4-mini-deep-research',
     maxOutput: 100_000,
     pricing: {
       cachedInput: 0.5,
       input: 2,
       output: 8,
     },
-    releasedAt: '2025-04-16',
+    releasedAt: '2025-06-26',
     settings: {
       extendParams: ['reasoningEffort'],
+      searchImpl: 'params',
     },
     type: 'chat',
   },
@@ -58,45 +63,48 @@ export const openaiChatModels: AIChatModelCard[] = [
     abilities: {
       functionCall: true,
       reasoning: true,
+      search: true,
       vision: true,
     },
     contextWindowTokens: 200_000,
     description:
-      'o4-mini 是我们最新的小型 o 系列模型。 它专为快速有效的推理而优化，在编码和视觉任务中表现出极高的效率和性能。',
-    displayName: 'o4-mini',
-    enabled: true,
-    id: 'o4-mini',
+      'o3-pro 模型使用更多的计算来更深入地思考并始终提供更好的答案，仅支持 Responses API 下使用。',
+    displayName: 'o3-pro',
+    id: 'o3-pro',
     maxOutput: 100_000,
     pricing: {
-      cachedInput: 0.275,
-      input: 1.1,
-      output: 4.4,
+      input: 20,
+      output: 80,
     },
-    releasedAt: '2025-04-17',
+    releasedAt: '2025-06-10',
     settings: {
       extendParams: ['reasoningEffort'],
+      searchImpl: 'params',
     },
     type: 'chat',
   },
   {
     abilities: {
       functionCall: true,
+      reasoning: true,
       search: true,
       vision: true,
     },
-    contextWindowTokens: 1_047_576,
-    description: 'GPT-4.1 是我们用于复杂任务的旗舰模型。它非常适合跨领域解决问题。',
-    displayName: 'GPT-4.1',
+    contextWindowTokens: 200_000,
+    description:
+      'o3 是一款全能强大的模型，在多个领域表现出色。它为数学、科学、编程和视觉推理任务树立了新标杆。它也擅长技术写作和指令遵循。用户可利用它分析文本、代码和图像，解决多步骤的复杂问题。',
+    displayName: 'o3',
     enabled: true,
-    id: 'gpt-4.1',
-    maxOutput: 32_768,
+    id: 'o3',
+    maxOutput: 100_000,
     pricing: {
       cachedInput: 0.5,
       input: 2,
       output: 8,
     },
-    releasedAt: '2025-04-14',
+    releasedAt: '2025-04-16',
     settings: {
+      extendParams: ['reasoningEffort'],
       searchImpl: 'params',
     },
     type: 'chat',
@@ -104,45 +112,28 @@ export const openaiChatModels: AIChatModelCard[] = [
   {
     abilities: {
       functionCall: true,
+      reasoning: true,
       search: true,
       vision: true,
     },
-    contextWindowTokens: 1_047_576,
+    contextWindowTokens: 200_000,
     description:
-      'GPT-4.1 mini 提供了智能、速度和成本之间的平衡，使其成为许多用例中有吸引力的模型。',
-    displayName: 'GPT-4.1 mini',
-    enabled: true,
-    id: 'gpt-4.1-mini',
-    maxOutput: 32_768,
+      'o3-deep-research 是我们最先进的深度研究模型，专为处理复杂的多步骤研究任务而设计。它可以从互联网上搜索和综合信息，也可以通过 MCP 连接器访问并利用你的自有数据。',
+    displayName: 'o3 Deep Research',
+    id: 'o3-deep-research',
+    maxOutput: 100_000,
     pricing: {
-      cachedInput: 0.1,
-      input: 0.4,
-      output: 1.6,
+      cachedInput: 2.5,
+      input: 10,
+      output: 40,
     },
-    releasedAt: '2025-04-14',
+    releasedAt: '2025-06-26',
     settings: {
+      extendParams: ['reasoningEffort'],
       searchImpl: 'params',
     },
     type: 'chat',
   },
-  {
-    abilities: {
-      functionCall: true,
-      vision: true,
-    },
-    contextWindowTokens: 1_047_576,
-    description: 'GPT-4.1 nano 是最快，最具成本效益的GPT-4.1模型。',
-    displayName: 'GPT-4.1 nano',
-    id: 'gpt-4.1-nano',
-    maxOutput: 32_768,
-    pricing: {
-      cachedInput: 0.025,
-      input: 0.1,
-      output: 0.4,
-    },
-    releasedAt: '2025-04-14',
-    type: 'chat',
-  },
   {
     abilities: {
       functionCall: true,
@@ -251,6 +242,71 @@ export const openaiChatModels: AIChatModelCard[] = [
     },
     type: 'chat',
   },
+  {
+    abilities: {
+      functionCall: true,
+      search: true,
+      vision: true,
+    },
+    contextWindowTokens: 1_047_576,
+    description: 'GPT-4.1 是我们用于复杂任务的旗舰模型。它非常适合跨领域解决问题。',
+    displayName: 'GPT-4.1',
+    enabled: true,
+    id: 'gpt-4.1',
+    maxOutput: 32_768,
+    pricing: {
+      cachedInput: 0.5,
+      input: 2,
+      output: 8,
+    },
+    releasedAt: '2025-04-14',
+    settings: {
+      searchImpl: 'params',
+    },
+    type: 'chat',
+  },
+  {
+    abilities: {
+      functionCall: true,
+      search: true,
+      vision: true,
+    },
+    contextWindowTokens: 1_047_576,
+    description:
+      'GPT-4.1 mini 提供了智能、速度和成本之间的平衡，使其成为许多用例中有吸引力的模型。',
+    displayName: 'GPT-4.1 mini',
+    enabled: true,
+    id: 'gpt-4.1-mini',
+    maxOutput: 32_768,
+    pricing: {
+      cachedInput: 0.1,
+      input: 0.4,
+      output: 1.6,
+    },
+    releasedAt: '2025-04-14',
+    settings: {
+      searchImpl: 'params',
+    },
+    type: 'chat',
+  },
+  {
+    abilities: {
+      functionCall: true,
+      vision: true,
+    },
+    contextWindowTokens: 1_047_576,
+    description: 'GPT-4.1 nano 是最快，最具成本效益的GPT-4.1模型。',
+    displayName: 'GPT-4.1 nano',
+    id: 'gpt-4.1-nano',
+    maxOutput: 32_768,
+    pricing: {
+      cachedInput: 0.025,
+      input: 0.1,
+      output: 0.4,
+    },
+    releasedAt: '2025-04-14',
+    type: 'chat',
+  },
   {
     abilities: {
       functionCall: true,
diff --git a/src/const/models.ts b/src/const/models.ts
index af72e810abb51..6d5773cf8e052 100644
--- a/src/const/models.ts
+++ b/src/const/models.ts
@@ -26,8 +26,12 @@ export const disableStreamModels = new Set([
 export const responsesAPIModels = new Set([
   'o1-pro',
   'o1-pro-2025-03-19',
+  'o3-deep-research',
+  'o3-deep-research-2025-06-26',
   'o3-pro',
   'o3-pro-2025-06-10',
+  'o4-mini-deep-research',
+  'o4-mini-deep-research-2025-06-26',
   'codex-mini-latest',
   'computer-use-preview',
   'computer-use-preview-2025-03-11',
diff --git a/src/libs/model-runtime/openai/index.ts b/src/libs/model-runtime/openai/index.ts
index 24de11f86eb76..946054ec3f6be 100644
--- a/src/libs/model-runtime/openai/index.ts
+++ b/src/libs/model-runtime/openai/index.ts
@@ -76,18 +76,17 @@ export const LobeOpenAI = createOpenAICompatibleRuntime({
         : tools;
 
       if (prunePrefixes.some((prefix) => model.startsWith(prefix))) {
-        if (!payload.reasoning) {
-          payload.reasoning = { summary: 'auto' };
-        } else {
-          payload.reasoning.summary = 'auto';
-        }
-
-        // computer-use series must set truncation as auto
-        if (model.startsWith('computer-use')) {
-          payload.truncation = 'auto';
-        }
-
-        return pruneReasoningPayload(payload) as any;
+        return pruneReasoningPayload({
+          ...rest,
+          model,
+          reasoning: payload.reasoning ? 
+            { ...payload.reasoning, summary: 'auto' } : 
+            { summary: 'auto' },
+          stream: payload.stream ?? true,
+          tools: openaiTools as any,
+          // computer-use series must set truncation as auto
+          ...(model.startsWith('computer-use') && { truncation: 'auto' }),
+        }) as any;
       }
 
       return { ...rest, model, stream: payload.stream ?? true, tools: openaiTools } as any;
