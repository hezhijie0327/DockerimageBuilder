diff --git a/src/config/modelProviders/perplexity.ts b/src/config/modelProviders/perplexity.ts
index d4403f407f89..aac0528decf4 100644
--- a/src/config/modelProviders/perplexity.ts
+++ b/src/config/modelProviders/perplexity.ts
@@ -5,43 +5,40 @@ const Perplexity: ModelProviderCard = {
   chatModels: [
     {
       displayName: 'Perplexity 8B Chat',
-      id: 'llama-3-sonar-small-32k-chat',
-      tokens: 32_768,
+      enabled: true,
+      id: 'llama-3.1-sonar-small-128k-chat',
+      tokens: 128_000,
     },
     {
       displayName: 'Perplexity 70B Chat',
       enabled: true,
-      id: 'llama-3-sonar-large-32k-chat',
-      tokens: 32_768,
+      id: 'llama-3.1-sonar-large-128k-chat',
+      tokens: 128_000,
     },
     {
       displayName: 'Perplexity 8B Online',
-      id: 'llama-3-sonar-small-32k-online',
-      tokens: 28_000,
+      enabled: true,
+      id: 'llama-3.1-sonar-small-128k-online',
+      tokens: 128_000,
     },
     {
       displayName: 'Perplexity 70B Online',
       enabled: true,
-      id: 'llama-3-sonar-large-32k-online',
-      tokens: 28_000,
-    },
-    {
-      displayName: 'Llama3 8B Instruct',
-      id: 'llama-3-8b-instruct',
-      tokens: 8192,
+      id: 'llama-3.1-sonar-large-128k-online',
+      tokens: 128_000,
     },
     {
-      displayName: 'Llama3 70B Instruct',
-      id: 'llama-3-70b-instruct',
-      tokens: 8192,
+      displayName: 'Llama3.1 8B Instruct',
+      id: 'llama-3.1-8b-instruct',
+      tokens: 128_000,
     },
     {
-      displayName: 'Mixtral 8x7B Instruct',
-      id: 'mixtral-8x7b-instruct',
-      tokens: 16_384,
+      displayName: 'Llama3.1 70B Instruct',
+      id: 'llama-3.1-70b-instruct',
+      tokens: 128_000,
     },
   ],
-  checkModel: 'llama-3-8b-instruct',
+  checkModel: 'llama-3.1-8b-instruct',
   id: 'perplexity',
   name: 'Perplexity',
   proxyUrl: {
