diff --git a/locales/ar/modelProvider.json b/locales/ar/modelProvider.json
index a3e2e99160a1..179d3f6cc386 100644
--- a/locales/ar/modelProvider.json
+++ b/locales/ar/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "Download specified Ollama model"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "أدخل معرف مفتاح الوصول لـ SenseNova",
+      "placeholder": "معرف مفتاح الوصول لـ SenseNova",
+      "title": "معرف مفتاح الوصول"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "أدخل سر مفتاح الوصول لـ SenseNova",
+      "placeholder": "سر مفتاح الوصول لـ SenseNova",
+      "title": "سر مفتاح الوصول"
+    },
+    "unlock": {
+      "description": "أدخل معرف مفتاح الوصول / سر مفتاح الوصول لبدء الجلسة. التطبيق لن يسجل إعدادات المصادقة الخاصة بك",
+      "title": "استخدم معلومات مصادقة SenseNova المخصصة"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "أدخل مفتاح الوصول من منصة بايدو تشيانفان",
diff --git a/locales/ar/models.json b/locales/ar/models.json
index 3ceef276748e..bcb13204851f 100644
--- a/locales/ar/models.json
+++ b/locales/ar/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math يركز على حل المشكلات في مجال الرياضيات، ويقدم إجابات احترافية للأسئلة الصعبة."
   },
+  "SenseChat": {
+    "description": "نموذج الإصدار الأساسي (V4)، بطول سياق 4K، يمتلك قدرات قوية وعامة."
+  },
+  "SenseChat-128K": {
+    "description": "نموذج الإصدار الأساسي (V4)، بطول سياق 128K، يتفوق في مهام فهم وتوليد النصوص الطويلة."
+  },
+  "SenseChat-32K": {
+    "description": "نموذج الإصدار الأساسي (V4)، بطول سياق 32K، يمكن استخدامه بمرونة في مختلف السيناريوهات."
+  },
+  "SenseChat-5": {
+    "description": "أحدث إصدار من النموذج (V5.5)، بطول سياق 128K، مع تحسينات ملحوظة في القدرة على الاستدلال الرياضي، المحادثات باللغة الإنجليزية، اتباع التعليمات وفهم النصوص الطويلة، مما يجعله في مستوى GPT-4o."
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "بطول سياق 32K، يتفوق في فهم المحادثات باللغة الكانتونية مقارنة بـ GPT-4، ويضاهي GPT-4 Turbo في مجالات المعرفة، الاستدلال، الرياضيات وكتابة الأكواد."
+  },
+  "SenseChat-Character": {
+    "description": "نموذج النسخة القياسية، بطول سياق 8K، بسرعة استجابة عالية."
+  },
+  "SenseChat-Character-Pro": {
+    "description": "نموذج النسخة المتقدمة، بطول سياق 32K، مع تحسين شامل في القدرات، يدعم المحادثات باللغة الصينية والإنجليزية."
+  },
+  "SenseChat-Turbo": {
+    "description": "مناسب للأسئلة السريعة، وسيناريوهات ضبط النموذج."
+  },
+  "SenseChat-Vision": {
+    "description": "أحدث إصدار من النموذج (V5.5)، بطول سياق 16K، يدعم إدخال صور متعددة، ويحقق تحسينات شاملة في القدرات الأساسية للنموذج، مع تحسينات كبيرة في التعرف على خصائص الكائنات، العلاقات المكانية، التعرف على أحداث الحركة، فهم المشاهد، التعرف على المشاعر، الاستدلال المنطقي وفهم النصوص وتوليدها."
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B هو إصدار مفتوح المصدر، يوفر تجربة حوار محسنة لتطبيقات الحوار."
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "نموذج Llama 3.1 Sonar Small Online، يتمتع بـ 8B من المعلمات، يدعم طول سياق حوالي 127,000 علامة، مصمم للدردشة عبر الإنترنت، قادر على معالجة تفاعلات نصية متنوعة بكفاءة."
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2 مصمم للتعامل مع المهام التي تجمع بين البيانات البصرية والنصية. إنه يتفوق في مهام وصف الصور والأسئلة البصرية، متجاوزًا الفجوة بين توليد اللغة والاستدلال البصري."
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2 مصمم للتعامل مع المهام التي تجمع بين البيانات البصرية والنصية. إنه يتفوق في مهام وصف الصور والأسئلة البصرية، متجاوزًا الفجوة بين توليد اللغة والاستدلال البصري."
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B يوفر قدرة معالجة معقدة لا مثيل لها، مصمم خصيصًا للمشاريع ذات المتطلبات العالية."
   },
diff --git a/locales/ar/providers.json b/locales/ar/providers.json
index 9056bb75dc32..fcc87d291f03 100644
--- a/locales/ar/providers.json
+++ b/locales/ar/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "Qwen هو نموذج لغة ضخم تم تطويره ذاتيًا بواسطة Alibaba Cloud، يتمتع بقدرات قوية في فهم وتوليد اللغة الطبيعية. يمكنه الإجابة على مجموعة متنوعة من الأسئلة، وكتابة المحتوى، والتعبير عن الآراء، وكتابة الشيفرات، ويؤدي دورًا في مجالات متعددة."
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "تسعى SiliconFlow إلى تسريع الذكاء الاصطناعي العام (AGI) لفائدة البشرية، من خلال تحسين كفاءة الذكاء الاصطناعي على نطاق واسع باستخدام حزمة GenAI سهلة الاستخدام وذات التكلفة المنخفضة."
   },
diff --git a/locales/bg-BG/modelProvider.json b/locales/bg-BG/modelProvider.json
index 016ee1d8f87c..187b58893ea6 100644
--- a/locales/bg-BG/modelProvider.json
+++ b/locales/bg-BG/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "Download specified Ollama model"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "Въведете SenseNova Access Key ID",
+      "placeholder": "SenseNova Access Key ID",
+      "title": "Access Key ID"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "Въведете SenseNova Access Key Secret",
+      "placeholder": "SenseNova Access Key Secret",
+      "title": "Access Key Secret"
+    },
+    "unlock": {
+      "description": "Въведете вашия Access Key ID / Access Key Secret, за да започнете сесия. Приложението няма да записва вашите конфигурации за удостоверяване",
+      "title": "Използвайте персонализирана информация за удостоверяване на SenseNova"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "Въведете Access Key от платформата Baidu Qianfan",
diff --git a/locales/bg-BG/models.json b/locales/bg-BG/models.json
index 40d63f23f236..af38a7c6bd5f 100644
--- a/locales/bg-BG/models.json
+++ b/locales/bg-BG/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math се фокусира върху решаването на математически проблеми, предоставяйки професионални отговори на трудни задачи."
   },
+  "SenseChat": {
+    "description": "Основна версия на модела (V4), с контекстна дължина 4K, с мощни общи способности."
+  },
+  "SenseChat-128K": {
+    "description": "Основна версия на модела (V4), с контекстна дължина 128K, показваща отлични резултати в задачи за разбиране и генериране на дълги текстове."
+  },
+  "SenseChat-32K": {
+    "description": "Основна версия на модела (V4), с контекстна дължина 32K, гъвкаво приложима в различни сцени."
+  },
+  "SenseChat-5": {
+    "description": "Най-новата версия на модела (V5.5), с контекстна дължина 128K, значително подобрена способност в области като математическо разсъждение, английски разговори, следване на инструкции и разбиране на дълги текстове, сравнима с GPT-4o."
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "С контекстна дължина 32K, надминава GPT-4 в разбирането на разговори на кантонски, сравним с GPT-4 Turbo в множество области като знания, разсъждение, математика и писане на код."
+  },
+  "SenseChat-Character": {
+    "description": "Стандартна версия на модела, с контекстна дължина 8K, с висока скорост на отговор."
+  },
+  "SenseChat-Character-Pro": {
+    "description": "Премиум версия на модела, с контекстна дължина 32K, с напълно подобрени способности, поддържаща разговори на китайски/английски."
+  },
+  "SenseChat-Turbo": {
+    "description": "Подходящ за бързи въпроси и отговори, сцени на фино настройване на модела."
+  },
+  "SenseChat-Vision": {
+    "description": "Най-новата версия на модела (V5.5), с контекстна дължина 16K, поддържа вход с множество изображения, напълно реализирана оптимизация на основните способности на модела, с голямо подобрение в разпознаването на свойства на обекти, пространствени отношения, разпознаване на действия, разбиране на сцени, разпознаване на емоции, логическо разсъждение и генериране на текст."
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B е отворен код версия, предоставяща оптимизирано изживяване в разговорните приложения."
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "Llama 3.1 Sonar Small Online модел, с 8B параметри, поддържащ контекстова дължина от около 127,000 маркера, проектиран за онлайн чат, способен да обработва ефективно различни текстови взаимодействия."
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2 е проектиран да обработва задачи, свързани с визуални и текстови данни. Той показва отлични резултати в задачи като описание на изображения и визуални въпроси и отговори, преодолявайки пропастта между генерирането на език и визуалното разсъждение."
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2 е проектиран да обработва задачи, свързани с визуални и текстови данни. Той показва отлични резултати в задачи като описание на изображения и визуални въпроси и отговори, преодолявайки пропастта между генерирането на език и визуалното разсъждение."
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B предлага ненадмината способност за обработка на сложност, проектирана за високи изисквания."
   },
diff --git a/locales/bg-BG/providers.json b/locales/bg-BG/providers.json
index 4a0cb9a6f9ad..2367df98ac41 100644
--- a/locales/bg-BG/providers.json
+++ b/locales/bg-BG/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "Qwen е самостоятелно разработен свръхголям езиков модел на Alibaba Cloud, с мощни способности за разбиране и генериране на естествен език. Може да отговаря на различни въпроси, да създава текстово съдържание, да изразява мнения и да пише код, играейки роля в множество области."
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlow се стреми да ускори AGI, за да бъде от полза за човечеството, повишавайки ефективността на мащабния AI чрез лесен за използване и икономически изгоден GenAI стек."
   },
diff --git a/locales/de-DE/modelProvider.json b/locales/de-DE/modelProvider.json
index 1f08a362b0df..3031768ff830 100644
--- a/locales/de-DE/modelProvider.json
+++ b/locales/de-DE/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "Download specified Ollama model"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "Geben Sie die SenseNova Access Key ID ein",
+      "placeholder": "SenseNova Access Key ID",
+      "title": "Access Key ID"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "Geben Sie den SenseNova Access Key Secret ein",
+      "placeholder": "SenseNova Access Key Secret",
+      "title": "Access Key Secret"
+    },
+    "unlock": {
+      "description": "Geben Sie Ihre Access Key ID / Access Key Secret ein, um die Sitzung zu starten. Die Anwendung speichert Ihre Authentifizierungsinformationen nicht",
+      "title": "Verwenden Sie benutzerdefinierte SenseNova Authentifizierungsinformationen"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "Geben Sie den Access Key der Baidu Qianfan-Plattform ein",
diff --git a/locales/de-DE/models.json b/locales/de-DE/models.json
index 3d3f9a055ced..f117b46dbe7c 100644
--- a/locales/de-DE/models.json
+++ b/locales/de-DE/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math konzentriert sich auf die Problemlösung im Bereich Mathematik und bietet professionelle Lösungen für schwierige Aufgaben."
   },
+  "SenseChat": {
+    "description": "Basisversion des Modells (V4) mit 4K Kontextlänge, die über starke allgemeine Fähigkeiten verfügt."
+  },
+  "SenseChat-128K": {
+    "description": "Basisversion des Modells (V4) mit 128K Kontextlänge, das in Aufgaben des Verständnisses und der Generierung langer Texte hervorragende Leistungen zeigt."
+  },
+  "SenseChat-32K": {
+    "description": "Basisversion des Modells (V4) mit 32K Kontextlänge, flexibel einsetzbar in verschiedenen Szenarien."
+  },
+  "SenseChat-5": {
+    "description": "Die neueste Modellversion (V5.5) mit 128K Kontextlänge hat signifikante Verbesserungen in den Bereichen mathematische Schlussfolgerungen, englische Konversation, Befolgen von Anweisungen und Verständnis langer Texte, vergleichbar mit GPT-4o."
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "Mit 32K Kontextlänge übertrifft es GPT-4 im Verständnis von Konversationen auf Kantonesisch und kann in mehreren Bereichen wie Wissen, Schlussfolgerungen, Mathematik und Programmierung mit GPT-4 Turbo konkurrieren."
+  },
+  "SenseChat-Character": {
+    "description": "Standardmodell mit 8K Kontextlänge und hoher Reaktionsgeschwindigkeit."
+  },
+  "SenseChat-Character-Pro": {
+    "description": "Premium-Modell mit 32K Kontextlänge, das umfassende Verbesserungen in den Fähigkeiten bietet und sowohl chinesische als auch englische Konversationen unterstützt."
+  },
+  "SenseChat-Turbo": {
+    "description": "Geeignet für schnelle Fragen und Antworten sowie Szenarien zur Feinabstimmung des Modells."
+  },
+  "SenseChat-Vision": {
+    "description": "Die neueste Modellversion (V5.5) mit 16K Kontextlänge unterstützt die Eingabe mehrerer Bilder und optimiert umfassend die grundlegenden Fähigkeiten des Modells. Es hat erhebliche Fortschritte in der Erkennung von Objektattributen, räumlichen Beziehungen, Erkennung von Handlungsereignissen, Szenenverständnis, Emotionserkennung, logischem Wissen und Textverständnis und -generierung erzielt."
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B ist die Open-Source-Version, die ein optimiertes Dialogerlebnis für Konversationsanwendungen bietet."
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "Das Llama 3.1 Sonar Small Online-Modell hat 8B Parameter und unterstützt eine Kontextlänge von etwa 127.000 Markierungen, es wurde speziell für Online-Chat entwickelt und kann verschiedene Textinteraktionen effizient verarbeiten."
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2 ist darauf ausgelegt, Aufgaben zu bearbeiten, die visuelle und textuelle Daten kombinieren. Es zeigt hervorragende Leistungen bei Aufgaben wie Bildbeschreibung und visueller Fragebeantwortung und überbrückt die Kluft zwischen Sprachgenerierung und visuellem Schließen."
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2 ist darauf ausgelegt, Aufgaben zu bearbeiten, die visuelle und textuelle Daten kombinieren. Es zeigt hervorragende Leistungen bei Aufgaben wie Bildbeschreibung und visueller Fragebeantwortung und überbrückt die Kluft zwischen Sprachgenerierung und visuellem Schließen."
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B bietet unvergleichliche Fähigkeiten zur Verarbeitung von Komplexität und ist maßgeschneidert für Projekte mit hohen Anforderungen."
   },
diff --git a/locales/de-DE/providers.json b/locales/de-DE/providers.json
index 281219ce9b36..277be41c777c 100644
--- a/locales/de-DE/providers.json
+++ b/locales/de-DE/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "Tongyi Qianwen ist ein von Alibaba Cloud selbst entwickeltes, groß angelegtes Sprachmodell mit starken Fähigkeiten zur Verarbeitung und Generierung natürlicher Sprache. Es kann eine Vielzahl von Fragen beantworten, Texte erstellen, Meinungen äußern und Code schreiben und spielt in mehreren Bereichen eine Rolle."
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlow hat sich zum Ziel gesetzt, AGI zu beschleunigen, um der Menschheit zu dienen, und die Effizienz großangelegter KI durch eine benutzerfreundliche und kostengünstige GenAI-Stack zu steigern."
   },
diff --git a/locales/en-US/modelProvider.json b/locales/en-US/modelProvider.json
index d439754e16b6..6c73e161e14b 100644
--- a/locales/en-US/modelProvider.json
+++ b/locales/en-US/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "Download specified Ollama model"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "Enter your SenseNova Access Key ID",
+      "placeholder": "SenseNova Access Key ID",
+      "title": "Access Key ID"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "Enter your SenseNova Access Key Secret",
+      "placeholder": "SenseNova Access Key Secret",
+      "title": "Access Key Secret"
+    },
+    "unlock": {
+      "description": "Input your Access Key ID / Access Key Secret to start the session. The application will not record your authentication configuration.",
+      "title": "Use Custom SenseNova Authentication Information"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "Enter the Access Key from the Baidu Qianfan platform",
diff --git a/locales/en-US/models.json b/locales/en-US/models.json
index e7413229a300..7ee9e1466703 100644
--- a/locales/en-US/models.json
+++ b/locales/en-US/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math focuses on problem-solving in the field of mathematics, providing expert solutions for challenging problems."
   },
+  "SenseChat": {
+    "description": "Basic version model (V4) with a context length of 4K, featuring strong general capabilities."
+  },
+  "SenseChat-128K": {
+    "description": "Basic version model (V4) with a context length of 128K, excelling in long text comprehension and generation tasks."
+  },
+  "SenseChat-32K": {
+    "description": "Basic version model (V4) with a context length of 32K, flexibly applicable to various scenarios."
+  },
+  "SenseChat-5": {
+    "description": "The latest version model (V5.5) with a context length of 128K shows significant improvements in mathematical reasoning, English conversation, instruction following, and long text comprehension, comparable to GPT-4o."
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "With a context length of 32K, it surpasses GPT-4 in Cantonese conversation comprehension and is competitive with GPT-4 Turbo in knowledge, reasoning, mathematics, and code writing across multiple domains."
+  },
+  "SenseChat-Character": {
+    "description": "Standard version model with an 8K context length and high response speed."
+  },
+  "SenseChat-Character-Pro": {
+    "description": "Advanced version model with a context length of 32K, offering comprehensive capability enhancements and supporting both Chinese and English conversations."
+  },
+  "SenseChat-Turbo": {
+    "description": "Suitable for fast question answering and model fine-tuning scenarios."
+  },
+  "SenseChat-Vision": {
+    "description": "The latest version model (V5.5) with a context length of 16K supports multi-image input and fully optimizes the model's foundational capabilities, achieving substantial improvements in object attribute recognition, spatial relationships, action event recognition, scene understanding, emotion recognition, logical reasoning, and text comprehension and generation."
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B is an open-source version that provides an optimized conversational experience for chat applications."
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "Llama 3.1 Sonar Small Online model, featuring 8B parameters, supports a context length of approximately 127,000 tokens, designed for online chat, efficiently handling various text interactions."
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2 is designed to handle tasks that combine visual and textual data. It excels in tasks such as image description and visual question answering, bridging the gap between language generation and visual reasoning."
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2 is designed to handle tasks that combine visual and textual data. It excels in tasks such as image description and visual question answering, bridging the gap between language generation and visual reasoning."
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B provides unparalleled complexity handling capabilities, tailored for high-demand projects."
   },
diff --git a/locales/en-US/providers.json b/locales/en-US/providers.json
index c411d98cc848..3ca8fe39341f 100644
--- a/locales/en-US/providers.json
+++ b/locales/en-US/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "Tongyi Qianwen is a large-scale language model independently developed by Alibaba Cloud, featuring strong natural language understanding and generation capabilities. It can answer various questions, create written content, express opinions, and write code, playing a role in multiple fields."
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlow is dedicated to accelerating AGI for the benefit of humanity, enhancing large-scale AI efficiency through an easy-to-use and cost-effective GenAI stack."
   },
diff --git a/locales/es-ES/modelProvider.json b/locales/es-ES/modelProvider.json
index 1acf7c6e8cf7..79b7997a2319 100644
--- a/locales/es-ES/modelProvider.json
+++ b/locales/es-ES/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "Download specified Ollama model"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "Introduce el ID de clave de acceso de SenseNova",
+      "placeholder": "ID de clave de acceso de SenseNova",
+      "title": "ID de clave de acceso"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "Introduce la clave secreta de acceso de SenseNova",
+      "placeholder": "Clave secreta de acceso de SenseNova",
+      "title": "Clave secreta de acceso"
+    },
+    "unlock": {
+      "description": "Introduce tu ID de clave de acceso / clave secreta de acceso para comenzar la sesión. La aplicación no registrará tu configuración de autenticación",
+      "title": "Usar información de autenticación personalizada de SenseNova"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "Introduce la Access Key de la plataforma Qianfan de Baidu",
diff --git a/locales/es-ES/models.json b/locales/es-ES/models.json
index a36e65bde9fc..f2ca7ad6cc4a 100644
--- a/locales/es-ES/models.json
+++ b/locales/es-ES/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math se centra en la resolución de problemas en el ámbito de las matemáticas, proporcionando respuestas profesionales a preguntas de alta dificultad."
   },
+  "SenseChat": {
+    "description": "Modelo de versión básica (V4), longitud de contexto de 4K, con potentes capacidades generales."
+  },
+  "SenseChat-128K": {
+    "description": "Modelo de versión básica (V4), longitud de contexto de 128K, se destaca en tareas de comprensión y generación de textos largos."
+  },
+  "SenseChat-32K": {
+    "description": "Modelo de versión básica (V4), longitud de contexto de 32K, aplicable de manera flexible en diversos escenarios."
+  },
+  "SenseChat-5": {
+    "description": "Modelo de última versión (V5.5), longitud de contexto de 128K, con capacidades significativamente mejoradas en razonamiento matemático, diálogos en inglés, seguimiento de instrucciones y comprensión de textos largos, comparable a GPT-4o."
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "Longitud de contexto de 32K, supera a GPT-4 en la comprensión de diálogos en cantonés, siendo comparable a GPT-4 Turbo en múltiples áreas como conocimiento, razonamiento, matemáticas y programación."
+  },
+  "SenseChat-Character": {
+    "description": "Modelo estándar, longitud de contexto de 8K, alta velocidad de respuesta."
+  },
+  "SenseChat-Character-Pro": {
+    "description": "Modelo de versión avanzada, longitud de contexto de 32K, con capacidades completamente mejoradas, admite diálogos en chino/inglés."
+  },
+  "SenseChat-Turbo": {
+    "description": "Adecuado para preguntas rápidas y escenarios de ajuste fino del modelo."
+  },
+  "SenseChat-Vision": {
+    "description": "Modelo de última versión (V5.5), longitud de contexto de 16K, admite entradas de múltiples imágenes, optimizando las capacidades básicas del modelo, logrando mejoras significativas en el reconocimiento de propiedades de objetos, relaciones espaciales, identificación de eventos de acción, comprensión de escenas, reconocimiento de emociones, razonamiento lógico y generación de comprensión de texto."
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B es una versión de código abierto, que proporciona una experiencia de conversación optimizada para aplicaciones de diálogo."
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "El modelo Llama 3.1 Sonar Small Online, con 8B de parámetros, soporta una longitud de contexto de aproximadamente 127,000 tokens, diseñado para chat en línea, capaz de manejar eficientemente diversas interacciones textuales."
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2 está diseñado para abordar tareas que combinan datos visuales y textuales. Se destaca en tareas como la descripción de imágenes y preguntas visuales, superando la brecha entre la generación de lenguaje y el razonamiento visual."
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2 está diseñado para abordar tareas que combinan datos visuales y textuales. Se destaca en tareas como la descripción de imágenes y preguntas visuales, superando la brecha entre la generación de lenguaje y el razonamiento visual."
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B proporciona una capacidad de procesamiento de complejidad inigualable, diseñado a medida para proyectos de alta demanda."
   },
diff --git a/locales/es-ES/providers.json b/locales/es-ES/providers.json
index 3b3a6eadec14..419bcf513278 100644
--- a/locales/es-ES/providers.json
+++ b/locales/es-ES/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "Tongyi Qianwen es un modelo de lenguaje de gran escala desarrollado de forma independiente por Alibaba Cloud, con potentes capacidades de comprensión y generación de lenguaje natural. Puede responder a diversas preguntas, crear contenido escrito, expresar opiniones y redactar código, desempeñando un papel en múltiples campos."
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlow se dedica a acelerar la AGI para beneficiar a la humanidad, mejorando la eficiencia de la IA a gran escala a través de un stack GenAI fácil de usar y de bajo costo."
   },
diff --git a/locales/fr-FR/modelProvider.json b/locales/fr-FR/modelProvider.json
index ad44269740b5..e4253c8f59f0 100644
--- a/locales/fr-FR/modelProvider.json
+++ b/locales/fr-FR/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "Download specified Ollama model"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "Entrez l'ID de clé d'accès SenseNova",
+      "placeholder": "ID de clé d'accès SenseNova",
+      "title": "ID de clé d'accès"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "Entrez le secret de clé d'accès SenseNova",
+      "placeholder": "Secret de clé d'accès SenseNova",
+      "title": "Secret de clé d'accès"
+    },
+    "unlock": {
+      "description": "Entrez votre ID de clé d'accès / secret de clé d'accès pour commencer la session. L'application ne conservera pas vos configurations d'authentification",
+      "title": "Utiliser des informations d'authentification SenseNova personnalisées"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "Entrez la clé d'accès de la plateforme Qianfan de Baidu",
diff --git a/locales/fr-FR/models.json b/locales/fr-FR/models.json
index 6a7d0e2bae9e..288101b59fbd 100644
--- a/locales/fr-FR/models.json
+++ b/locales/fr-FR/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math se concentre sur la résolution de problèmes dans le domaine des mathématiques, fournissant des réponses professionnelles pour des questions de haute difficulté."
   },
+  "SenseChat": {
+    "description": "Modèle de version de base (V4), longueur de contexte de 4K, avec de puissantes capacités générales."
+  },
+  "SenseChat-128K": {
+    "description": "Modèle de version de base (V4), longueur de contexte de 128K, excellent dans les tâches de compréhension et de génération de longs textes."
+  },
+  "SenseChat-32K": {
+    "description": "Modèle de version de base (V4), longueur de contexte de 32K, appliqué de manière flexible à divers scénarios."
+  },
+  "SenseChat-5": {
+    "description": "Modèle de dernière version (V5.5), longueur de contexte de 128K, avec des capacités significativement améliorées dans le raisonnement mathématique, les dialogues en anglais, le suivi d'instructions et la compréhension de longs textes, rivalisant avec GPT-4o."
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "Longueur de contexte de 32K, surpassant GPT-4 dans la compréhension des dialogues en cantonais, rivalisant avec GPT-4 Turbo dans plusieurs domaines tels que les connaissances, le raisonnement, les mathématiques et la rédaction de code."
+  },
+  "SenseChat-Character": {
+    "description": "Modèle standard, longueur de contexte de 8K, avec une grande rapidité de réponse."
+  },
+  "SenseChat-Character-Pro": {
+    "description": "Modèle avancé, longueur de contexte de 32K, avec des capacités globalement améliorées, prenant en charge les dialogues en chinois et en anglais."
+  },
+  "SenseChat-Turbo": {
+    "description": "Conçu pour des questions-réponses rapides et des scénarios de micro-ajustement du modèle."
+  },
+  "SenseChat-Vision": {
+    "description": "Modèle de dernière version (V5.5), longueur de contexte de 16K, prenant en charge l'entrée de plusieurs images, optimisant les capacités fondamentales du modèle, avec des améliorations significatives dans la reconnaissance des attributs d'objets, les relations spatiales, la reconnaissance d'événements d'action, la compréhension de scènes, la reconnaissance des émotions, le raisonnement logique et la génération de texte."
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B est une version open source, offrant une expérience de dialogue optimisée pour les applications de conversation."
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "Le modèle Llama 3.1 Sonar Small Online, avec 8B de paramètres, prend en charge une longueur de contexte d'environ 127 000 jetons, conçu pour le chat en ligne, capable de traiter efficacement diverses interactions textuelles."
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2 est conçu pour traiter des tâches combinant des données visuelles et textuelles. Il excelle dans des tâches telles que la description d'images et les questions-réponses visuelles, comblant le fossé entre la génération de langage et le raisonnement visuel."
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2 est conçu pour traiter des tâches combinant des données visuelles et textuelles. Il excelle dans des tâches telles que la description d'images et les questions-réponses visuelles, comblant le fossé entre la génération de langage et le raisonnement visuel."
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B offre une capacité de traitement de complexité inégalée, sur mesure pour des projets exigeants."
   },
diff --git a/locales/fr-FR/providers.json b/locales/fr-FR/providers.json
index 138390323326..e13f54b10cf1 100644
--- a/locales/fr-FR/providers.json
+++ b/locales/fr-FR/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "Tongyi Qianwen est un modèle de langage à grande échelle développé de manière autonome par Alibaba Cloud, doté de puissantes capacités de compréhension et de génération du langage naturel. Il peut répondre à diverses questions, créer du contenu écrit, exprimer des opinions, rédiger du code, etc., jouant un rôle dans plusieurs domaines."
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlow s'engage à accélérer l'AGI pour le bénéfice de l'humanité, en améliorant l'efficacité de l'IA à grande échelle grâce à une pile GenAI facile à utiliser et à faible coût."
   },
diff --git a/locales/it-IT/modelProvider.json b/locales/it-IT/modelProvider.json
index 2d6b6ab766f8..69878d7c466c 100644
--- a/locales/it-IT/modelProvider.json
+++ b/locales/it-IT/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "Scarica il modello Ollama specificato"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "Inserisci l'ID chiave di accesso SenseNova",
+      "placeholder": "ID chiave di accesso SenseNova",
+      "title": "ID chiave di accesso"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "Inserisci il segreto della chiave di accesso SenseNova",
+      "placeholder": "Segreto della chiave di accesso SenseNova",
+      "title": "Segreto della chiave di accesso"
+    },
+    "unlock": {
+      "description": "Inserisci il tuo ID chiave di accesso / segreto della chiave di accesso per iniziare la sessione. L'app non registrerà la tua configurazione di autenticazione",
+      "title": "Utilizza informazioni di autenticazione personalizzate di SenseNova"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "Inserisci l'Access Key della piattaforma Qianfan di Baidu",
diff --git a/locales/it-IT/models.json b/locales/it-IT/models.json
index e2dea3a2d34a..e09ccdb947ab 100644
--- a/locales/it-IT/models.json
+++ b/locales/it-IT/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math si concentra sulla risoluzione di problemi nel campo della matematica, fornendo risposte professionali a domande di alta difficoltà."
   },
+  "SenseChat": {
+    "description": "Modello di base (V4), lunghezza del contesto di 4K, con potenti capacità generali."
+  },
+  "SenseChat-128K": {
+    "description": "Modello di base (V4), lunghezza del contesto di 128K, si distingue in compiti di comprensione e generazione di testi lunghi."
+  },
+  "SenseChat-32K": {
+    "description": "Modello di base (V4), lunghezza del contesto di 32K, applicabile in vari scenari."
+  },
+  "SenseChat-5": {
+    "description": "Modello dell'ultima versione (V5.5), lunghezza del contesto di 128K, con capacità significativamente migliorate in ragionamento matematico, conversazioni in inglese, seguire istruzioni e comprensione di testi lunghi, paragonabile a GPT-4o."
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "Lunghezza del contesto di 32K, supera GPT-4 nella comprensione delle conversazioni in cantonese, paragonabile a GPT-4 Turbo in vari ambiti come conoscenza, ragionamento, matematica e scrittura di codice."
+  },
+  "SenseChat-Character": {
+    "description": "Modello standard, lunghezza del contesto di 8K, alta velocità di risposta."
+  },
+  "SenseChat-Character-Pro": {
+    "description": "Modello avanzato, lunghezza del contesto di 32K, capacità complessivamente migliorate, supporta conversazioni in cinese/inglese."
+  },
+  "SenseChat-Turbo": {
+    "description": "Adatto per domande e risposte rapide, scenari di micro-ottimizzazione del modello."
+  },
+  "SenseChat-Vision": {
+    "description": "Modello dell'ultima versione (V5.5), lunghezza del contesto di 16K, supporta input multipli di immagini, ottimizzazione completa delle capacità di base del modello, con notevoli miglioramenti nel riconoscimento delle proprietà degli oggetti, relazioni spaziali, riconoscimento di eventi, comprensione delle scene, riconoscimento delle emozioni, ragionamento logico e generazione di testi."
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B è una versione open source, progettata per fornire un'esperienza di dialogo ottimizzata per applicazioni conversazionali."
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "Il modello Llama 3.1 Sonar Small Online, con 8B parametri, supporta una lunghezza di contesto di circa 127.000 token, progettato per chat online, in grado di gestire interazioni testuali in modo efficiente."
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2 è progettato per gestire compiti che combinano dati visivi e testuali. Si distingue in compiti come la descrizione delle immagini e il question answering visivo, colmando il divario tra generazione del linguaggio e ragionamento visivo."
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2 è progettato per gestire compiti che combinano dati visivi e testuali. Si distingue in compiti come la descrizione delle immagini e il question answering visivo, colmando il divario tra generazione del linguaggio e ragionamento visivo."
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B offre capacità di elaborazione della complessità senza pari, progettato su misura per progetti ad alta richiesta."
   },
diff --git a/locales/it-IT/providers.json b/locales/it-IT/providers.json
index f69216637d88..6a627374e99c 100644
--- a/locales/it-IT/providers.json
+++ b/locales/it-IT/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "Qwen è un modello di linguaggio di grande scala sviluppato autonomamente da Alibaba Cloud, con potenti capacità di comprensione e generazione del linguaggio naturale. Può rispondere a varie domande, creare contenuti testuali, esprimere opinioni e scrivere codice, svolgendo un ruolo in vari settori."
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlow si impegna ad accelerare l'AGI per il bene dell'umanità, migliorando l'efficienza dell'AI su larga scala attraverso stack GenAI facili da usare e a basso costo."
   },
diff --git a/locales/ja-JP/modelProvider.json b/locales/ja-JP/modelProvider.json
index d16ea0f745e5..7f70566db495 100644
--- a/locales/ja-JP/modelProvider.json
+++ b/locales/ja-JP/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "Download specified Ollama model"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "SenseNova アクセスキー ID を入力してください",
+      "placeholder": "SenseNova アクセスキー ID",
+      "title": "アクセスキー ID"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "SenseNova アクセスキーシークレットを入力してください",
+      "placeholder": "SenseNova アクセスキーシークレット",
+      "title": "アクセスキーシークレット"
+    },
+    "unlock": {
+      "description": "あなたのアクセスキー ID / アクセスキーシークレットを入力すると、セッションが開始されます。アプリはあなたの認証設定を記録しません",
+      "title": "カスタム SenseNova 認証情報を使用"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "百度千帆プラットフォームのAccess Keyを入力してください",
diff --git a/locales/ja-JP/models.json b/locales/ja-JP/models.json
index 5e12cff10e47..fb959cf127c0 100644
--- a/locales/ja-JP/models.json
+++ b/locales/ja-JP/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Mathは、数学分野の問題解決に特化しており、高難度の問題に対して専門的な解答を提供します。"
   },
+  "SenseChat": {
+    "description": "基本バージョンのモデル (V4)、4Kのコンテキスト長で、汎用能力が強力です。"
+  },
+  "SenseChat-128K": {
+    "description": "基本バージョンのモデル (V4)、128Kのコンテキスト長で、長文理解や生成などのタスクで優れたパフォーマンスを発揮します。"
+  },
+  "SenseChat-32K": {
+    "description": "基本バージョンのモデル (V4)、32Kのコンテキスト長で、さまざまなシーンに柔軟に適用できます。"
+  },
+  "SenseChat-5": {
+    "description": "最新バージョンのモデル (V5.5)、128Kのコンテキスト長で、数学的推論、英語の対話、指示のフォロー、長文理解などの分野での能力が大幅に向上し、GPT-4oに匹敵します。"
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "32Kのコンテキスト長で、広東語の対話理解においてGPT-4を超え、知識、推論、数学、コード作成などの複数の分野でGPT-4 Turboに匹敵します。"
+  },
+  "SenseChat-Character": {
+    "description": "スタンダード版モデル、8Kのコンテキスト長で、高速な応答速度を持っています。"
+  },
+  "SenseChat-Character-Pro": {
+    "description": "ハイエンド版モデル、32Kのコンテキスト長で、能力が全面的に向上し、中国語/英語の対話をサポートしています。"
+  },
+  "SenseChat-Turbo": {
+    "description": "迅速な質問応答やモデルの微調整シーンに適しています。"
+  },
+  "SenseChat-Vision": {
+    "description": "最新バージョンのモデル (V5.5)、16Kのコンテキスト長で、複数の画像入力をサポートし、モデルの基本能力を全面的に最適化しています。物体の属性認識、空間関係、動作イベントの認識、シーン理解、感情認識、論理的常識推論、テキスト理解生成において大幅な向上を実現しました。"
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9Bはオープンソース版で、会話アプリケーションに最適化された対話体験を提供します。"
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "Llama 3.1 Sonar Small Onlineモデルは、8Bパラメータを持ち、約127,000トークンのコンテキスト長をサポートし、オンラインチャット用に設計されており、さまざまなテキストインタラクションを効率的に処理できます。"
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2は、視覚データとテキストデータを組み合わせたタスクを処理することを目的としています。画像の説明や視覚的質問応答などのタスクで優れたパフォーマンスを発揮し、言語生成と視覚的推論の間のギャップを埋めています。"
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2は、視覚データとテキストデータを組み合わせたタスクを処理することを目的としています。画像の説明や視覚的質問応答などのタスクで優れたパフォーマンスを発揮し、言語生成と視覚的推論の間のギャップを埋めています。"
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70Bは、比類のない複雑性処理能力を提供し、高要求プロジェクトに特化しています。"
   },
diff --git a/locales/ja-JP/providers.json b/locales/ja-JP/providers.json
index 9d915f1c9392..e9888dfcea66 100644
--- a/locales/ja-JP/providers.json
+++ b/locales/ja-JP/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "通義千問は、アリババクラウドが独自に開発した超大規模言語モデルであり、強力な自然言語理解と生成能力を持っています。さまざまな質問に答えたり、文章を創作したり、意見を表現したり、コードを執筆したりすることができ、さまざまな分野で活躍しています。"
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlowは、AGIを加速させ、人類に利益をもたらすことを目指し、使いやすくコスト効率の高いGenAIスタックを通じて大規模AIの効率を向上させることに取り組んでいます。"
   },
diff --git a/locales/ko-KR/modelProvider.json b/locales/ko-KR/modelProvider.json
index 5d0375f9ea20..f45c97bb782a 100644
--- a/locales/ko-KR/modelProvider.json
+++ b/locales/ko-KR/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "Download specified Ollama model"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "SenseNova Access Key ID를 입력하세요",
+      "placeholder": "SenseNova Access Key ID",
+      "title": "Access Key ID"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "SenseNova Access Key Secret를 입력하세요",
+      "placeholder": "SenseNova Access Key Secret",
+      "title": "Access Key Secret"
+    },
+    "unlock": {
+      "description": "Access Key ID / Access Key Secret를 입력하면 대화를 시작할 수 있습니다. 애플리케이션은 인증 구성을 기록하지 않습니다.",
+      "title": "사용자 정의 SenseNova 인증 정보 사용"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "바이두 천범 플랫폼의 Access Key를 입력하세요",
diff --git a/locales/ko-KR/models.json b/locales/ko-KR/models.json
index d455f39cc7ad..9e9028f8f0a1 100644
--- a/locales/ko-KR/models.json
+++ b/locales/ko-KR/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math는 수학 분야의 문제 해결에 중점을 두고 있으며, 고난이도 문제에 대한 전문적인 해답을 제공합니다."
   },
+  "SenseChat": {
+    "description": "기본 버전 모델(V4), 4K 컨텍스트 길이, 일반적인 능력이 강력합니다."
+  },
+  "SenseChat-128K": {
+    "description": "기본 버전 모델(V4), 128K 컨텍스트 길이, 긴 텍스트 이해 및 생성 작업에서 뛰어난 성능을 발휘합니다."
+  },
+  "SenseChat-32K": {
+    "description": "기본 버전 모델(V4), 32K 컨텍스트 길이, 다양한 시나리오에 유연하게 적용됩니다."
+  },
+  "SenseChat-5": {
+    "description": "최신 버전 모델(V5.5), 128K 컨텍스트 길이, 수학적 추론, 영어 대화, 지시 따르기 및 긴 텍스트 이해 등 분야에서 능력이 크게 향상되어 GPT-4o와 견줄 수 있습니다."
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "32K 컨텍스트 길이, 광둥어 대화 이해에서 GPT-4를 초월하며, 지식, 추론, 수학 및 코드 작성 등 여러 분야에서 GPT-4 Turbo와 견줄 수 있습니다."
+  },
+  "SenseChat-Character": {
+    "description": "표준 버전 모델, 8K 컨텍스트 길이, 높은 응답 속도를 자랑합니다."
+  },
+  "SenseChat-Character-Pro": {
+    "description": "고급 버전 모델, 32K 컨텍스트 길이, 능력이 전반적으로 향상되었으며, 중/영어 대화를 지원합니다."
+  },
+  "SenseChat-Turbo": {
+    "description": "빠른 질문 응답 및 모델 미세 조정 시나리오에 적합합니다."
+  },
+  "SenseChat-Vision": {
+    "description": "최신 버전 모델(V5.5), 16K 컨텍스트 길이, 다중 이미지 입력을 지원하며, 모델의 기본 능력 최적화를 전면적으로 구현하여 객체 속성 인식, 공간 관계, 동작 사건 인식, 장면 이해, 감정 인식, 논리 상식 추론 및 텍스트 이해 생성에서 큰 향상을 이루었습니다."
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B 오픈 소스 버전으로, 대화 응용을 위한 최적화된 대화 경험을 제공합니다."
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "Llama 3.1 Sonar Small Online 모델은 8B 매개변수를 갖추고 있으며, 약 127,000개의 토큰의 컨텍스트 길이를 지원하여 온라인 채팅을 위해 설계되었습니다."
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2는 시각 및 텍스트 데이터를 결합한 작업을 처리하기 위해 설계되었습니다. 이미지 설명 및 시각적 질문 응답과 같은 작업에서 뛰어난 성능을 발휘하며, 언어 생성과 시각적 추론 간의 간극을 메웁니다."
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2는 시각 및 텍스트 데이터를 결합한 작업을 처리하기 위해 설계되었습니다. 이미지 설명 및 시각적 질문 응답과 같은 작업에서 뛰어난 성능을 발휘하며, 언어 생성과 시각적 추론 간의 간극을 메웁니다."
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B는 비할 데 없는 복잡성 처리 능력을 제공하며, 높은 요구 사항을 가진 프로젝트에 맞춤형으로 설계되었습니다."
   },
diff --git a/locales/ko-KR/providers.json b/locales/ko-KR/providers.json
index ac97baeb67da..e0ed6cc34b1f 100644
--- a/locales/ko-KR/providers.json
+++ b/locales/ko-KR/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "통의천문은 알리바바 클라우드가 자주 개발한 초대형 언어 모델로, 강력한 자연어 이해 및 생성 능력을 갖추고 있습니다. 다양한 질문에 답변하고, 텍스트 콘텐츠를 창작하며, 의견을 표현하고, 코드를 작성하는 등 여러 분야에서 활용됩니다."
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlow는 AGI를 가속화하여 인류에 혜택을 주기 위해 사용하기 쉽고 비용이 저렴한 GenAI 스택을 통해 대규모 AI 효율성을 향상시키는 데 전념하고 있습니다."
   },
diff --git a/locales/nl-NL/modelProvider.json b/locales/nl-NL/modelProvider.json
index dcfb00abb34d..37bdbbcdef99 100644
--- a/locales/nl-NL/modelProvider.json
+++ b/locales/nl-NL/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "Download specified Ollama model"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "Vul je SenseNova Access Key ID in",
+      "placeholder": "SenseNova Access Key ID",
+      "title": "Access Key ID"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "Vul je SenseNova Access Key Secret in",
+      "placeholder": "SenseNova Access Key Secret",
+      "title": "Access Key Secret"
+    },
+    "unlock": {
+      "description": "Voer je Access Key ID / Access Key Secret in om de sessie te starten. De applicatie registreert je authenticatie-instellingen niet",
+      "title": "Gebruik aangepaste SenseNova authenticatie-informatie"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "Vul de Access Key van het Baidu Qianfan-platform in",
diff --git a/locales/nl-NL/models.json b/locales/nl-NL/models.json
index a827879f3726..d568c2edb7f5 100644
--- a/locales/nl-NL/models.json
+++ b/locales/nl-NL/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math richt zich op het oplossen van wiskundige vraagstukken en biedt professionele antwoorden op moeilijke vragen."
   },
+  "SenseChat": {
+    "description": "Basisversie van het model (V4), met een contextlengte van 4K, heeft sterke algemene capaciteiten."
+  },
+  "SenseChat-128K": {
+    "description": "Basisversie van het model (V4), met een contextlengte van 128K, presteert uitstekend in taken van begrip en generatie van lange teksten."
+  },
+  "SenseChat-32K": {
+    "description": "Basisversie van het model (V4), met een contextlengte van 32K, flexibel toepasbaar in verschillende scenario's."
+  },
+  "SenseChat-5": {
+    "description": "De nieuwste versie van het model (V5.5), met een contextlengte van 128K, heeft aanzienlijke verbeteringen in wiskundig redeneren, Engelse conversatie, instructievolging en begrip van lange teksten, en kan zich meten met GPT-4o."
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "Met een contextlengte van 32K overtreft het de conversatiebegrip in het Kantonees van GPT-4 en kan het zich in verschillende domeinen zoals kennis, redeneren, wiskunde en coderen meten met GPT-4 Turbo."
+  },
+  "SenseChat-Character": {
+    "description": "Standaardversie van het model, met een contextlengte van 8K, hoge responsnelheid."
+  },
+  "SenseChat-Character-Pro": {
+    "description": "Geavanceerde versie van het model, met een contextlengte van 32K, met uitgebreide verbeteringen in capaciteiten, ondersteunt zowel Chinese als Engelse conversaties."
+  },
+  "SenseChat-Turbo": {
+    "description": "Geschikt voor snelle vraag-en-antwoord en modelafstemming."
+  },
+  "SenseChat-Vision": {
+    "description": "De nieuwste versie van het model (V5.5), met een contextlengte van 16K, ondersteunt meerdere afbeeldingsinvoeren en heeft de basiscapaciteiten van het model geoptimaliseerd, met aanzienlijke verbeteringen in objecteigenschappenherkenning, ruimtelijke relaties, actie-evenementherkenning, scènebegrip, emotieherkenning, logische redenering en tekstbegrip en -generatie."
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B is de open-source versie die een geoptimaliseerde gesprekservaring biedt voor gespreksapplicaties."
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "Llama 3.1 Sonar Small Online model, met 8B parameters, ondersteunt een contextlengte van ongeveer 127.000 tokens, speciaal ontworpen voor online chat en kan efficiënt verschillende tekstinteracties verwerken."
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2 is ontworpen om taken te verwerken die visuele en tekstuele gegevens combineren. Het presteert uitstekend in taken zoals afbeeldingsbeschrijving en visuele vraag-en-antwoord, en overbrugt de kloof tussen taalgeneratie en visueel redeneren."
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2 is ontworpen om taken te verwerken die visuele en tekstuele gegevens combineren. Het presteert uitstekend in taken zoals afbeeldingsbeschrijving en visuele vraag-en-antwoord, en overbrugt de kloof tussen taalgeneratie en visueel redeneren."
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B biedt ongeëvenaarde complexiteitsverwerkingscapaciteiten, op maat gemaakt voor veeleisende projecten."
   },
diff --git a/locales/nl-NL/providers.json b/locales/nl-NL/providers.json
index c5e6198bb1d1..6d24faedda3f 100644
--- a/locales/nl-NL/providers.json
+++ b/locales/nl-NL/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "Tongyi Qianwen is een door Alibaba Cloud zelf ontwikkeld grootschalig taalmodel met krachtige mogelijkheden voor natuurlijke taalbegrip en -generatie. Het kan verschillende vragen beantwoorden, tekstinhoud creëren, meningen uiten, code schrijven, en speelt een rol in verschillende domeinen."
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlow streeft ernaar AGI te versnellen ten behoeve van de mensheid, door de efficiëntie van grootschalige AI te verbeteren met een gebruiksvriendelijke en kosteneffectieve GenAI-stack."
   },
diff --git a/locales/pl-PL/modelProvider.json b/locales/pl-PL/modelProvider.json
index ccf427e3acc8..4a53e74227f2 100644
--- a/locales/pl-PL/modelProvider.json
+++ b/locales/pl-PL/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "Download specified Ollama model"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "Wprowadź SenseNova Access Key ID",
+      "placeholder": "SenseNova Access Key ID",
+      "title": "Access Key ID"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "Wprowadź SenseNova Access Key Secret",
+      "placeholder": "SenseNova Access Key Secret",
+      "title": "Access Key Secret"
+    },
+    "unlock": {
+      "description": "Wprowadź swój Access Key ID / Access Key Secret, aby rozpocząć sesję. Aplikacja nie zapisze twojej konfiguracji autoryzacji",
+      "title": "Użyj niestandardowych informacji autoryzacyjnych SenseNova"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "Wprowadź Access Key z platformy Baidu Qianfan",
diff --git a/locales/pl-PL/models.json b/locales/pl-PL/models.json
index 24bbe2a7596a..7ce9997f30f1 100644
--- a/locales/pl-PL/models.json
+++ b/locales/pl-PL/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math koncentruje się na rozwiązywaniu problemów w dziedzinie matematyki, oferując profesjonalne odpowiedzi na trudne pytania."
   },
+  "SenseChat": {
+    "description": "Podstawowa wersja modelu (V4), długość kontekstu 4K, silne zdolności ogólne."
+  },
+  "SenseChat-128K": {
+    "description": "Podstawowa wersja modelu (V4), długość kontekstu 128K, doskonałe wyniki w zadaniach związanych z rozumieniem i generowaniem długich tekstów."
+  },
+  "SenseChat-32K": {
+    "description": "Podstawowa wersja modelu (V4), długość kontekstu 32K, elastycznie stosowana w różnych scenariuszach."
+  },
+  "SenseChat-5": {
+    "description": "Najnowsza wersja modelu (V5.5), długość kontekstu 128K, znacznie poprawione zdolności w zakresie rozumowania matematycznego, rozmów w języku angielskim, podążania za instrukcjami oraz rozumienia długich tekstów, dorównująca GPT-4o."
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "Długość kontekstu 32K, w rozumieniu rozmów w języku kantońskim przewyższa GPT-4, w wielu dziedzinach, takich jak wiedza, rozumowanie, matematyka i programowanie, dorównuje GPT-4 Turbo."
+  },
+  "SenseChat-Character": {
+    "description": "Standardowa wersja modelu, długość kontekstu 8K, wysoka szybkość reakcji."
+  },
+  "SenseChat-Character-Pro": {
+    "description": "Zaawansowana wersja modelu, długość kontekstu 32K, znacznie poprawione zdolności, obsługuje rozmowy w języku chińskim i angielskim."
+  },
+  "SenseChat-Turbo": {
+    "description": "Idealny do szybkich odpowiedzi i scenariuszy dostosowywania modelu."
+  },
+  "SenseChat-Vision": {
+    "description": "Najnowsza wersja modelu (V5.5), długość kontekstu 16K, obsługuje wiele obrazów jako wejście, w pełni realizuje optymalizację podstawowych zdolności modelu, osiągając znaczne postępy w rozpoznawaniu atrybutów obiektów, relacjach przestrzennych, rozpoznawaniu zdarzeń, rozumieniu scen, rozpoznawaniu emocji, rozumowaniu logicznym oraz generowaniu i rozumieniu tekstu."
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B to otwarta wersja, oferująca zoptymalizowane doświadczenie dialogowe dla aplikacji konwersacyjnych."
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "Model Llama 3.1 Sonar Small Online, z 8B parametrami, obsługujący kontekst o długości około 127,000 tokenów, zaprojektowany do czatów online, efektywnie przetwarzający różne interakcje tekstowe."
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2 jest zaprojektowany do obsługi zadań łączących dane wizualne i tekstowe. Wykazuje doskonałe wyniki w zadaniach takich jak opisywanie obrazów i odpowiadanie na pytania wizualne, przekraczając granice między generowaniem języka a rozumowaniem wizualnym."
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2 jest zaprojektowany do obsługi zadań łączących dane wizualne i tekstowe. Wykazuje doskonałe wyniki w zadaniach takich jak opisywanie obrazów i odpowiadanie na pytania wizualne, przekraczając granice między generowaniem języka a rozumowaniem wizualnym."
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B oferuje niezrównane możliwości przetwarzania złożoności, dostosowane do projektów o wysokich wymaganiach."
   },
diff --git a/locales/pl-PL/providers.json b/locales/pl-PL/providers.json
index bf4ce6f1b46a..95e930d1c518 100644
--- a/locales/pl-PL/providers.json
+++ b/locales/pl-PL/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "Tongyi Qianwen to samodzielnie opracowany przez Alibaba Cloud model językowy o dużej skali, charakteryzujący się silnymi zdolnościami rozumienia i generowania języka naturalnego. Może odpowiadać na różnorodne pytania, tworzyć treści pisemne, wyrażać opinie, pisać kod i działać w wielu dziedzinach."
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlow dąży do przyspieszenia AGI, aby przynieść korzyści ludzkości, poprawiając wydajność dużych modeli AI dzięki łatwemu w użyciu i niskokosztowemu stosowi GenAI."
   },
diff --git a/locales/pt-BR/modelProvider.json b/locales/pt-BR/modelProvider.json
index 48d56c9a0342..308818c089a4 100644
--- a/locales/pt-BR/modelProvider.json
+++ b/locales/pt-BR/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "Download specified Ollama model"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "Insira o SenseNova Access Key ID",
+      "placeholder": "SenseNova Access Key ID",
+      "title": "Access Key ID"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "Insira o SenseNova Access Key Secret",
+      "placeholder": "SenseNova Access Key Secret",
+      "title": "Access Key Secret"
+    },
+    "unlock": {
+      "description": "Digite seu Access Key ID / Access Key Secret para iniciar a sessão. O aplicativo não registrará suas configurações de autenticação",
+      "title": "Usar informações de autenticação personalizadas do SenseNova"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "Insira a Access Key da plataforma Qianfan do Baidu",
diff --git a/locales/pt-BR/models.json b/locales/pt-BR/models.json
index 1277d3f805b3..954a9039eecc 100644
--- a/locales/pt-BR/models.json
+++ b/locales/pt-BR/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math foca na resolução de problemas na área de matemática, oferecendo respostas especializadas para questões de alta dificuldade."
   },
+  "SenseChat": {
+    "description": "Modelo da versão básica (V4), com comprimento de contexto de 4K, com capacidades gerais poderosas."
+  },
+  "SenseChat-128K": {
+    "description": "Modelo da versão básica (V4), com comprimento de contexto de 128K, se destaca em tarefas de compreensão e geração de textos longos."
+  },
+  "SenseChat-32K": {
+    "description": "Modelo da versão básica (V4), com comprimento de contexto de 32K, aplicável de forma flexível em diversos cenários."
+  },
+  "SenseChat-5": {
+    "description": "Modelo da versão mais recente (V5.5), com comprimento de contexto de 128K, com capacidades significativamente aprimoradas em raciocínio matemático, diálogos em inglês, seguimento de instruções e compreensão de textos longos, rivalizando com o GPT-4o."
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "Comprimento de contexto de 32K, superando o GPT-4 na compreensão de diálogos em cantonês, competindo com o GPT-4 Turbo em várias áreas, incluindo conhecimento, raciocínio, matemática e programação."
+  },
+  "SenseChat-Character": {
+    "description": "Modelo padrão, com comprimento de contexto de 8K, alta velocidade de resposta."
+  },
+  "SenseChat-Character-Pro": {
+    "description": "Modelo avançado, com comprimento de contexto de 32K, com capacidades amplamente aprimoradas, suportando diálogos em chinês e inglês."
+  },
+  "SenseChat-Turbo": {
+    "description": "Adequado para perguntas rápidas e cenários de ajuste fino do modelo."
+  },
+  "SenseChat-Vision": {
+    "description": "Modelo da versão mais recente (V5.5), com comprimento de contexto de 16K, suporta entrada de múltiplas imagens, implementa otimizações abrangentes nas capacidades básicas do modelo, com grandes melhorias em reconhecimento de propriedades de objetos, relações espaciais, reconhecimento de eventos de ação, compreensão de cenas, reconhecimento de emoções, raciocínio lógico e compreensão e geração de texto."
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B é uma versão de código aberto, oferecendo uma experiência de diálogo otimizada para aplicações de conversa."
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "O modelo Llama 3.1 Sonar Small Online possui 8B de parâmetros, suportando um comprimento de contexto de aproximadamente 127.000 tokens, projetado para chats online, capaz de processar eficientemente diversas interações textuais."
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2 é projetado para lidar com tarefas que combinam dados visuais e textuais. Ele se destaca em tarefas como descrição de imagens e perguntas visuais, superando a lacuna entre geração de linguagem e raciocínio visual."
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2 é projetado para lidar com tarefas que combinam dados visuais e textuais. Ele se destaca em tarefas como descrição de imagens e perguntas visuais, superando a lacuna entre geração de linguagem e raciocínio visual."
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B oferece capacidade de processamento incomparável para complexidade, projetado sob medida para projetos de alta demanda."
   },
diff --git a/locales/pt-BR/providers.json b/locales/pt-BR/providers.json
index b60b145e6fb6..b1d75fca8e73 100644
--- a/locales/pt-BR/providers.json
+++ b/locales/pt-BR/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "Qwen é um modelo de linguagem de grande escala desenvolvido pela Alibaba Cloud, com forte capacidade de compreensão e geração de linguagem natural. Ele pode responder a várias perguntas, criar conteúdo escrito, expressar opiniões e escrever código, atuando em vários campos."
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlow se dedica a acelerar a AGI para beneficiar a humanidade, melhorando a eficiência da IA em larga escala por meio de uma pilha GenAI fácil de usar e de baixo custo."
   },
diff --git a/locales/ru-RU/modelProvider.json b/locales/ru-RU/modelProvider.json
index 2f974ed7c81a..4001ad8ee4db 100644
--- a/locales/ru-RU/modelProvider.json
+++ b/locales/ru-RU/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "Download specified Ollama model"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "Введите SenseNova Access Key ID",
+      "placeholder": "SenseNova Access Key ID",
+      "title": "Access Key ID"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "Введите SenseNova Access Key Secret",
+      "placeholder": "SenseNova Access Key Secret",
+      "title": "Access Key Secret"
+    },
+    "unlock": {
+      "description": "Введите ваш Access Key ID / Access Key Secret, чтобы начать сессию. Приложение не будет записывать ваши настройки аутентификации",
+      "title": "Используйте пользовательскую аутентификацию SenseNova"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "Введите Access Key платформы Baidu Qianfan",
diff --git a/locales/ru-RU/models.json b/locales/ru-RU/models.json
index b466be4b9e8b..40cc66a99777 100644
--- a/locales/ru-RU/models.json
+++ b/locales/ru-RU/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math сосредоточен на решении математических задач, предоставляя профессиональные ответы на сложные вопросы."
   },
+  "SenseChat": {
+    "description": "Базовая версия модели (V4), длина контекста 4K, обладает мощными универсальными возможностями."
+  },
+  "SenseChat-128K": {
+    "description": "Базовая версия модели (V4), длина контекста 128K, демонстрирует отличные результаты в задачах понимания и генерации длинных текстов."
+  },
+  "SenseChat-32K": {
+    "description": "Базовая версия модели (V4), длина контекста 32K, гибко применяется в различных сценариях."
+  },
+  "SenseChat-5": {
+    "description": "Последняя версия модели (V5.5), длина контекста 128K, значительно улучшенные способности в математическом рассуждении, английских диалогах, следовании инструкциям и понимании длинных текстов, сопоставимые с GPT-4o."
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "Длина контекста 32K, превосходит GPT-4 в понимании диалогов на кантонском, сопоставим с GPT-4 Turbo в таких областях, как знания, рассуждение, математика и написание кода."
+  },
+  "SenseChat-Character": {
+    "description": "Стандартная версия модели, длина контекста 8K, высокая скорость отклика."
+  },
+  "SenseChat-Character-Pro": {
+    "description": "Расширенная версия модели, длина контекста 32K, всеобъемлющие улучшения возможностей, поддерживает диалоги на китайском и английском языках."
+  },
+  "SenseChat-Turbo": {
+    "description": "Подходит для быстрого ответа на вопросы и сценариев тонкой настройки модели."
+  },
+  "SenseChat-Vision": {
+    "description": "Последняя версия модели (V5.5), длина контекста 16K, поддерживает ввод нескольких изображений, полностью реализована оптимизация базовых возможностей модели, значительно улучшены распознавание свойств объектов, пространственные отношения, распознавание событий, понимание сцен, распознавание эмоций, логическое рассуждение и генерация текста."
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B — это открытая версия, обеспечивающая оптимизированный диалоговый опыт для приложений."
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "Модель Llama 3.1 Sonar Small Online, обладающая 8B параметрами, поддерживает контекст длиной около 127,000 токенов, специально разработана для онлайн-чатов и эффективно обрабатывает различные текстовые взаимодействия."
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2 предназначен для выполнения задач, сочетающих визуальные и текстовые данные. Он демонстрирует отличные результаты в таких задачах, как описание изображений и визуальные вопросы и ответы, преодолевая разрыв между генерацией языка и визуальным рассуждением."
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2 предназначен для выполнения задач, сочетающих визуальные и текстовые данные. Он демонстрирует отличные результаты в таких задачах, как описание изображений и визуальные вопросы и ответы, преодолевая разрыв между генерацией языка и визуальным рассуждением."
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B предлагает непревзойдённые возможности обработки сложности, специально разработанные для высоких требований проектов."
   },
diff --git a/locales/ru-RU/providers.json b/locales/ru-RU/providers.json
index 11a98eb19291..2941102a11f9 100644
--- a/locales/ru-RU/providers.json
+++ b/locales/ru-RU/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "Qwen — это сверхбольшая языковая модель, разработанная Alibaba Cloud, обладающая мощными возможностями понимания и генерации естественного языка. Она может отвечать на различные вопросы, создавать текстовый контент, выражать мнения и писать код, играя важную роль в различных областях."
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlow стремится ускорить AGI, чтобы принести пользу человечеству, повышая эффективность масштабного AI с помощью простого и экономичного стека GenAI."
   },
diff --git a/locales/tr-TR/modelProvider.json b/locales/tr-TR/modelProvider.json
index 4a2bd80535a6..41798d6a2439 100644
--- a/locales/tr-TR/modelProvider.json
+++ b/locales/tr-TR/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "下载指定的 Ollama 模型"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "SenseNova Erişim Anahtar Kimliği girin",
+      "placeholder": "SenseNova Erişim Anahtar Kimliği",
+      "title": "Erişim Anahtar Kimliği"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "SenseNova Erişim Anahtar Gizli Anahtarını girin",
+      "placeholder": "SenseNova Erişim Anahtar Gizli Anahtarı",
+      "title": "Erişim Anahtar Gizli Anahtarı"
+    },
+    "unlock": {
+      "description": "Oturuma başlamak için Erişim Anahtar Kimliğinizi / Erişim Anahtar Gizli Anahtarınızı girin. Uygulama kimlik doğrulama yapılandırmanızı kaydetmeyecek",
+      "title": "Özel SenseNova kimlik doğrulama bilgilerini kullan"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "Baidu Qianfan platform için Access Key girin",
diff --git a/locales/tr-TR/models.json b/locales/tr-TR/models.json
index c53fa6575987..402ec91ca08b 100644
--- a/locales/tr-TR/models.json
+++ b/locales/tr-TR/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math, matematik alanındaki sorunları çözmeye odaklanır ve yüksek zorlukta sorulara profesyonel yanıtlar sunar."
   },
+  "SenseChat": {
+    "description": "Temel sürüm model (V4), 4K bağlam uzunluğu ile genel yetenekleri güçlüdür."
+  },
+  "SenseChat-128K": {
+    "description": "Temel sürüm model (V4), 128K bağlam uzunluğu ile uzun metin anlama ve üretme görevlerinde mükemmel performans sergilemektedir."
+  },
+  "SenseChat-32K": {
+    "description": "Temel sürüm model (V4), 32K bağlam uzunluğu ile çeşitli senaryolarda esnek bir şekilde uygulanabilir."
+  },
+  "SenseChat-5": {
+    "description": "En son sürüm model (V5.5), 128K bağlam uzunluğu, matematiksel akıl yürütme, İngilizce diyalog, talimat takibi ve uzun metin anlama gibi alanlarda önemli gelişmeler göstermektedir ve GPT-4o ile karşılaştırılabilir."
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "32K bağlam uzunluğu ile, Kantonca diyalog anlama konusunda GPT-4'ü aşmakta, bilgi, akıl yürütme, matematik ve kod yazma gibi birçok alanda GPT-4 Turbo ile rekabet edebilmektedir."
+  },
+  "SenseChat-Character": {
+    "description": "Standart sürüm model, 8K bağlam uzunluğu ile yüksek yanıt hızı sunmaktadır."
+  },
+  "SenseChat-Character-Pro": {
+    "description": "Gelişmiş sürüm model, 32K bağlam uzunluğu ile yetenekleri tamamen geliştirilmiş, Çince/İngilizce diyalogları desteklemektedir."
+  },
+  "SenseChat-Turbo": {
+    "description": "Hızlı soru-cevap ve model ince ayar senaryoları için uygundur."
+  },
+  "SenseChat-Vision": {
+    "description": "En son sürüm model (V5.5), 16K bağlam uzunluğu, çoklu görüntü girişini destekler, modelin temel yetenek optimizasyonunu tam olarak gerçekleştirir ve nesne özellik tanıma, mekansal ilişkiler, eylem olayı tanıma, sahne anlama, duygu tanıma, mantıksal bilgi akıl yürütme ve metin anlama üretiminde önemli iyileştirmeler sağlamıştır."
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B açık kaynak versiyonu, diyalog uygulamaları için optimize edilmiş bir diyalog deneyimi sunar."
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "Llama 3.1 Sonar Small Online modeli, 8B parametreye sahiptir ve yaklaşık 127,000 belirteçlik bağlam uzunluğunu destekler, çevrimiçi sohbet için tasarlanmıştır ve çeşitli metin etkileşimlerini etkili bir şekilde işler."
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2, görsel ve metin verilerini birleştiren görevleri işlemek için tasarlanmıştır. Görüntü tanımlama ve görsel soru-cevap gibi görevlerde mükemmel performans sergileyerek dil üretimi ile görsel akıl yürütme arasındaki boşluğu kapatmaktadır."
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2, görsel ve metin verilerini birleştiren görevleri işlemek için tasarlanmıştır. Görüntü tanımlama ve görsel soru-cevap gibi görevlerde mükemmel performans sergileyerek dil üretimi ile görsel akıl yürütme arasındaki boşluğu kapatmaktadır."
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B, eşsiz karmaşıklık işleme yeteneği sunar ve yüksek talepli projeler için özel olarak tasarlanmıştır."
   },
diff --git a/locales/tr-TR/providers.json b/locales/tr-TR/providers.json
index 5a324e5a4f03..e1400eaae272 100644
--- a/locales/tr-TR/providers.json
+++ b/locales/tr-TR/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "Tongyi Qianwen, Alibaba Cloud tarafından geliştirilen büyük ölçekli bir dil modelidir ve güçlü doğal dil anlama ve üretme yeteneklerine sahiptir. Çeşitli soruları yanıtlayabilir, metin içeriği oluşturabilir, görüşlerini ifade edebilir ve kod yazabilir. Birçok alanda etkili bir şekilde kullanılmaktadır."
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlow, insanlığa fayda sağlamak amacıyla AGI'yi hızlandırmaya odaklanmakta ve kullanıcı dostu ve maliyet etkin GenAI yığınları ile büyük ölçekli yapay zeka verimliliğini artırmayı hedeflemektedir."
   },
diff --git a/locales/vi-VN/modelProvider.json b/locales/vi-VN/modelProvider.json
index 54ff8a321ec5..cc690a75ea90 100644
--- a/locales/vi-VN/modelProvider.json
+++ b/locales/vi-VN/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "Tải xuống mô hình Ollama đã chỉ định"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "Nhập SenseNova Access Key ID",
+      "placeholder": "SenseNova Access Key ID",
+      "title": "Access Key ID"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "Nhập SenseNova Access Key Secret",
+      "placeholder": "SenseNova Access Key Secret",
+      "title": "Access Key Secret"
+    },
+    "unlock": {
+      "description": "Nhập Access Key ID / Access Key Secret của bạn để bắt đầu phiên. Ứng dụng sẽ không ghi lại cấu hình xác thực của bạn",
+      "title": "Sử dụng thông tin xác thực SenseNova tùy chỉnh"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "Nhập Access Key từ nền tảng Qianfan của Baidu",
diff --git a/locales/vi-VN/models.json b/locales/vi-VN/models.json
index 1c8dbded195f..33e4f585a334 100644
--- a/locales/vi-VN/models.json
+++ b/locales/vi-VN/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math tập trung vào việc giải quyết các vấn đề trong lĩnh vực toán học, cung cấp giải pháp chuyên nghiệp cho các bài toán khó."
   },
+  "SenseChat": {
+    "description": "Mô hình phiên bản cơ bản (V4), độ dài ngữ cảnh 4K, khả năng tổng quát mạnh mẽ."
+  },
+  "SenseChat-128K": {
+    "description": "Mô hình phiên bản cơ bản (V4), độ dài ngữ cảnh 128K, thể hiện xuất sắc trong các nhiệm vụ hiểu và sinh văn bản dài."
+  },
+  "SenseChat-32K": {
+    "description": "Mô hình phiên bản cơ bản (V4), độ dài ngữ cảnh 32K, linh hoạt áp dụng trong nhiều tình huống."
+  },
+  "SenseChat-5": {
+    "description": "Phiên bản mô hình mới nhất (V5.5), độ dài ngữ cảnh 128K, khả năng cải thiện đáng kể trong suy luận toán học, đối thoại tiếng Anh, theo dõi chỉ dẫn và hiểu biết văn bản dài, ngang tầm với GPT-4o."
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "Độ dài ngữ cảnh 32K, vượt qua GPT-4 trong hiểu biết đối thoại tiếng Quảng Đông, có thể so sánh với GPT-4 Turbo trong nhiều lĩnh vực như kiến thức, suy luận, toán học và lập trình mã."
+  },
+  "SenseChat-Character": {
+    "description": "Mô hình phiên bản tiêu chuẩn, độ dài ngữ cảnh 8K, tốc độ phản hồi cao."
+  },
+  "SenseChat-Character-Pro": {
+    "description": "Mô hình phiên bản cao cấp, độ dài ngữ cảnh 32K, khả năng được cải thiện toàn diện, hỗ trợ đối thoại tiếng Trung/tiếng Anh."
+  },
+  "SenseChat-Turbo": {
+    "description": "Phù hợp cho các tình huống hỏi đáp nhanh và tinh chỉnh mô hình."
+  },
+  "SenseChat-Vision": {
+    "description": "Phiên bản mô hình mới nhất (V5.5), độ dài ngữ cảnh 16K, hỗ trợ đầu vào nhiều hình ảnh, hoàn thiện khả năng cơ bản của mô hình, đạt được sự cải thiện lớn trong nhận diện thuộc tính đối tượng, mối quan hệ không gian, nhận diện sự kiện hành động, hiểu biết cảnh, nhận diện cảm xúc, suy luận kiến thức logic và hiểu biết sinh văn bản."
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B là phiên bản mã nguồn mở, cung cấp trải nghiệm đối thoại tối ưu cho các ứng dụng hội thoại."
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "Mô hình Llama 3.1 Sonar Small Online, có 8B tham số, hỗ trợ độ dài ngữ cảnh khoảng 127,000 mã, được thiết kế cho trò chuyện trực tuyến, có khả năng xử lý hiệu quả các tương tác văn bản khác nhau."
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2 được thiết kế để xử lý các nhiệm vụ kết hợp dữ liệu hình ảnh và văn bản. Nó thể hiện xuất sắc trong các nhiệm vụ mô tả hình ảnh và hỏi đáp hình ảnh, vượt qua ranh giới giữa tạo ngôn ngữ và suy luận hình ảnh."
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2 được thiết kế để xử lý các nhiệm vụ kết hợp dữ liệu hình ảnh và văn bản. Nó thể hiện xuất sắc trong các nhiệm vụ mô tả hình ảnh và hỏi đáp hình ảnh, vượt qua ranh giới giữa tạo ngôn ngữ và suy luận hình ảnh."
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B cung cấp khả năng xử lý phức tạp vô song, được thiết kế riêng cho các dự án yêu cầu cao."
   },
diff --git a/locales/vi-VN/providers.json b/locales/vi-VN/providers.json
index 21c4c79606c1..79b8ef736b87 100644
--- a/locales/vi-VN/providers.json
+++ b/locales/vi-VN/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "Qwen là mô hình ngôn ngữ quy mô lớn tự phát triển của Alibaba Cloud, có khả năng hiểu và tạo ngôn ngữ tự nhiên mạnh mẽ. Nó có thể trả lời nhiều câu hỏi, sáng tác nội dung văn bản, bày tỏ quan điểm, viết mã, v.v., hoạt động trong nhiều lĩnh vực."
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlow cam kết tăng tốc AGI để mang lại lợi ích cho nhân loại, nâng cao hiệu quả AI quy mô lớn thông qua một ngăn xếp GenAI dễ sử dụng và chi phí thấp."
   },
diff --git a/locales/zh-CN/modelProvider.json b/locales/zh-CN/modelProvider.json
index 216c75f040fe..27f30e78c163 100644
--- a/locales/zh-CN/modelProvider.json
+++ b/locales/zh-CN/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "下载指定的 Ollama 模型"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "填入 SenseNova Access Key ID",
+      "placeholder": "SenseNova Access Key ID",
+      "title": "Access Key ID"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "填入 SenseNova Access Key Secret",
+      "placeholder": "SenseNova Access Key Secret",
+      "title": "Access Key Secret"
+    },
+    "unlock": {
+      "description": "输入你的 Access Key ID / Access Key Secret 即可开始会话。应用不会记录你的鉴权配置",
+      "title": "使用自定义 SenseNova 鉴权信息"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "填入百度千帆平台的 Access Key",
diff --git a/locales/zh-CN/models.json b/locales/zh-CN/models.json
index 679925ded7c9..a32f2ee24168 100644
--- a/locales/zh-CN/models.json
+++ b/locales/zh-CN/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math 专注于数学领域的问题求解，为高难度题提供专业解答。"
   },
+  "SenseChat": {
+    "description": "基础版本模型 (V4)，4K上下文长度，通用能力强大"
+  },
+  "SenseChat-128K": {
+    "description": "基础版本模型 (V4)，128K上下文长度，在长文本理解及生成等任务中表现出色"
+  },
+  "SenseChat-32K": {
+    "description": "基础版本模型 (V4)，32K上下文长度，灵活应用于各类场景"
+  },
+  "SenseChat-5": {
+    "description": "最新版本模型 (V5.5)，128K上下文长度，在数学推理、英文对话、指令跟随以及长文本理解等领域能力显著提升，比肩GPT-4o"
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "32K上下文长度，在粤语的对话理解上超越了GPT-4，在知识、推理、数学及代码编写等多个领域均能与GPT-4 Turbo相媲美"
+  },
+  "SenseChat-Character": {
+    "description": "标准版模型，8K上下文长度，高响应速度"
+  },
+  "SenseChat-Character-Pro": {
+    "description": "高级版模型，32K上下文长度，能力全面提升，支持中/英文对话"
+  },
+  "SenseChat-Turbo": {
+    "description": "适用于快速问答、模型微调场景"
+  },
+  "SenseChat-Vision": {
+    "description": "最新版本模型 (V5.5)，16K上下文长度，支持多图的输入，全面实现模型基础能力优化，在对象属性识别、空间关系、动作事件识别、场景理解、情感识别、逻辑常识推理和文本理解生成上都实现了较大提升。"
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B 开放源码版本，为会话应用提供优化后的对话体验。"
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "Llama 3.1 Sonar Small Online 模型，具备8B参数，支持约127,000个标记的上下文长度，专为在线聊天设计，能高效处理各种文本交互。"
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。"
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。"
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B 提供无与伦比的复杂性处理能力，为高要求项目量身定制。"
   },
diff --git a/locales/zh-CN/providers.json b/locales/zh-CN/providers.json
index ce1fa0f77a25..48edaa8a88b6 100644
--- a/locales/zh-CN/providers.json
+++ b/locales/zh-CN/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "通义千问是阿里云自主研发的超大规模语言模型，具有强大的自然语言理解和生成能力。它可以回答各种问题、创作文字内容、表达观点看法、撰写代码等，在多个领域发挥作用。"
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconCloud，基于优秀开源基础模型的高性价比 GenAI 云服务"
   },
diff --git a/locales/zh-TW/modelProvider.json b/locales/zh-TW/modelProvider.json
index e502fbaa19d8..df96ebaecd11 100644
--- a/locales/zh-TW/modelProvider.json
+++ b/locales/zh-TW/modelProvider.json
@@ -112,6 +112,22 @@
       "title": "下載指定的 Ollama 模型"
     }
   },
+  "sensenova": {
+    "sensenovaAccessKeyID": {
+      "desc": "填入 SenseNova Access Key ID",
+      "placeholder": "SenseNova Access Key ID",
+      "title": "Access Key ID"
+    },
+    "sensenovaAccessKeySecret": {
+      "desc": "填入 SenseNova Access Key Secret",
+      "placeholder": "SenseNova Access Key Secret",
+      "title": "Access Key Secret"
+    },
+    "unlock": {
+      "description": "輸入你的 Access Key ID / Access Key Secret 即可開始會話。應用不會記錄你的鑑權配置",
+      "title": "使用自訂的 SenseNova 鑑權資訊"
+    }
+  },
   "wenxin": {
     "accessKey": {
       "desc": "填入百度千帆平台的 Access Key",
diff --git a/locales/zh-TW/models.json b/locales/zh-TW/models.json
index 5b00f24a09c2..536506dd7915 100644
--- a/locales/zh-TW/models.json
+++ b/locales/zh-TW/models.json
@@ -131,6 +131,33 @@
   "Qwen/Qwen2.5-Math-72B-Instruct": {
     "description": "Qwen2.5-Math專注於數學領域的問題求解，為高難度題提供專業解答。"
   },
+  "SenseChat": {
+    "description": "基礎版本模型 (V4)，4K上下文長度，通用能力強大"
+  },
+  "SenseChat-128K": {
+    "description": "基礎版本模型 (V4)，128K上下文長度，在長文本理解及生成等任務中表現出色"
+  },
+  "SenseChat-32K": {
+    "description": "基礎版本模型 (V4)，32K上下文長度，靈活應用於各類場景"
+  },
+  "SenseChat-5": {
+    "description": "最新版本模型 (V5.5)，128K上下文長度，在數學推理、英文對話、指令跟隨以及長文本理解等領域能力顯著提升，比肩GPT-4o"
+  },
+  "SenseChat-5-Cantonese": {
+    "description": "32K上下文長度，在粵語的對話理解上超越了GPT-4，在知識、推理、數學及程式編寫等多個領域均能與GPT-4 Turbo相媲美"
+  },
+  "SenseChat-Character": {
+    "description": "標準版模型，8K上下文長度，高響應速度"
+  },
+  "SenseChat-Character-Pro": {
+    "description": "高級版模型，32K上下文長度，能力全面提升，支持中/英文對話"
+  },
+  "SenseChat-Turbo": {
+    "description": "適用於快速問答、模型微調場景"
+  },
+  "SenseChat-Vision": {
+    "description": "最新版本模型 (V5.5)，16K上下文長度，支持多圖的輸入，全面實現模型基礎能力優化，在物件屬性識別、空間關係、動作事件識別、場景理解、情感識別、邏輯常識推理和文本理解生成上都實現了較大提升。"
+  },
   "THUDM/glm-4-9b-chat": {
     "description": "GLM-4 9B 開放源碼版本，為會話應用提供優化後的對話體驗。"
   },
@@ -589,6 +616,12 @@
   "llama-3.1-sonar-small-128k-online": {
     "description": "Llama 3.1 Sonar Small Online 模型，具備 8B 參數，支持約 127,000 個標記的上下文長度，專為在線聊天設計，能高效處理各種文本交互。"
   },
+  "llama-3.2-11b-vision-preview": {
+    "description": "Llama 3.2 旨在處理結合視覺和文本數據的任務。它在圖像描述和視覺問答等任務中表現出色，跨越了語言生成和視覺推理之間的鴻溝。"
+  },
+  "llama-3.2-90b-vision-preview": {
+    "description": "Llama 3.2 旨在處理結合視覺和文本數據的任務。它在圖像描述和視覺問答等任務中表現出色，跨越了語言生成和視覺推理之間的鴻溝。"
+  },
   "llama3-70b-8192": {
     "description": "Meta Llama 3 70B 提供無與倫比的複雜性處理能力，為高要求項目量身定制。"
   },
diff --git a/locales/zh-TW/providers.json b/locales/zh-TW/providers.json
index 0c5f40f61fab..94f628622354 100644
--- a/locales/zh-TW/providers.json
+++ b/locales/zh-TW/providers.json
@@ -60,6 +60,7 @@
   "qwen": {
     "description": "通義千問是阿里雲自主研發的超大規模語言模型，具有強大的自然語言理解和生成能力。它可以回答各種問題、創作文字內容、表達觀點看法、撰寫代碼等，在多個領域發揮作用。"
   },
+  "sensenova": {},
   "siliconcloud": {
     "description": "SiliconFlow 致力於加速 AGI，以惠及人類，通過易用與成本低的 GenAI 堆疊提升大規模 AI 效率。"
   },
diff --git a/package.json b/package.json
index 8b3cb670c2ce..138e8c710ad8 100644
--- a/package.json
+++ b/package.json
@@ -135,6 +135,7 @@
     "@trpc/next": "next",
     "@trpc/react-query": "next",
     "@trpc/server": "next",
+    "@types/crypto-js": "^4.2.0",
     "@vercel/analytics": "^1.3.1",
     "@vercel/edge-config": "^1.2.1",
     "@vercel/speed-insights": "^1.0.12",
diff --git a/src/app/(main)/settings/llm/ProviderList/SenseNova/index.tsx b/src/app/(main)/settings/llm/ProviderList/SenseNova/index.tsx
new file mode 100644
index 000000000000..c109d5c4ee7c
--- /dev/null
+++ b/src/app/(main)/settings/llm/ProviderList/SenseNova/index.tsx
@@ -0,0 +1,44 @@
+'use client';
+
+import { Input } from 'antd';
+import { useTranslation } from 'react-i18next';
+
+import { SenseNovaProviderCard } from '@/config/modelProviders';
+import { GlobalLLMProviderKey } from '@/types/user/settings';
+
+import { KeyVaultsConfigKey } from '../../const';
+import { ProviderItem } from '../../type';
+
+const providerKey: GlobalLLMProviderKey = 'sensenova';
+
+export const useSenseNovaProvider = (): ProviderItem => {
+  const { t } = useTranslation('modelProvider');
+
+  return {
+    ...SenseNovaProviderCard,
+    apiKeyItems: [
+      {
+        children: (
+          <Input.Password
+            autoComplete={'new-password'}
+            placeholder={t(`${providerKey}.sensenovaAccessKeyID.placeholder`)}
+          />
+        ),
+        desc: t(`${providerKey}.sensenovaAccessKeyID.desc`),
+        label: t(`${providerKey}.sensenovaAccessKeyID.title`),
+        name: [KeyVaultsConfigKey, providerKey, 'sensenovaAccessKeyID'],
+      },
+      {
+        children: (
+          <Input.Password
+            autoComplete={'new-password'}
+            placeholder={t(`${providerKey}.sensenovaAccessKeySecret.placeholder`)}
+          />
+        ),
+        desc: t(`${providerKey}.sensenovaAccessKeySecret.desc`),
+        label: t(`${providerKey}.sensenovaAccessKeySecret.title`),
+        name: [KeyVaultsConfigKey, providerKey, 'sensenovaAccessKeySecret'],
+      },
+    ],
+  };
+};
diff --git a/src/app/(main)/settings/llm/ProviderList/providers.tsx b/src/app/(main)/settings/llm/ProviderList/providers.tsx
index d07e93fe0546..47f40bf2f30d 100644
--- a/src/app/(main)/settings/llm/ProviderList/providers.tsx
+++ b/src/app/(main)/settings/llm/ProviderList/providers.tsx
@@ -34,6 +34,7 @@ import { useGithubProvider } from './Github';
 import { useOllamaProvider } from './Ollama';
 import { useOpenAIProvider } from './OpenAI';
 import { useWenxinProvider } from './Wenxin';
+import { useSenseNovaProvider } from './SenseNova';
 
 export const useProviderList = (): ProviderItem[] => {
   const AzureProvider = useAzureProvider();
@@ -42,6 +43,7 @@ export const useProviderList = (): ProviderItem[] => {
   const BedrockProvider = useBedrockProvider();
   const GithubProvider = useGithubProvider();
   const WenxinProvider = useWenxinProvider();
+  const SenseNovaProvider = useSenseNovaProvider();
 
   return useMemo(
     () => [
@@ -68,6 +70,7 @@ export const useProviderList = (): ProviderItem[] => {
       SparkProviderCard,
       ZhiPuProviderCard,
       ZeroOneProviderCard,
+      SenseNovaProvider,
       StepfunProviderCard,
       MoonshotProviderCard,
       BaichuanProviderCard,
@@ -76,6 +79,6 @@ export const useProviderList = (): ProviderItem[] => {
       TaichuProviderCard,
       SiliconCloudProviderCard,
     ],
-    [AzureProvider, OllamaProvider, OpenAIProvider, BedrockProvider, GithubProvider,WenxinProvider],
+    [AzureProvider, OllamaProvider, OpenAIProvider, BedrockProvider, GithubProvider, WenxinProvider, SenseNovaProvider],
   );
 };
diff --git a/src/app/api/chat/agentRuntime.test.ts b/src/app/api/chat/agentRuntime.test.ts
index 1d1a1b1064e4..848e8b25fbde 100644
--- a/src/app/api/chat/agentRuntime.test.ts
+++ b/src/app/api/chat/agentRuntime.test.ts
@@ -24,6 +24,7 @@ import {
   ModelProvider,
 } from '@/libs/agent-runtime';
 import { AgentRuntime } from '@/libs/agent-runtime';
+import { LobeSenseNovaAI } from '@/libs/agent-runtime/sensenova';
 import { LobeStepfunAI } from '@/libs/agent-runtime/stepfun';
 import LobeWenxinAI from '@/libs/agent-runtime/wenxin';
 
@@ -58,6 +59,9 @@ vi.mock('@/config/llm', () => ({
 
     WENXIN_ACCESS_KEY: 'test-wenxin-access-key',
     WENXIN_SECRET_KEY: 'test-wenxin-secret-key',
+
+    SENSENOVA_ACCESS_KEY_ID: 'test-sensenova-access-key-id',
+    SENSENOVA_ACCESS_KEY_SECRET: 'test-sensenova-access-key-secret',
   })),
 }));
 
@@ -206,6 +210,16 @@ describe('initAgentRuntimeWithUserPayload method', () => {
       expect(runtime['_runtime']).toBeInstanceOf(LobeStepfunAI);
     });
 
+    it.skip('SenseNova AI provider: with apikey', async () => {
+      const jwtPayload: JWTPayload = {
+        sensenovaAccessKeyID: 'user-sensenova-access-key-id',
+        sensenovaAccessKeySecret: 'sensenova-access-key-secret',
+      };
+      const runtime = await initAgentRuntimeWithUserPayload(ModelProvider.SenseNova, jwtPayload);
+      expect(runtime).toBeInstanceOf(AgentRuntime);
+      expect(runtime['_runtime']).toBeInstanceOf(LobeSenseNovaAI);
+    });
+
     it.skip('Wenxin AI provider: with apikey', async () => {
       const jwtPayload: JWTPayload = {
         wenxinAccessKey: 'user-wenxin-accessKey',
@@ -353,6 +367,13 @@ describe('initAgentRuntimeWithUserPayload method', () => {
       expect(runtime['_runtime']).toBeInstanceOf(LobeTogetherAI);
     });
 
+    it.skip('SenseNova AI provider: without apikey', async () => {
+      const jwtPayload = {};
+      const runtime = await initAgentRuntimeWithUserPayload(ModelProvider.SenseNova, jwtPayload);
+      expect(runtime).toBeInstanceOf(AgentRuntime);
+      expect(runtime['_runtime']).toBeInstanceOf(LobeSenseNovaAI);
+    });
+
     it.skip('Wenxin AI provider: without apikey', async () => {
       const jwtPayload = {};
       const runtime = await initAgentRuntimeWithUserPayload(ModelProvider.Wenxin, jwtPayload);
diff --git a/src/app/api/chat/sensenova/route.test.ts b/src/app/api/chat/sensenova/route.test.ts
new file mode 100644
index 000000000000..625ba8a11844
--- /dev/null
+++ b/src/app/api/chat/sensenova/route.test.ts
@@ -0,0 +1,27 @@
+// @vitest-environment edge-runtime
+import { describe, expect, it, vi } from 'vitest';
+
+import { POST as UniverseRoute } from '../[provider]/route';
+import { POST, runtime } from './route';
+
+// 模拟 '../[provider]/route'
+vi.mock('../[provider]/route', () => ({
+  POST: vi.fn().mockResolvedValue('mocked response'),
+}));
+
+describe('Configuration tests', () => {
+  it('should have runtime set to "edge"', () => {
+    expect(runtime).toBe('nodejs');
+  });
+});
+
+describe('SenseNova POST function tests', () => {
+  it('should call UniverseRoute with correct parameters', async () => {
+    const mockRequest = new Request('https://example.com', { method: 'POST' });
+    await POST(mockRequest);
+    expect(UniverseRoute).toHaveBeenCalledWith(mockRequest, {
+      createRuntime: expect.anything(),
+      params: { provider: 'sensenova' },
+    });
+  });
+});
diff --git a/src/app/api/chat/sensenova/route.ts b/src/app/api/chat/sensenova/route.ts
new file mode 100644
index 000000000000..981ea8576477
--- /dev/null
+++ b/src/app/api/chat/sensenova/route.ts
@@ -0,0 +1,34 @@
+import { getLLMConfig } from '@/config/llm';
+import { AgentRuntime } from '@/libs/agent-runtime';
+import { LobeSenseNovaAI } from '@/libs/agent-runtime/sensenova';
+
+import { POST as UniverseRoute } from '../[provider]/route';
+
+import { generateJwtTokenSenseNova } from '@/libs/agent-runtime/sensenova/authToken';
+
+export const runtime = 'nodejs';
+
+export const maxDuration = 30;
+
+export const POST = async (req: Request) =>
+  UniverseRoute(req, {
+    createRuntime: (payload) => {
+      const { SENSENOVA_ACCESS_KEY_ID, SENSENOVA_ACCESS_KEY_SECRET } = getLLMConfig();
+
+      let sensenovaAccessKeyID: string | undefined = payload?.sensenovaAccessKeyID || SENSENOVA_ACCESS_KEY_ID;
+      let sensenovaAccessKeySecret: string | undefined = payload?.sensenovaAccessKeySecret || SENSENOVA_ACCESS_KEY_SECRET;
+
+      const apiKey = generateJwtTokenSenseNova(sensenovaAccessKeyID, sensenovaAccessKeySecret, 60, 15);
+
+      const params = {
+        apiKey,
+        sensenovaAccessKeyID,
+        sensenovaAccessKeySecret,
+      };
+
+      const instance = new LobeSenseNovaAI(params);
+
+      return new AgentRuntime(instance);
+    },
+    params: { provider: 'sensenova' },
+  });
diff --git a/src/config/llm.ts b/src/config/llm.ts
index b07ed60f6082..a14fe7c560a8 100644
--- a/src/config/llm.ts
+++ b/src/config/llm.ts
@@ -125,6 +125,11 @@ export const getLLMConfig = () => {
       ENABLED_HUNYUAN: z.boolean(),
       HUNYUAN_API_KEY: z.string().optional(),
       HUNYUAN_MODEL_LIST: z.string().optional(),
+
+      ENABLED_SENSENOVA: z.boolean(),
+      SENSENOVA_ACCESS_KEY_ID: z.string().optional(),
+      SENSENOVA_ACCESS_KEY_SECRET: z.string().optional(),
+      SENSENOVA_MODEL_LIST: z.string().optional(),
     },
     runtimeEnv: {
       API_KEY_SELECT_MODE: process.env.API_KEY_SELECT_MODE,
@@ -247,6 +252,11 @@ export const getLLMConfig = () => {
       ENABLED_HUNYUAN: !!process.env.HUNYUAN_API_KEY,
       HUNYUAN_API_KEY: process.env.HUNYUAN_API_KEY,
       HUNYUAN_MODEL_LIST: process.env.HUNYUAN_MODEL_LIST,
+
+      ENABLED_SENSENOVA: !!process.env.SENSENOVA_ACCESS_KEY_ID && !!process.env.SENSENOVA_ACCESS_KEY_SECRET,
+      SENSENOVA_ACCESS_KEY_ID: process.env.SENSENOVA_ACCESS_KEY_ID,
+      SENSENOVA_ACCESS_KEY_SECRET: process.env.SENSENOVA_ACCESS_KEY_SECRET,
+      SENSENOVA_MODEL_LIST: process.env.SENSENOVA_MODEL_LIST,
     },
   });
 };
diff --git a/src/config/modelProviders/index.ts b/src/config/modelProviders/index.ts
index 3cca8d0f813a..b2516ebaa316 100644
--- a/src/config/modelProviders/index.ts
+++ b/src/config/modelProviders/index.ts
@@ -21,6 +21,7 @@ import OpenAIProvider from './openai';
 import OpenRouterProvider from './openrouter';
 import PerplexityProvider from './perplexity';
 import QwenProvider from './qwen';
+import SenseNovaProvider from './sensenova';
 import SiliconCloudProvider from './siliconcloud';
 import SparkProvider from './spark';
 import StepfunProvider from './stepfun';
@@ -61,6 +62,7 @@ export const LOBE_DEFAULT_MODEL_LIST: ChatModelCard[] = [
   Ai21Provider.chatModels,
   HunyuanProvider.chatModels,
   WenxinProvider.chatModels,
+  SenseNovaProvider.chatModels,
 ].flat();
 
 export const DEFAULT_MODEL_PROVIDER_LIST = [
@@ -87,6 +89,7 @@ export const DEFAULT_MODEL_PROVIDER_LIST = [
   SparkProvider,
   ZhiPuProvider,
   ZeroOneProvider,
+  SenseNovaProvider,
   StepfunProvider,
   MoonshotProvider,
   BaichuanProvider,
@@ -126,6 +129,7 @@ export { default as OpenAIProviderCard } from './openai';
 export { default as OpenRouterProviderCard } from './openrouter';
 export { default as PerplexityProviderCard } from './perplexity';
 export { default as QwenProviderCard } from './qwen';
+export { default as SenseNovaProviderCard } from './sensenova';
 export { default as SiliconCloudProviderCard } from './siliconcloud';
 export { default as SparkProviderCard } from './spark';
 export { default as StepfunProviderCard } from './stepfun';
diff --git a/src/config/modelProviders/sensenova.ts b/src/config/modelProviders/sensenova.ts
new file mode 100644
index 000000000000..fe4965a6897b
--- /dev/null
+++ b/src/config/modelProviders/sensenova.ts
@@ -0,0 +1,124 @@
+import { ModelProviderCard } from '@/types/llm';
+
+// ref https://platform.sensenova.cn/pricing
+// ref https://platform.sensenova.cn/release?path=/release-202409.md
+const SenseNova: ModelProviderCard = {
+  chatModels: [
+    {
+      description: '最新版本模型 (V5.5)，128K上下文长度，在数学推理、英文对话、指令跟随以及长文本理解等领域能力显著提升，比肩GPT-4o',
+      displayName: 'SenseChat 5.5',
+      enabled: true,
+      functionCall: true,
+      id: 'SenseChat-5',
+      pricing: {
+        currency: 'CNY',
+        input: 40,
+        output: 100,
+      },
+      tokens: 131_072,
+    },
+    {
+      description: '最新版本模型 (V5.5)，16K上下文长度，支持多图的输入，全面实现模型基础能力优化，在对象属性识别、空间关系、动作事件识别、场景理解、情感识别、逻辑常识推理和文本理解生成上都实现了较大提升。',
+      displayName: 'SenseChat 5.5 Vision',
+      enabled: true,
+      id: 'SenseChat-Vision',
+      pricing: {
+        currency: 'CNY',
+        input: 100,
+        output: 100,
+      },
+      tokens: 16_384,
+      vision: true,
+    },
+    {
+      description: '适用于快速问答、模型微调场景',
+      displayName: 'SenseChat 5.0 Turbo',
+      enabled: true,
+      id: 'SenseChat-Turbo',
+      pricing: {
+        currency: 'CNY',
+        input: 2,
+        output: 5,
+      },
+      tokens: 32_768,
+    },
+    {
+      description: '32K上下文长度，在粤语的对话理解上超越了GPT-4，在知识、推理、数学及代码编写等多个领域均能与GPT-4 Turbo相媲美',
+      displayName: 'SenseChat 5.0 Cantonese',
+      id: 'SenseChat-5-Cantonese',
+      pricing: {
+        currency: 'CNY',
+        input: 27,
+        output: 27,
+      },
+      tokens: 32_768,
+    },
+    {
+      description: '基础版本模型 (V4)，128K上下文长度，在长文本理解及生成等任务中表现出色',
+      displayName: 'SenseChat 4.0 128K',
+      enabled: true,
+      id: 'SenseChat-128K',
+      pricing: {
+        currency: 'CNY',
+        input: 60,
+        output: 60,
+      },
+      tokens: 131_072,
+    },
+    {
+      description: '基础版本模型 (V4)，32K上下文长度，灵活应用于各类场景',
+      displayName: 'SenseChat 4.0 32K',
+      enabled: true,
+      id: 'SenseChat-32K',
+      pricing: {
+        currency: 'CNY',
+        input: 36,
+        output: 36,
+      },
+      tokens: 32_768,
+    },
+    {
+      description: '基础版本模型 (V4)，4K上下文长度，通用能力强大',
+      displayName: 'SenseChat 4.0 4K',
+      enabled: true,
+      id: 'SenseChat',
+      pricing: {
+        currency: 'CNY',
+        input: 12,
+        output: 12,
+      },
+      tokens: 4096,
+    },
+    {
+      description: '标准版模型，8K上下文长度，高响应速度',
+      displayName: 'SenseChat Character',
+      id: 'SenseChat-Character',
+      pricing: {
+        currency: 'CNY',
+        input: 12,
+        output: 12,
+      },
+      tokens: 8192,
+    },
+    {
+      description: '高级版模型，32K上下文长度，能力全面提升，支持中/英文对话',
+      displayName: 'SenseChat Character Pro',
+      id: 'SenseChat-Character-Pro',
+      pricing: {
+        currency: 'CNY',
+        input: 15,
+        output: 15,
+      },
+      tokens: 32_768,
+    },
+  ],
+  checkModel: 'SenseChat-Turbo',
+  disableBrowserRequest: true,
+  id: 'sensenova',
+  modelList: { showModelFetcher: true },
+  modelsUrl: 'https://platform.sensenova.cn/pricing',
+  name: 'SenseNova',
+  url: 'https://platform.sensenova.cn/home',
+};
+
+export default SenseNova;
diff --git a/src/const/auth.ts b/src/const/auth.ts
index 643ee56ceefe..33c0180fc766 100644
--- a/src/const/auth.ts
+++ b/src/const/auth.ts
@@ -40,6 +40,9 @@ export interface JWTPayload {
   wenxinAccessKey?: string;
   wenxinSecretKey?: string;
 
+  sensenovaAccessKeyID?: string;
+  sensenovaAccessKeySecret?: string;
+
   /**
    * user id
    * in client db mode it's a uuid
diff --git a/src/const/settings/llm.ts b/src/const/settings/llm.ts
index d22d1e55d4b0..630373414cdc 100644
--- a/src/const/settings/llm.ts
+++ b/src/const/settings/llm.ts
@@ -19,6 +19,7 @@ import {
   OpenRouterProviderCard,
   PerplexityProviderCard,
   QwenProviderCard,
+  SenseNovaProviderCard,
   SiliconCloudProviderCard,
   SparkProviderCard,
   StepfunProviderCard,
@@ -118,6 +119,10 @@ export const DEFAULT_LLM_CONFIG: UserModelProviderConfig = {
     enabled: false,
     enabledModels: filterEnabledModels(QwenProviderCard),
   },
+  sensenova: {
+    enabled: false,
+    enabledModels: filterEnabledModels(SenseNovaProviderCard),
+  },
   siliconcloud: {
     enabled: false,
     enabledModels: filterEnabledModels(SiliconCloudProviderCard),
diff --git a/src/features/Conversation/Error/APIKeyForm/SenseNova.tsx b/src/features/Conversation/Error/APIKeyForm/SenseNova.tsx
new file mode 100644
index 000000000000..dbf970b1c6d6
--- /dev/null
+++ b/src/features/Conversation/Error/APIKeyForm/SenseNova.tsx
@@ -0,0 +1,49 @@
+import { SenseNova } from '@lobehub/icons';
+import { Input } from 'antd';
+import { memo } from 'react';
+import { useTranslation } from 'react-i18next';
+
+import { ModelProvider } from '@/libs/agent-runtime';
+import { useUserStore } from '@/store/user';
+import { keyVaultsConfigSelectors } from '@/store/user/selectors';
+
+import { FormAction } from '../style';
+
+const SenseNovaForm = memo(() => {
+  const { t } = useTranslation('modelProvider');
+
+  const [sensenovaAccessKeyID, sensenovaAccessKeySecret, setConfig] = useUserStore((s) => [
+    keyVaultsConfigSelectors.sensenovaConfig(s).sensenovaAccessKeyID,
+    keyVaultsConfigSelectors.sensenovaConfig(s).sensenovaAccessKeySecret,
+    s.updateKeyVaultConfig,
+  ]);
+
+  return (
+    <FormAction
+      avatar={<SenseNova color={SenseNova.colorPrimary} size={56} />}
+      description={t('sensenova.unlock.description')}
+      title={t('sensenova.unlock.title')}
+    >
+      <Input.Password
+        autoComplete={'new-password'}
+        onChange={(e) => {
+          setConfig(ModelProvider.SenseNova, { sensenovaAccessKeyID: e.target.value });
+        }}
+        placeholder={t('sensenova.sensenovaAccessKeyID.placeholder')}
+        type={'block'}
+        value={sensenovaAccessKeyID}
+      />
+      <Input.Password
+        autoComplete={'new-password'}
+        onChange={(e) => {
+          setConfig(ModelProvider.SenseNova, { sensenovaAccessKeySecret: e.target.value });
+        }}
+        placeholder={t('sensenova.sensenovaAccessKeySecret.placeholder')}
+        type={'block'}
+        value={sensenovaAccessKeySecret}
+      />
+    </FormAction>
+  );
+});
+
+export default SenseNovaForm;
diff --git a/src/features/Conversation/Error/APIKeyForm/index.tsx b/src/features/Conversation/Error/APIKeyForm/index.tsx
index 5ba78f4f0ba3..7b53b69d8945 100644
--- a/src/features/Conversation/Error/APIKeyForm/index.tsx
+++ b/src/features/Conversation/Error/APIKeyForm/index.tsx
@@ -10,6 +10,7 @@ import { GlobalLLMProviderKey } from '@/types/user/settings';
 
 import BedrockForm from './Bedrock';
 import ProviderApiKeyForm from './ProviderApiKeyForm';
+import SenseNovaForm from './SenseNova';
 import WenxinForm from './Wenxin';
 
 interface APIKeyFormProps {
@@ -66,6 +67,8 @@ const APIKeyForm = memo<APIKeyFormProps>(({ id, provider }) => {
     <Center gap={16} style={{ maxWidth: 300 }}>
       {provider === ModelProvider.Bedrock ? (
         <BedrockForm />
+      ) : provider === ModelProvider.SenseNova ? (
+        <SenseNovaForm />
       ) : provider === ModelProvider.Wenxin ? (
         <WenxinForm />
       ) : (
diff --git a/src/libs/agent-runtime/AgentRuntime.ts b/src/libs/agent-runtime/AgentRuntime.ts
index 68ea3ade7cd7..2cc181682630 100644
--- a/src/libs/agent-runtime/AgentRuntime.ts
+++ b/src/libs/agent-runtime/AgentRuntime.ts
@@ -24,6 +24,7 @@ import { LobeOpenAI } from './openai';
 import { LobeOpenRouterAI } from './openrouter';
 import { LobePerplexityAI } from './perplexity';
 import { LobeQwenAI } from './qwen';
+import { LobeSenseNovaAI } from './sensenova';
 import { LobeSiliconCloudAI } from './siliconcloud';
 import { LobeSparkAI } from './spark';
 import { LobeStepfunAI } from './stepfun';
@@ -144,6 +145,7 @@ class AgentRuntime {
       openrouter: Partial<ClientOptions>;
       perplexity: Partial<ClientOptions>;
       qwen: Partial<ClientOptions>;
+      sensenova: Partial<ClientOptions>;
       siliconcloud: Partial<ClientOptions>;
       spark: Partial<ClientOptions>;
       stepfun: Partial<ClientOptions>;
@@ -307,6 +309,11 @@ class AgentRuntime {
         runtimeModel = new LobeHunyuanAI(params.hunyuan);
         break;
       }
+
+      case ModelProvider.SenseNova: {
+        runtimeModel = new LobeSenseNovaAI(params.sensenova);
+        break;
+      }
     }
 
     return new AgentRuntime(runtimeModel);
diff --git a/src/libs/agent-runtime/sensenova/authToken.ts b/src/libs/agent-runtime/sensenova/authToken.ts
new file mode 100644
index 000000000000..8a226e88a8f0
--- /dev/null
+++ b/src/libs/agent-runtime/sensenova/authToken.ts
@@ -0,0 +1,34 @@
+import CryptoJS from 'crypto-js';
+
+const base64UrlEncode = (obj: object) => {
+    return CryptoJS.enc.Base64.stringify(CryptoJS.enc.Utf8.parse(JSON.stringify(obj)))
+      .replaceAll('=', '')
+      .replaceAll('+', '-')
+      .replaceAll('/', '_')
+}
+
+// https://console.sensecore.cn/help/docs/model-as-a-service/nova/overview/Authorization
+export const generateJwtTokenSenseNova = (accessKeyID: string = '', accessKeySecret: string = '', expiredAfter: number = 1800, notBefore: number = 5) => {
+      const headers = {
+        alg: 'HS256',
+        typ: 'JWT'
+      }
+
+      const payload = {
+        exp: Math.floor(Date.now() / 1000) + expiredAfter,
+        iss: accessKeyID,
+        nbf: Math.floor(Date.now() / 1000) - notBefore,
+      }
+
+      const data = `${ base64UrlEncode(headers) }.${ base64UrlEncode(payload) }`
+
+      const signature = CryptoJS.HmacSHA256(data, accessKeySecret)
+        .toString(CryptoJS.enc.Base64)
+        .replaceAll('=', '')
+        .replaceAll('+', '-')
+        .replaceAll('/', '_')
+
+      const apiKey = `${ data }.${ signature }`
+
+      return apiKey
+};
diff --git a/src/libs/agent-runtime/sensenova/index.test.ts b/src/libs/agent-runtime/sensenova/index.test.ts
new file mode 100644
index 000000000000..b2e33e48ef67
--- /dev/null
+++ b/src/libs/agent-runtime/sensenova/index.test.ts
@@ -0,0 +1,255 @@
+// @vitest-environment node
+import OpenAI from 'openai';
+import { Mock, afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
+
+import {
+  ChatStreamCallbacks,
+  LobeOpenAICompatibleRuntime,
+  ModelProvider,
+} from '@/libs/agent-runtime';
+
+import * as debugStreamModule from '../utils/debugStream';
+import { LobeSenseNovaAI } from './index';
+
+const provider = ModelProvider.SenseNova;
+const defaultBaseURL = 'https://api.sensenova.cn/compatible-mode/v1';
+
+const bizErrorType = 'ProviderBizError';
+const invalidErrorType = 'InvalidProviderAPIKey';
+
+// Mock the console.error to avoid polluting test output
+vi.spyOn(console, 'error').mockImplementation(() => {});
+
+let instance: LobeOpenAICompatibleRuntime;
+
+beforeEach(() => {
+  instance = new LobeSenseNovaAI({ apiKey: 'test' });
+
+  // 使用 vi.spyOn 来模拟 chat.completions.create 方法
+  vi.spyOn(instance['client'].chat.completions, 'create').mockResolvedValue(
+    new ReadableStream() as any,
+  );
+});
+
+afterEach(() => {
+  vi.clearAllMocks();
+});
+
+describe('LobeSenseNovaAI', () => {
+  describe('init', () => {
+    it('should correctly initialize with an API key', async () => {
+      const instance = new LobeSenseNovaAI({ apiKey: 'test_api_key' });
+      expect(instance).toBeInstanceOf(LobeSenseNovaAI);
+      expect(instance.baseURL).toEqual(defaultBaseURL);
+    });
+  });
+
+  describe('chat', () => {
+    describe('Error', () => {
+      it('should return OpenAIBizError with an openai error response when OpenAI.APIError is thrown', async () => {
+        // Arrange
+        const apiError = new OpenAI.APIError(
+          400,
+          {
+            status: 400,
+            error: {
+              message: 'Bad Request',
+            },
+          },
+          'Error message',
+          {},
+        );
+
+        vi.spyOn(instance['client'].chat.completions, 'create').mockRejectedValue(apiError);
+
+        // Act
+        try {
+          await instance.chat({
+            messages: [{ content: 'Hello', role: 'user' }],
+            model: 'SenseChat-Turbo',
+            temperature: 0,
+          });
+        } catch (e) {
+          expect(e).toEqual({
+            endpoint: defaultBaseURL,
+            error: {
+              error: { message: 'Bad Request' },
+              status: 400,
+            },
+            errorType: bizErrorType,
+            provider,
+          });
+        }
+      });
+
+      it('should throw AgentRuntimeError with NoOpenAIAPIKey if no apiKey is provided', async () => {
+        try {
+          new LobeSenseNovaAI({});
+        } catch (e) {
+          expect(e).toEqual({ errorType: invalidErrorType });
+        }
+      });
+
+      it('should return OpenAIBizError with the cause when OpenAI.APIError is thrown with cause', async () => {
+        // Arrange
+        const errorInfo = {
+          stack: 'abc',
+          cause: {
+            message: 'api is undefined',
+          },
+        };
+        const apiError = new OpenAI.APIError(400, errorInfo, 'module error', {});
+
+        vi.spyOn(instance['client'].chat.completions, 'create').mockRejectedValue(apiError);
+
+        // Act
+        try {
+          await instance.chat({
+            messages: [{ content: 'Hello', role: 'user' }],
+            model: 'SenseChat-Turbo',
+            temperature: 0,
+          });
+        } catch (e) {
+          expect(e).toEqual({
+            endpoint: defaultBaseURL,
+            error: {
+              cause: { message: 'api is undefined' },
+              stack: 'abc',
+            },
+            errorType: bizErrorType,
+            provider,
+          });
+        }
+      });
+
+      it('should return OpenAIBizError with an cause response with desensitize Url', async () => {
+        // Arrange
+        const errorInfo = {
+          stack: 'abc',
+          cause: { message: 'api is undefined' },
+        };
+        const apiError = new OpenAI.APIError(400, errorInfo, 'module error', {});
+
+        instance = new LobeSenseNovaAI({
+          apiKey: 'test',
+
+          baseURL: 'https://api.abc.com/v1',
+        });
+
+        vi.spyOn(instance['client'].chat.completions, 'create').mockRejectedValue(apiError);
+
+        // Act
+        try {
+          await instance.chat({
+            messages: [{ content: 'Hello', role: 'user' }],
+            model: 'SenseChat-Turbo',
+            temperature: 0,
+          });
+        } catch (e) {
+          expect(e).toEqual({
+            endpoint: 'https://api.***.com/v1',
+            error: {
+              cause: { message: 'api is undefined' },
+              stack: 'abc',
+            },
+            errorType: bizErrorType,
+            provider,
+          });
+        }
+      });
+
+      it('should throw an InvalidSenseNovaAPIKey error type on 401 status code', async () => {
+        // Mock the API call to simulate a 401 error
+        const error = new Error('Unauthorized') as any;
+        error.status = 401;
+        vi.mocked(instance['client'].chat.completions.create).mockRejectedValue(error);
+
+        try {
+          await instance.chat({
+            messages: [{ content: 'Hello', role: 'user' }],
+            model: 'SenseChat-Turbo',
+            temperature: 0,
+          });
+        } catch (e) {
+          // Expect the chat method to throw an error with InvalidSenseNovaAPIKey
+          expect(e).toEqual({
+            endpoint: defaultBaseURL,
+            error: new Error('Unauthorized'),
+            errorType: invalidErrorType,
+            provider,
+          });
+        }
+      });
+
+      it('should return AgentRuntimeError for non-OpenAI errors', async () => {
+        // Arrange
+        const genericError = new Error('Generic Error');
+
+        vi.spyOn(instance['client'].chat.completions, 'create').mockRejectedValue(genericError);
+
+        // Act
+        try {
+          await instance.chat({
+            messages: [{ content: 'Hello', role: 'user' }],
+            model: 'SenseChat-Turbo',
+            temperature: 0,
+          });
+        } catch (e) {
+          expect(e).toEqual({
+            endpoint: defaultBaseURL,
+            errorType: 'AgentRuntimeError',
+            provider,
+            error: {
+              name: genericError.name,
+              cause: genericError.cause,
+              message: genericError.message,
+              stack: genericError.stack,
+            },
+          });
+        }
+      });
+    });
+
+    describe('DEBUG', () => {
+      it('should call debugStream and return StreamingTextResponse when DEBUG_SENSENOVA_CHAT_COMPLETION is 1', async () => {
+        // Arrange
+        const mockProdStream = new ReadableStream() as any; // 模拟的 prod 流
+        const mockDebugStream = new ReadableStream({
+          start(controller) {
+            controller.enqueue('Debug stream content');
+            controller.close();
+          },
+        }) as any;
+        mockDebugStream.toReadableStream = () => mockDebugStream; // 添加 toReadableStream 方法
+
+        // 模拟 chat.completions.create 返回值，包括模拟的 tee 方法
+        (instance['client'].chat.completions.create as Mock).mockResolvedValue({
+          tee: () => [mockProdStream, { toReadableStream: () => mockDebugStream }],
+        });
+
+        // 保存原始环境变量值
+        const originalDebugValue = process.env.DEBUG_SENSENOVA_CHAT_COMPLETION;
+
+        // 模拟环境变量
+        process.env.DEBUG_SENSENOVA_CHAT_COMPLETION = '1';
+        vi.spyOn(debugStreamModule, 'debugStream').mockImplementation(() => Promise.resolve());
+
+        // 执行测试
+        // 运行你的测试函数，确保它会在条件满足时调用 debugStream
+        // 假设的测试函数调用，你可能需要根据实际情况调整
+        await instance.chat({
+          messages: [{ content: 'Hello', role: 'user' }],
+          model: 'SenseChat-Turbo',
+          stream: true,
+          temperature: 0,
+        });
+
+        // 验证 debugStream 被调用
+        expect(debugStreamModule.debugStream).toHaveBeenCalled();
+
+        // 恢复原始环境变量值
+        process.env.DEBUG_SENSENOVA_CHAT_COMPLETION = originalDebugValue;
+      });
+    });
+  });
+});
diff --git a/src/libs/agent-runtime/sensenova/index.ts b/src/libs/agent-runtime/sensenova/index.ts
new file mode 100644
index 000000000000..a9dd5200654c
--- /dev/null
+++ b/src/libs/agent-runtime/sensenova/index.ts
@@ -0,0 +1,24 @@
+import OpenAI from 'openai';
+
+import { ChatStreamPayload, ModelProvider } from '../types';
+import { LobeOpenAICompatibleFactory } from '../utils/openaiCompatibleFactory';
+
+export const LobeSenseNovaAI = LobeOpenAICompatibleFactory({
+  baseURL: 'https://api.sensenova.cn/compatible-mode/v1',
+  chatCompletion: {
+    handlePayload: (payload: ChatStreamPayload) => {
+      const { frequency_penalty, temperature, top_p, ...rest } = payload;
+
+      return {
+        ...rest,
+        frequency_penalty: (frequency_penalty !== undefined && frequency_penalty > 0 && frequency_penalty <= 2) ? frequency_penalty : undefined,
+        temperature: (temperature !== undefined && temperature > 0 && temperature <= 2) ? temperature : undefined,
+        top_p: (top_p !== undefined && top_p > 0 && top_p < 1) ? top_p : undefined,
+      } as OpenAI.ChatCompletionCreateParamsStreaming;
+    }
+  },
+  debug: {
+    chatCompletion: () => process.env.DEBUG_SENSENOVA_CHAT_COMPLETION === '1',
+  },
+  provider: ModelProvider.SenseNova,
+});
diff --git a/src/libs/agent-runtime/types/type.ts b/src/libs/agent-runtime/types/type.ts
index 59a2fc03b8be..7ad9ace9d355 100644
--- a/src/libs/agent-runtime/types/type.ts
+++ b/src/libs/agent-runtime/types/type.ts
@@ -43,6 +43,7 @@ export enum ModelProvider {
   OpenRouter = 'openrouter',
   Perplexity = 'perplexity',
   Qwen = 'qwen',
+  SenseNova = 'sensenova',
   SiliconCloud = 'siliconcloud',
   Spark = 'spark',
   Stepfun = 'stepfun',
diff --git a/src/locales/default/modelProvider.ts b/src/locales/default/modelProvider.ts
index 964413157fbb..71ff45d8149a 100644
--- a/src/locales/default/modelProvider.ts
+++ b/src/locales/default/modelProvider.ts
@@ -115,6 +115,23 @@ export default {
       title: '下载指定的 Ollama 模型',
     },
   },
+  sensenova: {
+    sensenovaAccessKeyID: {
+      desc: '填入 SenseNova Access Key ID',
+      placeholder: 'SenseNova Access Key ID',
+      title: 'Access Key ID',
+    },
+    sensenovaAccessKeySecret: {
+      desc: '填入 SenseNova Access Key Secret',
+      placeholder: 'SenseNova Access Key Secret',
+      title: 'Access Key Secret',
+    },
+    unlock: {
+      description:
+        '输入你的 Access Key ID / Access Key Secret 即可开始会话。应用不会记录你的鉴权配置',
+      title: '使用自定义 SenseNova 鉴权信息',
+    },
+  },
   wenxin: {
     accessKey: {
       desc: '填入百度千帆平台的 Access Key',
diff --git a/src/server/globalConfig/index.ts b/src/server/globalConfig/index.ts
index f26ddd83ae69..89231202bdd3 100644
--- a/src/server/globalConfig/index.ts
+++ b/src/server/globalConfig/index.ts
@@ -15,6 +15,7 @@ import {
   OpenAIProviderCard,
   OpenRouterProviderCard,
   QwenProviderCard,
+  SenseNovaProviderCard,
   SiliconCloudProviderCard,
   TogetherAIProviderCard,
   ZeroOneProviderCard,
@@ -71,6 +72,9 @@ export const getServerGlobalConfig = () => {
     ENABLED_AI21,
     ENABLED_AI360,
 
+    ENABLED_SENSENOVA,
+    SENSENOVA_MODEL_LIST,
+
     ENABLED_SILICONCLOUD,
     SILICONCLOUD_MODEL_LIST,
 
@@ -220,6 +224,14 @@ export const getServerGlobalConfig = () => {
           modelString: QWEN_MODEL_LIST,
         }),
       },
+      sensenova: {
+        enabled: ENABLED_SENSENOVA,
+        enabledModels: extractEnabledModels(SENSENOVA_MODEL_LIST),
+        serverModelCards: transformToChatModelCards({
+          defaultChatModels: SenseNovaProviderCard.chatModels,
+          modelString: SENSENOVA_MODEL_LIST,
+        }),
+      },
       siliconcloud: {
         enabled: ENABLED_SILICONCLOUD,
         enabledModels: extractEnabledModels(SILICONCLOUD_MODEL_LIST),
diff --git a/src/services/_auth.ts b/src/services/_auth.ts
index 7ecfa4f64c13..098156d475bc 100644
--- a/src/services/_auth.ts
+++ b/src/services/_auth.ts
@@ -5,6 +5,8 @@ import { keyVaultsConfigSelectors, userProfileSelectors } from '@/store/user/sel
 import { GlobalLLMProviderKey } from '@/types/user/settings';
 import { createJWT } from '@/utils/jwt';
 
+import { generateJwtTokenSenseNova } from '@/libs/agent-runtime/sensenova/authToken';
+
 export const getProviderAuthPayload = (provider: string) => {
   switch (provider) {
     case ModelProvider.Bedrock: {
@@ -25,6 +27,20 @@ export const getProviderAuthPayload = (provider: string) => {
       };
     }
 
+    case ModelProvider.SenseNova: {
+      const { sensenovaAccessKeyID, sensenovaAccessKeySecret } = keyVaultsConfigSelectors.sensenovaConfig(
+        useUserStore.getState(),
+      );
+
+      const apiKey = generateJwtTokenSenseNova(sensenovaAccessKeyID, sensenovaAccessKeySecret, 60, 15);
+
+      return { 
+        apiKey,
+        sensenovaAccessKeyID: sensenovaAccessKeyID, 
+        sensenovaAccessKeySecret: sensenovaAccessKeySecret, 
+      };
+    }
+
     case ModelProvider.Wenxin: {
       const { secretKey, accessKey } = keyVaultsConfigSelectors.wenxinConfig(
         useUserStore.getState(),
diff --git a/src/store/user/slices/modelList/selectors/keyVaults.ts b/src/store/user/slices/modelList/selectors/keyVaults.ts
index 8a038f8d4919..6f5047d55481 100644
--- a/src/store/user/slices/modelList/selectors/keyVaults.ts
+++ b/src/store/user/slices/modelList/selectors/keyVaults.ts
@@ -16,6 +16,7 @@ const openAIConfig = (s: UserStore) => keyVaultsSettings(s).openai || {};
 const bedrockConfig = (s: UserStore) => keyVaultsSettings(s).bedrock || {};
 const wenxinConfig = (s: UserStore) => keyVaultsSettings(s).wenxin || {};
 const ollamaConfig = (s: UserStore) => keyVaultsSettings(s).ollama || {};
+const sensenovaConfig = (s: UserStore) => keyVaultsSettings(s).sensenova || {};
 const azureConfig = (s: UserStore) => keyVaultsSettings(s).azure || {};
 const getVaultByProvider = (provider: GlobalLLMProviderKey) => (s: UserStore) =>
   (keyVaultsSettings(s)[provider] || {}) as OpenAICompatibleKeyVault &
@@ -43,5 +44,6 @@ export const keyVaultsConfigSelectors = {
   ollamaConfig,
   openAIConfig,
   password,
+  sensenovaConfig,
   wenxinConfig,
 };
diff --git a/src/store/user/slices/modelList/selectors/modelConfig.ts b/src/store/user/slices/modelList/selectors/modelConfig.ts
index 8e2acb1421ca..a41e14a9ab8c 100644
--- a/src/store/user/slices/modelList/selectors/modelConfig.ts
+++ b/src/store/user/slices/modelList/selectors/modelConfig.ts
@@ -69,6 +69,7 @@ const openAIConfig = (s: UserStore) => currentLLMSettings(s).openai;
 const bedrockConfig = (s: UserStore) => currentLLMSettings(s).bedrock;
 const ollamaConfig = (s: UserStore) => currentLLMSettings(s).ollama;
 const azureConfig = (s: UserStore) => currentLLMSettings(s).azure;
+const sensenovaConfig = (s: UserStore) => currentLLMSettings(s).sensenova;
 
 const isAzureEnabled = (s: UserStore) => currentLLMSettings(s).azure.enabled;
 
@@ -86,4 +87,5 @@ export const modelConfigSelectors = {
 
   ollamaConfig,
   openAIConfig,
+  sensenovaConfig,
 };
diff --git a/src/types/user/settings/keyVaults.ts b/src/types/user/settings/keyVaults.ts
index 1134a768996a..a6fce0854414 100644
--- a/src/types/user/settings/keyVaults.ts
+++ b/src/types/user/settings/keyVaults.ts
@@ -16,6 +16,11 @@ export interface AWSBedrockKeyVault {
   sessionToken?: string;
 }
 
+export interface SenseNovaKeyVault {
+  sensenovaAccessKeyID?: string;
+  sensenovaAccessKeySecret?: string;
+}
+
 export interface WenxinKeyVault {
   accessKey?: string;
   secretKey?: string;
@@ -45,6 +50,7 @@ export interface UserKeyVaults {
   password?: string;
   perplexity?: OpenAICompatibleKeyVault;
   qwen?: OpenAICompatibleKeyVault;
+  sensenova?: SenseNovaKeyVault;
   siliconcloud?: OpenAICompatibleKeyVault;
   spark?: OpenAICompatibleKeyVault;
   stepfun?: OpenAICompatibleKeyVault;
